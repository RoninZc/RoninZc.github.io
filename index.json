[{"categories":null,"content":"问题 这个问题是本人在折腾自己的良心云（凉心云）的时候发现的，当时是想使用一个前置 Nginx 转发所有的请求，同时进行日志的记录等等。 当我写完配置文件，测试时没有任何问题。但是当我关闭了自己搭建的 es 服务，我发现我访问所有的服务都 500 了，这时我查看 nginx error 日志，记录如下 [emerg] 1#1: host not found in upstream \"es\" in /etc/nginx/conf.d/es.conf:13 ","date":"2022-07-20","objectID":"/docker%E9%83%A8%E7%BD%B2nginx%E5%87%BA%E7%8E%B0host-not-found-in-upstream%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/:1:0","tags":["Docker","Nginx"],"title":"Docker 部署 Nginx 出现「host not found in upstream」问题解决","uri":"/docker%E9%83%A8%E7%BD%B2nginx%E5%87%BA%E7%8E%B0host-not-found-in-upstream%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"categories":null,"content":"解决 在 nginx 的配置文件中添加以下内容 server { listen 80; server_name test.com; # 添加额外的 dns 解析地址，此地址为 docker 内部 dns 地址 # 当 proxy_pass 为变量时 必须添加 resolver 127.0.0.11; location / { set $tmp es; proxy_pass http://$tmp; } } ","date":"2022-07-20","objectID":"/docker%E9%83%A8%E7%BD%B2nginx%E5%87%BA%E7%8E%B0host-not-found-in-upstream%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/:2:0","tags":["Docker","Nginx"],"title":"Docker 部署 Nginx 出现「host not found in upstream」问题解决","uri":"/docker%E9%83%A8%E7%BD%B2nginx%E5%87%BA%E7%8E%B0host-not-found-in-upstream%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"categories":null,"content":"原理 nginx 启动时，会对其配置的 upstream 进行 DNS 解析测试，如果无法解析成功则会报错无法启动。 但是，当我们将 upstream 修改为变量时，nginx 不会进行测试，以此绕过这个问题。 resolver 则为 Nginx 设置 DNS 服务器，Nginx会动态利用 resolver 设置的DNS服务器（本机设置的 DNS 服务器或 /etc/hosts 无效），将域名解析成 IP，proxy 模块会将请求转发到解析后的IP上。 如果不添加的话，访问将会502 Bad Gateway，同时日志会显示 no resolver defined to resolve es ","date":"2022-07-20","objectID":"/docker%E9%83%A8%E7%BD%B2nginx%E5%87%BA%E7%8E%B0host-not-found-in-upstream%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/:2:1","tags":["Docker","Nginx"],"title":"Docker 部署 Nginx 出现「host not found in upstream」问题解决","uri":"/docker%E9%83%A8%E7%BD%B2nginx%E5%87%BA%E7%8E%B0host-not-found-in-upstream%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"categories":null,"content":" 这篇文章用作自己学习 k8s 的笔记，学习的资料为b站的视频 2021 年末倾力打造 Kubernetes 入门至精通 - 2022 年幸福的开胃菜_哔哩哔哩_bilibili 本文章为本人学习所用，如需转载请注明出处 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"1、基础概念 基础组件 kubectl api server scheduler replication controller etcd kubelet kube proxy firewall 插件 CoreDNS 负责为整个集群提供 DNS 服务 Ingress Controller 为 k8s 中的服务提供外网入口 Prometheus 为整个集群提供资源监控能力，时序数据库 Dashboard 提供 B/S 的访问体系，允许用户通过 web 进行集群管理和设置，比较常用的如：rancher Federation 提供跨可用区的集群，提供不同数据中心的 K8S 集群的管理能力 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"2、Pod 在下达创建 pod 的时候，第一个被初始化的容器为pause，作用为初始化网络栈，挂载存储卷等。后续继续创建对应的 container，这些创建的 container 都会与初始容器pause 共享网络栈和存储等，类似 docker 中的--net和--volumes-from。这样在一个 Pod 中的 container 可以直接通过回环接口相互访问。 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Pod种类 自主式 Pod 控制器管理的 Pod（推荐） ReplicationController \u0026 ReplicaSet \u0026 Deployment HPA（HorizontalPodAutoScale） StatefullSet DarmonSet Job \u0026 Cronjob 自定义控制器… 不做讨论 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"控制器种类 Replication Controller （RC）\u0026 ReplicaSet（RS） \u0026 Deployment 用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的 Pod 来替代，而如果异常多出的容器也会自动回收。 在新版本的 K8S 中建议使用 RS 来取代 RC。 RS 的本质和 RC 没有本质区别，只是名字不一样，并且 RS 支持集合式的标签选择器（tag selector）。 虽然 RS 可以独立使用，但是一般建议使用 Deployment 来自动管理 RS，这样可以无需担心和其他机制不兼容的问题。比如 RS 不支持滚动更新（rolling-update）但 Deployment 支持。 滚动更新 # 更新前 Deployment「Pod模板:v1，副本数量：3」 └─ RS「副本数量：3」 ├─ Pod:v1 ├─ Pod:v1 └─ Pod:v1 # 更新Pod模板:v2 # 更新中： Deployment「Pod模板:v1，副本数量：3」 ├─ RS「副本数量：2」 │ ├── Pod:v1 │ └── Pod:v1 └─ RS「副本数量：1」 └─ Pod:v2 # 更新完毕： Deployment「Pod模板:v1，副本数量：3」 ├─ RS「副本数量：0」 └─ RS「副本数量：3」 ├─ Pod:v2 ├─ Pod:v2 └─ Pod:v2 滚动更新会创建一个新的 RS 控制器，以此来创建新版本的 Pod，此时把老版本的 RS 控制器的期望数量一个个调整至0，这样就完成了滚动更新。 HPA（HorizontalPodAutoScale）自动扩缩容 可以根据 Pod 的资源使用情况，调整副本数量，依赖于 RC、RS、Deployment 之上 StatefulSet 服务分类 有状态的服务 无状态服务 中心化服务 去中心化服务 为了解决有状态服务的问题而设计出来，可用来有序扩容缩，其应用场景包括： 稳定的持久化存储，即 Pod 重新调度后还是能访问到相同的持久化数据，基于 PVC 实现 稳定的网络标志，即 Pod 重新调度后，其 PodName 和 HostName 不变，基于 Headless Service（即没有 Cluster IP 的 Service）实现 有序部署，有序扩展，即 Pod 是有顺序的，在部署或者扩展的时候要依据定义的顺序依次进行（即从 0 到 N-1，在下一个 Pod 运行之前，所有之前的 Pod 必须都是 Running 和 Ready 状态），基于 init containers 来实现 有序收缩，有序删除（即 N-1到 0） DaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除所有由它创建的 Pod 经典用法： 运行集群存储 daemon，例如在每个 Node 上运行 glusterd，ceph 在每个 Node 上运行日志手机 deamon，例如 fluentd，logstash 在每个 Node 上运行监控 deamon，例如 Prometheus Node Exporter Job \u0026 cronJob Job 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束 Cron Job 管理基于时间的 Job，即： 在给定时间点只运行一次 周期性的在给定时间点运行 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"网络模型 K8S 的网络模型假定了所有 Pod 都在一个可以直接连通的扁平的网络空间中，这在 GCE（Google Compute Engine）里面是现成的网络模型，K8S 假定这个网络已经存在。而在私有云里搭建 K8S 集群，就不能假定这个网络已经存在了。我们需要自己实现这个网络假设，将不同节点上的 Docker 容器之间的互相访问先打通，然后运行 K8S。 Flannel Flannel 是 CoreOS 团队针对 Kubernetes 设计的一个网络规划服务，简单来说，它的功能是让集群中的不同节点主机创建的 Docker 容器都具有全集群唯一的虚拟 IP 地址。而且它还能在这些 IP 地址之间建立一个覆盖网络（Overlay Network），通过这个覆盖网络，将数据包原封不动地传输到目标容器内。基于 etcd 实现。 实现步骤： Flanneld 向 etcd 申请当前 Pod 的网段，修改当前 Docker0 的IP 会带上当前机器的物理网卡地址，这样就在 etcd 里标识了虚拟网段与真实IP之间的关系 当一个 Pod 发送网络数据的时候，通过对方的虚拟IP就可以找到真实IP了 请求流转（根据图观察） app2 发送一个数据包给10.1.20.3，发现无法直接访问，数据包传递给网关 此时数据包被 Flanneld 所捕获（Flannel0 监听的为 10.1.15.0，注意这个0）传递给对应的另外一个 Flanneld（从etcd获取） 此时 Flanneld 会对数据包进行二次封装，类似一个快递里是另外一个快递 接收到数据包后进行拆包，在对应的 Docker0 中广播，这样也就能收到了 回应同理 网络通讯模式 同 Pod 间不同容器间的网络通讯：本地回环 不同 Pod 间的通讯 同物理机：Docker0 网桥实现报文转发 不同物理机：flannel UDP 数据包二次封装 svc 网络与 Pod 间的通讯 隔离：namespace network ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:3","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"3、K8S安装 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"前置准备 安装配置 推荐安装在单网卡机器 CPU \u003e= 2，内存 3G 以上，磁盘 100G 关闭 SWAP 分区 /boot 800m / 全部 seliunx，firewall stop，iptable none K8S安装3个节点，可以配置一个软路由，双网卡 网卡1: 仅主机 网卡2: NAT 上网 安装工具包（可选） sudo apt-get install -y conntrack ntpdate ntp ipvsadm ipset iptables curl sysstat wget net-tools git 同步时区 sudo apt install ntpdate sudo ntpdate ntp.aliyun.com 关闭swap sudo swapoff -a # 临时关闭 sed -ri 's/.swap./#\u0026/' /etc/fstab # 永久关闭 允许 iptables 桥接流量 cat \u003c\u003cEOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF # 设置网卡允许转发 ipv4 流量 sudo sysctl -w net.ipv4.ip_forward=1 sudo sysctl --system ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"安装 Kubernetes 源码包编译安装（难度过高） 可参考Kubernetes - 二进制版本安装 - v1.18 (cloudmessage.top) 容器化安装 kubeadm 官方 证书有效期 1 年（需要修改源码，设置生成证书有效时间） rancher sealos 1、安装容器组件 docker ARM 系统安装 X86_64 可参考上文，注意修改对应系统架构即可 containerd k8s v1.24.0后 K8Sv1.24.0-containerd安装教程 2、安装 Kubeadm （主从配置） Kubeadm 启动流程 Master Systemd \u003e kubelet \u003e 容器组件 \u003e Kubernetes 容器组件在 k8s v1.24.0 版本已弃用 Docker shim 使用了新组件 CRI DOCKERD # 添加阿里云镜像源 sudo apt update \u0026\u0026 sudo apt install -y apt-transport-https sudo curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add - # 添加阿里云或者官方 api 源 # 阿里云 echo \"deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main\" | sudo tee /etc/apt/sources.list.d/kubernetes.list # 官方 sudo curl -o /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg echo \"deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee /etc/apt/sources.list.d/kubernetes.list # 安装软件 sudo apt update \u0026\u0026 sudo apt install -y kubelet kubeadm kubectl # 开机自启 systemctl enable kubelet.service # 注意，此时可能 kublet 没正常运行，不用管继续往下走 3、初始化主节点 # 打印 kubeadm 默认配置 sudo kubeadm config print init-defaults \u003e kubeadm-config.yaml # 修改：`localAPIEndpoint.advertiseAddress`的值为当前主节点的 ip 地址 ... localAPIEndpoint: advertiseAddress: 1.2.3.4 # 这里 bindPort: 6443 ... # 修改：`nodeRegistration.name` 的值为当前主节点名称 ··· nodeRegistration: criSocket: unix:///var/run/containerd/containerd.sock imagePullPolicy: IfNotPresent name: k8s-master01 # 这里 taints: null ··· # 添加 Pod 网段，Flannel 需要工作在指定的网段 ... networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 podSubnet: 10.244.0.0/16 # 新增该行 ··· # 设置负载均衡方式为 ipvs（可选），下列配置添加到末尾，注意 --- 也需要添加 ··· --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration featureGates: SupportIPVSProxyMode: true mode: ipvs ··· # k8s.gcr.io 国内无法直接访问，所以替换为阿里云镜像地址 sed -i 's/k8s.gcr.io/registry.cn-hangzhou.aliyuncs.com\\/google_containers/g' kubeadm-config.yaml # 配置文件准备完毕，开始初始化 sudo kubeadm init --config=kubeadm-config.yaml --ignore-preflight-errors=all --v=5 | tee kubeadm-init.log # 初始化成功根据页面提示 # 非 root 用户 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # root 用户 export KUBECONFIG=/etc/kubernetes/admin.conf # 查看集群信息 kubectl cluster-info 4、工作节点加入 # 在初始化主节点成功后，打印出的日志内的最后一段，告诉了我们应该如何加入一个主节点 # 也可以 cat kubeadm-init.log 查看 # 加入前查看当前主机名称 hostnamectl，可以修改为自己便于识别的名称 sudo hostnamectl set-hostname k8s-node01 --static # 加入节点 sudo kubeadm join 192.168.31.100:6443 --token xxx.xxx \\ --discovery-token-ca-cert-hash sha256:xxx # 如果提示 unable to fetch the kubeadm-config ConfigMap: faild to get config map: Unauthorized # 这个代表 token 过期，重新生成即可 sudo kubeadm token create --ttl 0 --print-join-command # 如果提示 # [kubelet-check] Initial timeout of 40s passed. # error execution phase kubelet-start: error uploading crisocket: timed out waiting for the condition # To see the stack trace of this error execute with --v=5 or higher sudo kubeadm reset -f 5、工作节点退出 # 1、将节点设置为维护模式 kubectl drain k8s-node01 --delete-local-data --force --ignore-daemonsets node/k8s-node01 # 2、删除节点 kubectl delete node k8s-node01 # 登陆上节点机器 # 3、停止 kubelet systemctl stop kubelet # 4、k8s 重置 sudo kubeadm reset -f 6、创建网络「flannel」 # 拷贝配置文件 sudo mkdir -p /usr/local/kubernetes/cni/flannel/ cd /usr/local/kubernetes/cni/flannel/ wget https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml # 应用配置 kubectl apply -f kube-flannel.yml # 等待2～3分钟，查看是否成功 kubectl get nodes # 可以看到所有节点都显示 ready 7、集群测试 7.1、创建pod # 创建一个 deployment 任务 指定镜像 kubectl create deployment nginx --image=nginx # 获取 pod 列表 kubectl get po -o wide 7.2、创建 svc 网络 # 创建一个 svc 网络 kubectl create svc clusterip nginx --tcp=80:80 # 查看当前 svc 网络 kubectl get svc ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"4、资源清单 在 k8s 中所有的内容都是资源，资源实例化之后，叫做对象 资源： 命名空间级别 工作负载型资源：Pod、ReplicaSet、Deployment 等 服务发现及负载均衡型资源：Service、Ingress 等 配置与存储型资源：Volume、CSI 等 特殊类型的存储卷：ConfigMap、Secre 等 集群级资源 Namespace、Node、ClusterRole、ClusterRoleBinding 元数据类型资源 HPA、PodTemplate、LimitRange 在 k8s 中，一般使用 yaml 格式的文件来创建符合我们预期期望的对象，这样的 yaml 文件我们一般称为资源清单 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"格式 apiVersion: group/apiversion # 如果没有给定 group 名称，那么默认为 core，可以使用 kubectl apt-versions 获取当前 k8s 版本上所有的 apiVersion 版本信息（每个版本可能不同） kind: # 资源类别 metadate: # 资源元数据 name namespace lables annotations # 主要目的是方便用户阅读查找 spec: # 期望的状态 （disired state） status: # 当前状态，本字段由 kubernetes 自身维护，用户不能定义 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"常用命令 必须记住的命令 kubectl explain xxx.xxx 必须记住的命令 kubectl explain xxx.xxx 必须记住的命令 kubectl explain xxx.xxx # 查询 # -n 指定命名空间，默认为 default kuebctl get pod -o wide -l [key/key=values] # 获取 pod 列表 kubectl get pod podName -o json/yaml # 获取 pod 详细信息 kubectl log podName # 获取 pod 日志 kubectl describe pod podName # 获取 pod 事件信息 # 操作 kubectl create -f filename # 创建资源 kubectl exec -it podName -c containerName -- [script] # 在某个容器内执行脚本 kubectl delete [res] [--all | name] # 删除资源 kubectl scale --replicas=[num] [controllerKind]/[resName] # 修改某个控制器的副本数量 获取 apiversion 版本信息 kubectl api-versions # output: admissionregistration.k8s.io/v1 apiextensions.k8s.io/v1 apiregistration.k8s.io/v1 apps/v1 ... 字段配置格式 apiVersion \u003cstring\u003e # 表示字符串类型 metadata \u003cobject\u003e # 表示需要嵌套多层字段 labels \u003cmap[string]string\u003e # 表示由 k:v 组成的映射 finalizers \u003c[]string\u003e # 表示字符串列表 ownerReferences \u003c[]object\u003e # 表示对象列表 hostPID \u003cboolean\u003e # true | flase priority \u003cinteger\u003e # 整型 name \u003cstring\u003e -required- # 如果类型后面接 required，表示为必填字段 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"通过定义清单文件创建 Pod apiVersion: v1 kind: Pod metadate: name: pod-demo namespace: default lables: app: myPod spec: containers: - name: myPod-1 image: nginx - name: myPod-2 image: busybos:1.34.1 command: - \"/bin/sh\" - \"-c\" - \"sleep 3600\" # 使用 -o 选项加 yaml，可以将资源的配置以 yaml 的格式输出，也可以使用 json kubectl get pod xxx.xxx.xxx -o yaml ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:3","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"5、Pod 生命周期 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"执行流程 Pause：在一个 Pod 启动前，会先启动一个 Pause 容器。它会初始化相应的网络栈，同时把自身的网络卷共享给 Pod 内的容器 初始化容器「initC」，可以有0到无限个 它是批处理类型的任务 它的运行是有序的，第一个不运行成功，第二个不会运行 如果执行失败，会直接重载整个 Pod，直到 Init 容器成功为止。然而，如果 Pod 对应的 restartPolicy 为 Never 则不会重启 主容器「mainC」，至少存在一个 多个 mainC 并行启动 多个 mainC 共享同一个网络卷，绑定的端口不能重复 hook 启动前「和主进程同时运行，不一定在主进程运行前执行完成」 关闭前「可以保证在关闭前执行完成」 探针「tcp｜http｜script」 可以进行就绪、存活探测探针：判断是否可以进行后续探针，新版本才存在 就绪探针：判断一个 mainC 是否已经准备好提供服务，可以定义探测间隔 存活探针：判断一个 mainC 是否存活，如无响应则重启容器 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"init 容器 因为 Init 容器具有与应用容器分离的单独镜像，所以它们的启动相关代码具有如下优势： 它们可以包含并运行实用工具，但是出于安全考虑，不建议在应用容器镜像中包含这些工具 应用程序镜像可以分离出创建和部署的角色，而没有必要联合它们构建一个单独的镜像 Init 容器使用 Linux Namespace，所以相对于应用容器来说具有不同的文件系统视图。因此，他们能够具有访问 Secret 的权限，而应用程序则不能 他们必须在应用容器启动之前运行完成，而应用容器是并行运行的，所以 Init 容器能够提供一种简单的阻塞或延迟应用容器启动的方法，直到满足啦一组先决条件 Init 容器具有应用容器的所有字段。除了 readinessProbe，因为 Init 容器无法定义不同于完成和就绪之外的其他状态，这会在验证过程中强制执行 在 Pod 中的每个 app 和 init 容器的名称必须唯一；与其他任何容器共享同一个名称，会在验证时抛出错误 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"简单实操 # testpod.yaml apiVersion: v1 kind: Pod metadata: name: my-nginx-pod labels: app: my-nginx spec: containers: - name: my-nginx image: nginx initContainers: - name: init-my-service image: busybox command: ['sh', '-c', 'until nslookup my-service; do echo waiting for my-service; sleep 2; done;'] - name: init-my-db image: busybox command: ['sh', '-c', 'until nslookup my-db; do echo waiting for my-db; sleep 2; done;'] # init-testpod.yaml apiVersion: v1 kind: Service metadata: name: my-service spec: ports: - protocol: TCP port: 80 targetPort: 9376 --- apiVersion: v1 kind: Service metadata: name: my-db spec: ports: - protocol: TCP port: 80 targetPort: 9377 先创建 init 模板 kubectl create -f init-pod.yaml 查看 Pod 状态 kubectl get po 查看初始化容器日志 kubectl logs my-nginx-pod -c init-my-service 发现一直在解析域名，这时我们创建响应的 service kubectl create -f init-test-pod.yaml 然后我们再去查看容器的状态，可能需要等待一定的时间 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:3","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"探针 探针是由 kubelet 对容器执行的定期诊断，要执行诊断，kubelet 调用容器实现的 Handler。有三种类型的处理程序： ExecAction：在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功 TCPSocketAction：对指定端口上的容器 IP 地址进行 TCP 检查。如果端口打开，则诊断被任务时成功的 HTTPGetAction：对指定的端口和路径上的容器 IP 地址执行 HTTP Get 请求。如果响应的状态码大于等于 200 且小于 400，则诊断被认为是成功的 每次探测都将获得以下三种结果： 成功：容器通过诊断 失败：容器未通过诊断 未知：诊断失败，但不会采取任何行动 readinessProbe「就绪探针」 指示容器是否准备好服务请求。如果就绪探测失败，端点控制器将从与 Pod 匹配的所有 Service 的端点中删除该 Pod 的 IP 地址。初始延迟前的就绪状态默认为 Failure。如果容器不提供就绪探针，则默认状态为 SUCCESS # readinessProbe-httpget apiVersion: v1 kind: Pod metadata: name: reaadiness-httpget-pod namespace: default labels: app: myapp spec: containers: - name: readiness-httpget-container image: nginx imagePullPolice: IfNotPresent readinessProbe: # 配置就绪探针 httpGet: # 探针类型，请求端口和 path port: 80 path: readiness.html initialDelaySeconds: 1 # 开始探测延迟 periodSeconds: 3 # 探测间隔 创建该 Pod 后，会发现 Pod 处于运行状态，但是 READY 却是 0/1。这时我们查看容器日志，发现探针返回为 404，此时表示探针正常生效。 我们进入容器，在 nginx 的根目录下创建readiness.html文件，退出后发现容器已处于就绪状态。 livenessProbe「存活探针」 指示容器是否正在运行。如果存活探测失败，则 kubelet 会杀死容器，并且容器将根据重启策略来判断是否重新拉起。如果容器不提供存活探针，则默认状态为 SUCCESS # livenessProbe-exec apiVersion: v1 kind: Pod metadata: name: liveness-exec-pod namespace: default spec: containers: - name: liveness-exec-container image: busybox imagePullPolicy: IfNotPresent command: [\"/bin/sh\", \"-c\", \"touch /tmp/live; sleep 60; rm -rf /tmp/live; sleep 3600\"] # 运行脚本 livenessProbe: exec: # exec 类型探针 command: [\"test\", \"-e\", \"/tmp/live\"] # 执行脚本 initialDelaySeconds: 1 # 开始探测延迟 periodSeconds: 3 # 探测间隔 创建该 Pod 后，在前 60 秒内正常运行，之后发现 Pod 被杀死并重新创建。 # livenessProbe-httpget apiVersion: v1 kind: Pod metadata: name: liveness-httpget-pod namespace: default spec: containers: - name: liveness-httpget-container image: nginx imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 livenessProbe: httpGet: # 探针类型，请求端口和 path port: 80 path: index.html initialDelaySeconds: 3 # 开始探测延迟 periodSeconds: 3 # 探测间隔 timeoutSeconds: 3 # 超时时间 # livenessProbe-tcp apiVersion: v1 kind: Pod metadata: name: liveness-tcp-pod namespace: default spec: containers: - name: liveness-tcp-container image: nginx imagePullPolicy: IfNotPresent ports: - name: tcp containerPort: 80 livenessProbe: tcpSocket: # 探针类型，请求端口 port: 80 initialDelaySeconds: 5 # 开始探测延迟 timeoutSeconds: 1 # 超时时间 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:4","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"启动、退出动作「hook」 apiVersion: v1 kind: Pod metadata: name: lifecycle-demo spec: containers: - name: lifecycle-demo-container image: nginx lifecycle: # 生命周期 postStart: # 启动前 exec: command: [\"/bin/sh\", \"-c\", \"echo postStart \u003e /usr/share/message\"] preStart: # 关闭前 exec: command: [\"/bin/sh\", \"-c\", \"echo preStart \u003e /usr/share/message\"] 在进入容器后，就可以看到/usr/share/message存在，并且内容是我们自定义的postStart。我们进去容器死循环打印文件 while true; do cat /usr/share/message; done 在外部关闭容器后，发现打印变成了preStart ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:5","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"6、控制器详解 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"RC 控制器 # file: rc.yaml apiVersion: v1 kind: ReplicationController metadata: name: frontend spec: replicas: 3 # 副本数量 selector: # 标签选择器，寻找 app=nginx 的 Pod app: nginx template: # 创建 Pod 模板 metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 在创建上述文件后，我们执行 kubectl create -f rc.yaml 然后我们查看对应 Pod： 这也就是 RC 控制器的功能，我们可以尝试删除其中一个 Pod 会发现又被重新创建 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"RS 控制器 apiVersion: v1 kind: ReplicaSet metadata: name: frontend spec: replicas: 3 # 副本数量 selector: # 标签选择器，寻找 app=nginx 的 Pod matchLabels: app: nginx1 # matchExpressions: 可选 template: # 创建 Pod 模板 metadata: labels: app: nginx1 spec: containers: - name: nginx image: nginx ports: - containerPort: 80 RS 控制器相比 RC 控制器，只是多了一种标签选择器，我们可以通过下面的命令查看对应的文档： kubectl explain rs.spec.selector 可以看到除了和 RC 控制器功能一致的matchLabels，还多了一种matchExpressions可选择。 matchExpressions目前能支持的操作包括： In：label 的值在某个列表中 NotIn：label 的值不在某一个列表中 Exists：某个 label 存在 DoesNotExist：某个 label 不存在 示例 # selector exists demo apiVersion: v1 kind: ReplicaSet metadata: name: rs-demo spec: selector: matchExpressions: # 这里 - key: app operator: Exists # label 中 key 为 app 存在即可 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 # selector In demo apiVersion: v1 kind: ReplicaSet metadata: name: rs-demo spec: selector: matchExpressions: # 这里 - key: app operator: In # label 中 key 对应的 value 在枚举的 values 中即可 values: - nginx - nginx1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Deployment 控制器 命令的定义方式 命令式定义 kubectl create -f xxxxx 声明式定义 kubectl apply -f xxxxx 区别：声明式命令可以重复使用，系统会自动判断当前操作是修改还是创建 推荐直接使用 apply，在遇到命令式资源时会自动降级成命令式 Deployment 为 Pod 和 ReplicaSet 提供来一个声明式定义方法，用来代替之前的 ReplicationController 来方便管理应用。典型的应用场景包括： 定义 Deployment 来创建 Pod 和 ReplicaSet 滚动升级和回滚应用 扩容和缩容 暂停和继续 Deployment 1、部署一个简单的 Nginx 应用 apiVersion: extensions/v1beta1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 3 template: metadate: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 kubectl apply -f https://kubernetes.io/docs/user-guide/nginx-deployment.yaml --record # --record 可以记录当前命令到 deployment 到历史记录中 2、扩容 # 修改副本数量为 10，不会影响 deployment 已经创建的 rs kubectl scale deployment nginx-deployment --replicas 10 如果集群支持 horizontal pod autoscaling 的话，还可以为 Deployment 设置自动扩展 kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80 3、更新镜像 kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 4、回滚 kubectl rollout undo deployment/nginx-deployment 假如当前有4个版本 v1、v2、v3、v4，目前的版本为 v4，使用上述命令回滚之后回滚到 v3 版本，再次使用上述命令，此时回重新回滚到 v4 版本，因为当前的上一个版本为 v4，如果想指定版本可以使用下述命令： # 查看历史版本记录，如果使用了 --replicas 会显示当时的命令 kubectl rollout history deployment/nginx-deployment # 回滚到指定版本 kubectl rollout undo deployment/nginx-deployment --to-revision=2 # 暂停 deployment 的更新 kubectl rollout pause deployment/nginx-deployment # 可以使用 kubectl rollout status 查看回滚是否完成，同时命令返回 code 为 0，可以使用脚本来判断 kubectl rollout status depoyment/nginx-deployment 限制版本数量 可以设置.spec.revisionHistoryLimit来设置保留的版本数量，这个数量也就是 deployment 管理的历史 rs 数量 多个 rollout 并行 假设当前有 10 个 Pod 正在从 v1 版本升级至 v2 版本，此时 v1 : 5、v2 : 5。 这时我们再升级至 v3 版本，此时升级的 5 个 v2 版本的 Pod 会直接被杀死，然后直接创建 v3 版本的 Pod。 常用回滚策略 一般在企业中不会使用 revision 这种回滚方式，而是会复制最近版本的配置文件，修改名称后直接进行 apply 操作，比如nginx-deployment-2022-06-06 12:00:00.yaml。这样的话出现问题可以直接 apply 至上一个配置文件即可。 5、更新策略 Deployment 可以保证在升级时只有一定数量的 Pod 是 down 的。默认它会确保至少有比期望的副本数量少一个为 up 状态，也就是最多一个不可用 同时也可以确保只创建出超过期望一定数量的 Pod，默认会比期望的副本数量多一个是 up 状态 未来的 kuberentes 版本中，将从 1-1 变成 25%-25% 当然，也支持自定义更新策略 kubectl explain deploy.spec.strategy.type Recreate：重新创建 rollingUpdate：滚动更新（推荐） maxSurge：指定超出副本数有几个，两种方式：1、指定数量 2、百分比 maxUnavailable：指定副本数量最多有几个不可用 # 查询当前更新策略 kubectl describe deployments {控制器名称} # 找到 RollingUpdateStrategy # 修改当前更新策略 kubectl edit deployment {控制器名称} # 找到 rollingUpdate # 或者使用 patch 打补丁 kubectl patch deployment nginx-deployment -p '{\"spec\": {\"strategy\": {\"rollingUpdate\": {\"maxSurge\":1, \"maxUnavailable\": 0}}}}' 6、金丝雀部署 # 需要设置当前更新策略为 maxSurge:1 maxUnavailable:0 kubectl patch deployment nginx-deployment -p '{\"spec\": {\"strategy\": {\"rollingUpdate\": {\"maxSurge\":1, \"maxUnavailable\": 0}}}}' # 开始更新后直接暂停，此时只会新建一个新版本的 Pod，旧版本的 Pod 不会进行删除 # 此时 svc 网络会将流量负载均衡至当前全部 Pod，就可以测试新版本了 kubectl set image deployment nginx-deployment nginx=nginx:1.9.1 \\ \u0026\u0026 kubectl rollout pause deployment nginx-deployment # 等待测试结束后，继续更新 kubectl rollout resume deployment nginx-deployment ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:3","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"DaemonSet DaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 假如集群时，也会为他们新增一个 Pod。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod 使用 DaemonSet 的一些典型用法： 运行集群存储 daemon，例如在每个 Node 上运行glusterd、ceph 在每个 Node 上运行日志收集 daemon，例如fluentd、logstash 在每个 Node 上运行监控 darmon，例如Promentheus Node Exproter、collectd、Datadog代理、New Relic 代理或者Ganglia gmond apiVersion: apps/v1 kind: DaemonSet metadata: name: daemonset-example labels: app: daemonset spec: selector: matchLabels: name: daemonset-example template: metadata: labels: name: daemonset-example spec: containers: - name: daemonset-example image: nginx ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:4","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Job Job 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束 特殊说明 .spec.template格式同 Pod RestartPolicy 仅支持 Never 或者 OnFailure 当个 Pod 时，默认 Pod 运行成功后 Job 即结束 .spec.completions标志 Job 结束需要成功运行的 Pod 个数，默认为 1 .spec.parallelism标志并行运行的 Pod 个数，默认为 1 spec.activeDeadlineSecods标志失败 Pod 的重试最大时间，超过这个时间不会继续重试 apiVersion: batch/v1 kind: Job metadata: name: job spec: template: metadata: name: job spec: containers: - name: job image: busybox command: ['echo', 'this is a job container'] restartPolicy: Never ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:5","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"CronJob CronJob 基于时间管理的 Job，即： 在给定的时间点只运行一次 周期性的在给定时间点运行 使用条件：当前使用 k8s 集群，版本 \u003e= 1.8 典型用法： 在给定的时间点调度 Job 运行 创建周期性运行的 Job，例如：数据库备份、发送邮件 Spec .spec.schedule：调度，必须字段，指定任务运行周期，格式同 Cron .spec.jobTemplate：Job 模板，必须字段，指定需要运行的任务，格式同 Job .spec.startingDeadlineSeconds：启动 Job 的时间（秒），选填，超出该时间未启动认定为失败，默认没有期限 .spce.concurrencyPolicy：并发策略，选填，指定 Job 的并发执行，只允许以下策略： Allow （默认）：允许并发运行 Forbid： 禁止并发运行，如果前一个还没有完成，则跳过 Replace：取消当前正在运行的 Job，用一个新的替换 以上策略只能应用于同一个 CronJob 创建的 Job，如果存在多个 CronJob，它们之间总是互不干涉的 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:6","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"7、Service Kubernetes Service 定义了这样一种抽象： 一个 Pod 的逻辑分组，一种可以访问它们的策略，通常称为 微服务 这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"核心迭代 在 Kubernetes 集群中，每一个 Node 运行一个 kube-proxy进程。kube-proxy 负责为 Service实现一种 VIP（虚拟IP）的形式，而不是ExternalName的形式。在 Kubernetes v1.0 版本，代理完全在 userspace。在 Kubernetes v1.1 版本，增加了 iptables 代理，但并不是默认的运行模式。从 Kubernetes v1.2 起，默认就是 iptables 代理。在 Kubernetes v1.8.0-beta.0 中，添加了 ipvs 代理。在 Kubernetes v1.14 版本开始默认使用 ipvs 代理。 在 Kubernetes v1.0 版本，Service 是 4层（TCP/UDP over IP）概念。在 Kubernetes v1.1 版本，新增了 Ingress API（beta 版），用来表示 7层（HTTP）服务。 1、userspace 代理模式 2、iptables 代理模式 3、ipvs 代理模式 注意：ipvs 模式假定运行 kube-proxy 之前在节点上都已经安装了 IPVS 内核模块。当 kube-proxy以 ipvs 代理模式启动时，kube-proxy 将验证节点是否安装 IPVS 模块，如果未安装，则回退到 iptables 代理模式 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"限制 Service 能够提供负载均衡的能力，但是在使用上有以下限制： 只提供 4 层负载均衡能力，没有 7 层的功能，但有时我们需要更多的匹配规则来转发请求，这点 4 层负载均衡是不支持的 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"类型 ClusterIP：默认类型，自动分配一个仅 Cluster 内部可以访问的虚拟 IP NodePort：在 Cluster Ip 基础上为 Service 在每台机器上绑定一个端口，这样就可以通过 : 来访问服务 LoadBalancer：在 NodePort 的基础上，结束 cloud provider 创建一个外部负载均衡器，并将请求转发到 : ExternalName：把集群外部的服务引入到集群内部来，在集群内部直接使用。没有任何类型代理被创建，这自由 Kubernetes 1.7 或更高版本的 kube-dns 才支持 1、ClusterIP # temp-service.yaml apiVersion: v1 kind: Service metadata: name: myapp namespace: default spec: type: ClusterIP selector: app: myapp relese: stable ports: - name: http port: 80 targetPort: 80 Headless Service apiVersion: v1 kind: Service metadata: name: myapp-headless namespace: default spec: selector: app: myapp clusterIP: \"None\" ports: - port: 80 targetPort: 80 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:3","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":" 此文章为转载，原文章链接动态字段存储方案对比 - 修行编程，沉淀技术，记录生活 - JinTang’s Zone ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:0:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"一、前言 最近在考虑PAAS移动平台的”动态字段存储”问题，简单来说就是前段某页面中的表单动态增加一个编辑框，以某一个新字段的形式提交到后端，后端接口能够在不增加新的表字段且基本不需要修改代码的方式存储起来。 我们都知道，关系型数据库MySQL的数据表在修改表字段时，代价比较大，甚至出现锁表导致服务奔溃。有什么好的办法呢？下面我仍然基于MySQL，对比了两种可行的方法，希望对你有帮助。 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:1:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"二、动态结构 关系数据库非常适合具有大量关系的结构化数据，它所存储的数据都是预先能够定义出清晰的结构，并且短期或更长的时间内结构不会发生变化。但是业务总是不断在变化的，业务在扩展，存储的信息必然更多更广，表结构发生变化几乎是不可避免。 为了解决”动态结构”的问题也有不少轻易能够想到的方法： 列模型：就是常说的”宽表”，为了应对表结构的改变，我们可以在设计表结构的时候，预留多一些空白字段，简单好理解，但是容易造成数据的”稀疏性”，同时长远看来宽表太宽存储性能很差，太窄会满足不了业务变化。 行模型：就是以key-value结构作为一行存储到表中，每增加一个字段就新增一行数据，兼顾灵活性，问题在于value定义类型只能是varchar，大小也需要做限制。 NoSQL：利用NoSQL基于document类型的特性，可以很方便地存储动态结构并且查询效率高，但问题在于业务改造成本大，同时需要ACID事务的场景支持度不够。 还有一种模型，目前在诸如医疗数据库、犯罪数据库和大型电商类数据等有着广泛应用的成熟模型：EAV模型，也即是以”实体-属性-值”来组织数据。 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:2:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"EAV模型 在开源和php社区，最著名的EAV实现是Magento，一个电子商务平台。EAV模型，就是把实体-属性-值（Entity-Attribute-Value）分开表进行存储。实体表存储对象的ID和主要属性，属性表存储需要扩展的属性，值表由不同类型的表组成一个集合，一个值需要由实体ID+属性ID来确定。 为了方便查找某一个实体具备哪些属性，可以增加实体类型（type_id），基于实体的类型，可以通过查找eav_attribute来找到要设置产品的那一属性。当需要操作某一个实体的属性时，就可以先把实体拥有的属性先查出来，再对属性进行操作，设置属性值时，先判断属性的类型是什么，再找到对应类型的值表，然后更新改属性的值。 虽然EAV模型能够解决以上三种模型的缺点，有着灵活性强，完美解决数据稀疏性，但是它也因为太过于复杂，有着明显的学习曲线，查询性能也相对低下，必须为其提升性能做大量的辅助工作。 我的目标是寻找一种动态结构的数据的模型性能可与文档数据库相媲美，结构更简单比EAV更具可读性。那就是MySQL5.7以后支持的JSON类型，也就表字段类型为JSON，用于存储动态扩展字段。 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:2:1","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"JSON模型 JSON模型，比较MySQL5.7以前使用text类型来存文本JSON的方式，JSON模型兼顾了性能及易用性，在操作和性能上都得到很大的提升。JSON类型是以二进制方式存储的，要比字符串更加高效，再也不用json序列化近文本字段，查询之后还要解析，同时还要兼顾json的合法性。 在MySQL 5.7.8中，MySQL支持由RFC 7159定义的本地JSON数据类型，它支持对JSON(JavaScript对象标记)文档中的数据进行有效访问. 有如下几个特性： MySQL会对DML JSON数据自动验证。无效的DML JSON数据操作会产生错误. 优化的存储格式。存储在JSON列中的JSON文档转换为一种内部格式，允许对Json元素进行快速读取访问. MySQL Json类型支持建立索引增加查询性能提升. 另外有还有一种我认为收益比较大的是：虚拟列 Virtual Column 在MySQL 5.7中，支持两种Generated Column，即Virtual Generated Column和Stored Generated Column，前者只将Generated Column保存在数据字典中（表的元数据），并不会将这一列数据持久化到磁盘上；后者会将Generated Column持久化到磁盘上，而不是每次读取的时候计算所得。很明显，后者存放了可以通过已有数据计算而得的数据，需要更多的磁盘空间，与Virtual Column相比并没有优势，因此，MySQL 5.7中，不指定Generated Column的类型，默认是Virtual Column。 有了虚拟列，在select子句和where子句中，查询虚拟列与普通的列没有不同，查询用法上可以基本不需要变化。同时由于虚拟列的特性，只是与json中的属性key的一种映射关系，所以虚拟列的增删性能是非常好的。 另外，在建立了虚拟列之后，可以继续对虚拟列建立索引，可以提升查询性能，有了索引，性能几乎跟普通没有区别。 下面的第五节的模型操作对比中会给出一些JSON操作的实例，更多参考官方文档：https://dev.mysql.com/doc/refman/5.7/en/json.html 下面给出列模型、行模型、EAV模型和JSON模型的优缺点及表结构对比： 由于列模型、行模型和NoSQL都是比较容易理解和常见，所以下文重点只对EAV模型和JSON模型进行分析和对比 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:2:2","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"三、性能测试结果对比 下面是两种模型参与性能测试的SQL，包括查询，更新和插入数据，可以对比观察一下不同模型SQL的复杂度： 下面为SQL在不同量级的数据量时，从查询、更新、插入、建立字段和索引等操作维度，对比了EAV模型、MySQL5.7的JSON模型 和 MySQL8.0的JSON模型 的性能，另外对比了磁盘空间占用和数据导入性能 图表展示，方便查看趋势 结论： 两种模型从操作的复杂度比较，EAV模型要复杂得多，查询不宜联查这么多的表，所以每次都必须分步骤，查询有哪些属性并拿到属性ID（当然可以利用缓存来优化），JSON模型只要有虚拟列，查询时与普通的方式没有却别，插入或更新时需要利用函数； 从查询性能来看，JSON模型明显优于EAV模型。不过虽然这样，EAV只要做好适当的缓存优化，其实是可以满足一定的场景并被接受； 无论在那个数量级下，JSON模型操作虚拟列时的消耗都是极快，而对于给虚拟列添加索引，性能会随着数据量级的增大而增加，毕竟需要建立索引树，也是正常操作了，与普通列的索引差不多； MySQL8.0对JSON类型也做了增强，对比MySQL5.7，在添加/删除索引的性能上，性能提升了接近一倍，虚拟列的操作性能在不同数据量级下，更加稳定； 由于测试用例还是比较粗略，所以不一定100%精准，发现哪里有问题，欢迎指正。 对EAV模型和JSON模型的表结构和增删改查等操作感兴趣的，请看第五节”动态存储模型实际案例” ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:3:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"四、总结 本篇为你介绍了动态结构的场景，并且列举了几个可行的存储模型：列模型（宽表），行模型，EAV模型和JSON模型，并且分析了各种模型的优缺点，通过实际的案例来对比分析了EAV模型和JSON模型，了解了这两种模型的实际操作的SQL语句，展示了不同的数据量级下的查询、插入和更新性能。 经过一番对比，相信你已经面对”动态结构”的场景时候，已经有据可依了，希望对你有帮助。 肝文章不易，点个赞再走。感谢！！ ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:4:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"五、附加：动态存储模型实际案例 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:5:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"1. EAV模型（Entity-Attribute-Value Model） 表结构 属性表 create table `eav_attribute` ( `id` int unsigned not null auto_increment comment '属性ID', `entity_type_id` int unsigned not null default 0 comment '实体类型ID', `attribute_code` varchar(128) not null default '' comment '属性Code', `attribute_name` varchar(128) not null default '' comment '属性名称', `attribute_type` enum ('int', 'varchar', 'text', 'decimal', 'datetime') not null comment '属性类型', primary key (`id`), index `IDX_ENTITY_TYPE_ID` (`entity_type_id`), index `IDX_TYPE` (`attribute_type`) ) engine = innodb charset = utf8mb4 comment 'eav属性表'; 用户实体表 create table `user_entity` ( id int auto_increment primary key comment '用户实体ID', type_id int unsigned not null default 0 comment '实体类型ID', username varchar(32) default '' not null comment '用户名' ) engine = innodb charset = utf8mb4 comment '用户实体表'; 用户整型值表 create table `user_int` ( `entity_id` int unsigned not null comment '实体ID', `attribute_id` int unsigned not null comment '属性ID', `value` int not null default 0 comment '整型值', primary key (`entity_id`, `attribute_id`), index `IDX_VALUE` (`value`) ) engine = innodb charset = utf8mb4 comment 'user整型值表'; 用户字符串值表 create table `user_varchar` ( `entity_id` int unsigned not null comment '实体ID', `attribute_id` int unsigned not null comment '属性ID', `value` varchar(255) not null default '' comment '字符值', primary key (`entity_id`, `attribute_id`), index `IDX_VALUE` (`value`) ) engine = innodb charset = utf8mb4 comment 'user字符值表'; 用户文本值表 create table `user_text` ( `entity_id` int unsigned not null comment '实体ID', `attribute_id` int unsigned not null comment '属性ID', `value` text comment '文本值', primary key (`entity_id`, `attribute_id`) ) engine = innodb charset = utf8mb4 comment 'user文本值表'; 用户浮点型值表 create table `user_decimal` ( `entity_id` int unsigned not null comment '实体ID', `attribute_id` int unsigned not null comment '属性ID', `value` decimal(9, 2) unsigned not null comment '浮点值', primary key (`entity_id`, `attribute_id`), index `IDX_VALUE` (`value`) ) engine = innodb charset = utf8mb4 comment 'user浮点值表'; 用户日期型值表 create table `user_datetime` ( `entity_id` int unsigned not null comment '实体ID', `attribute_id` int unsigned not null comment '属性ID', `value` datetime not null comment '日期值', primary key (`entity_id`, `attribute_id`), index `IDX_VALUE` (`value`) ) engine = innodb charset = utf8mb4 comment 'user日期值表'; 插入属性数据 INSERT INTO `eav_attribute` (id, entity_type_id, attribute_code, attribute_name, attribute_type) VALUES (1, 1, 'name', '姓名', 'varchar'), (2, 1, 'age', '年龄', 'int'), (3, 1, 'gender', '性别', 'varchar'), (4, 1, 'phone', '电话', 'varchar'), (5, 1, 'mobile', '移动电话', 'varchar'), (6, 1, 'address', '家庭住址', 'varchar'), (7, 1, 'height', '身高(cm)', 'decimal'), (8, 1, 'weight', '体重(kg)', 'decimal'), (9, 1, 'profile', '简介', 'text'), (10, 1, 'birthday', '出生年月', 'datetime'); ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:5:1","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"2. JSON模型 表结构 用户表 create table `user` ( `id` int unsigned not null auto_increment comment '用户ID', `username` varchar(32) not null default '' comment '账号', primary key(`id`) ) engine = innodb charset = utf8mb4 comment '用户主表'; 用户源数据表 create table `user_metadata` ( `id` int unsigned not null auto_increment comment '用户元数据', `field_code` varchar(32) not null default '' comment '字段code', `field_name` varchar(32) not null default '' comment '字段名', `field_type` varchar(32) not null default '' comment '字段类型', primary key(`id`), index `IDX_FIELD` (`field_name`, `field_type`) ) engine = innodb charset = utf8mb4 comment '用户元数据表'; 用户扩展字段表 create table `user_extra_field` ( `id` int unsigned not null auto_increment comment '字段id', `user_id` int unsigned not null default 0 comment '用户ID', `properties` json default null comment '扩展字段', primary key(`id`), index `IDX_USER_ID` (`user_id`) ) engine = innodb charset = utf8mb4 comment '用户扩展字段表'; 元数据 insert into `user_metadata` (id, field_code, field_name, field_type) VALUES (1, 'name', '姓名', 'varchar'), (2, 'age', '年龄', 'int'), (3, 'gender', '性别', 'varchar'), (4, 'phone', '电话', 'varchar'), (5, 'mobile', '移动电话', 'varchar'), (6, 'address', '家庭住址', 'varchar'), (7, 'height', '身高(cm)', 'decimal'), (8, 'weight', '体重(kg)', 'decimal'), (9, 'profile', '简介', 'text'), (10,'birthday', '出生年月', 'datetime'); 说明：由于json类型里的数据类型也是只有字符串、数字、对象（JSON 对象）、数组、布尔和Null，所以使用元数据表把属性的具体类型存储起来，可以在必要时可以在代码层做类型转换逻辑。 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:5:2","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"模型操作对比 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:6:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"1. 字段操作 增加一个”edu”学历字段 EAV模型 只需要在属性表eav_attribute中增加一行即可 insert into eav_attribute (entity_type_id, attribute_code, attribute_name, attribute_type) values (1, 'edu', '学历', 'varchar'); JSON 需要在元数据表user_metadata增加一行，并且增加虚拟列edu以及其索引 alter table user_extra_field add column `edu` varchar(32) GENERATED ALWAYS AS (json_extract(`properties`,'$.edu')) VIRTUAL; alter table user_extra_field add index `IDX_EDU` (`edu`); 删除mobile字段 EAV模型 需要三步： 查询mobile属性 删除属性记录 删除属性值 -- step1: 查询属性信息 select * from eav_attribute where entity_type_id = 1; -- step2: 删除字段 delete from eav_attribute where id = 5; -- step3: 删除值 delete from user_varchar where attribute_id = 5; JSON模型 利用json_remove()方法，可以直接删除json字段对应的属性 -- step1: 删除字段 delete from user_metadata where field_code = 'mobile'; -- step2: 删除值 update user_extra_field set properties = json_remove(properties, '$.mobile'); -- step3: 删除虚拟列 alter table user_extra_field drop column `mobile`; 注意，第2、3步可以根据业务自身考虑是否有必要，为了节省空间，那些确定不再使用的属性字段可以考虑删除，缩小json体积。 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:6:1","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"2. 查询操作 查询身高高于170cm，年满18岁的男性用户 EAV模型 需要分三步进行查询，每一步的结果传递需要代码逻辑层实现，此处直接贴出所有的查询SQL -- step1: 查询所有属性 select * from eav_attribute where entity_type_id = 1; -- step2: 根据条件过滤出用户ID select i.entity_id from user_int as i join user_varchar as v on i.entity_id = v.entity_id and v.value = '男' and v.attribute_id = 3 join user_decimal as d on v.entity_id = d.entity_id and d.value \u003e 170 and d.attribute_id = 7 where i.attribute_id = 2 and i.value \u003e 18; -- step3: 根据用户ID与属性，查询满足条件的实体信息 select entity_id as id, `value`, a.attribute_code from ( select entity_id, `value`, attribute_id from user_int where attribute_id = 2 and entity_id in (1,3,4,6,10,13,17,18) union all select entity_id, `value`, attribute_id from user_varchar where attribute_id in (1, 3) and entity_id in (1,3,4,6,10,13,17,18) union all select entity_id, `value`, attribute_id from user_datetime where attribute_id = 10 and entity_id in (1,3,4,6,10,13,17,18) union all select entity_id, `value`, attribute_id from user_decimal where attribute_id = 7 and entity_id in (1,3,4,6,10,13,17,18) ) as s join eav_attribute as a on s.attribute_id = a.id; 注意：查出来的结果，还需要进行key-value的转换 JSON模型 select u.id, json_unquote(f.properties -\u003e '$.name') as name, json_unquote(f.properties -\u003e '$.gender') as gender, f.properties -\u003e '$.height' as height, json_unquote(f.properties -\u003e '$.birthday') as birthday from user as u join user_extra_field as f on u.id = f.user_id and f.properties -\u003e '$.age' \u003e 18 and f.properties -\u003e '$.height' \u003e 170 and f.properties -\u003e '$.gender' = '男' 在建立了虚拟列的前提下，查询与传统的方式没有区别 select u.id,f.name,f.gender,f.height, f.birthday from user as u join user_extra_field as f on u.id = f.user_id and f.age \u003e 18 and f.height \u003e 170 and f.gender = '男' 查询用户详情：查询用户ID为3的用户信息 EAV模型 需要分两步：1. 查询所有的属性，2.根据属性ID和用户ID，查询属性值 -- step1: 查询所有属性 select * from eav_attribute where entity_type_id = 1; -- step2: 根据属性及id，查询id为3的用户信息 select entity_id as id, `value`, a.attribute_code from ( select entity_id, `value`, attribute_id from user_int where attribute_id = 2 and entity_id = 3 union all select entity_id, `value`, attribute_id from user_varchar where attribute_id in (1,3,4,5,6) and entity_id = 3 union all select entity_id, `value`, attribute_id from user_decimal where attribute_id in (7, 8) and entity_id = 3 union all select entity_id, `value`, attribute_id from user_text where attribute_id = 9 and entity_id = 3 union all select entity_id, `value`, attribute_id from user_datetime where attribute_id = 10 and entity_id = 3 ) as s join eav_attribute as a on s.attribute_id = a.id JSON模型 select u.id, u.username, f.properties from user as u join user_extra_field as f on u.id = f.user_id where u.id = 3; ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:6:2","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"3. 插入数据 新增一条数据 insert into user (id, username, name, age, gender, phone, address, profile, birthday) values (20, 'jayzone', '张三', 22, '男', '13722211133', '广东省深圳市宝安区西乡街道华泰大厦101', '我很好，你呢？', '1994-01-11'); EAV模型 分两步操作: 1.查询所有属性，2.根据属性ID和值，插入到对应的表中 -- step1: 查询所有属性 select * from eav_attribute where entity_type_id = 1; -- step2: 把值插入到对应的表 insert into user_entity (id, username, type_id) values (20, 'jayzone', 1); insert into user_int (entity_id, attribute_id, value) values (20, 2, 22); insert into user_varchar (entity_id, attribute_id, value) values (20, 1, '张三'), (20, 3, '男'), (20, 4, '13722211133'), (20, 6, '广东省深圳市宝安区西乡街道华泰大厦101'); insert into user_text (entity_id, attribute_id, value) values (20, 9, '我很好，你呢？'); insert into user_datetime (entity_id, attribute_id, value) values (20, 10, '1994-01-11 00:00:00'); JSON模型 需要使用**json_object()**方法构建json对象，在存入JSON字段中 insert into user (id, username) values (20, 'jayzone'); insert into user_extra_field (user_id, properties) values (20, json_object('name', '张三', 'age', 22, 'gender', '男', 'phone', '13722211133', 'address', '广东省深圳市宝安区西乡街道华泰大厦101', 'profile', '我很好,你呢？', 'birthday', '1994-01-11')); ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:6:3","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"4. 更新数据 新增一个字段, 并且更新用户ID=3的用户学历为本科 EAV模型 需要在eav_attribute表中增加一行记录，然后更新对应的值 -- step1: 查询属性 select * from eav_attribute where entity_type_id = 1; -- step2: 更新对应属性的值 update user_varchar set value = '本科' where entity_id = 3 and attribute_id = 11; JSON模型 利用json_insert/json_set方法更新对应字段的值 update user_extra_field set properties = json_set(properties, '$.phone', '15016716555') where id = 3; ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:6:4","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"1、卸载旧版本 sudo apt remove docker docker-engine docker.io containerd runc ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:1","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"2、安装相关依赖包 sudo apt update \u0026\u0026 sudo apt install -y apt-transport-https ca-certificates curl gnupg lsb-release ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:2","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"3、添加证书\u0026镜像 官方镜像 # 官方镜像 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # 如果你使用的是 Ubuntu 22.04 请使用 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/aliyun-docker-archive-keyring.gpg sudo add-apt-repository \"deb [arch=arm64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" 阿里云镜像 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - # 如果你使用的是 Ubuntu 22.04 请使用 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg ｜ sudo gpg --dearmor -o /usr/share/keyrings/aliyun-docker-archive-keyring.gpg sudo add-apt-repository \"deb [arch=arm64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\" 如果卡住不动的话，可以先 wget 下载文件，直接导入 wget http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg sudo apt-key add ./gpg ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:3","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"4、安装 sudo apt update \u0026\u0026 sudo apt install -y containerd ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:4","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"5、生成配置文件 mkdir -p /etc/containerd \u0026\u0026 containerd config default | sudo tee /etc/containerd/config.toml # 修改配置文件 # 老版本需要手动添加 `SystemdCgroup = true` sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml \u0026\u0026 grep 'SystemdCgroup' -B 11 /etc/containerd/config.toml ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:5","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"6、配置镜像加速官方链接 # 这里需要替换为自己阿里云的镜像加速器地址 sudo sed -i 's#endpoint = \"\"#endpoint = \"https://xxxxxx.mirror.aliyuncs.com\"#g' /etc/containerd/config.toml \u0026\u0026 grep 'endpoin' -B 5 /etc/containerd/config.toml sed -i 's#sandbox_image = \"k8s.gcr.io/pause#sandbox_image = \"registry.aliyuncs.com/google_containers/pause#g' /etc/containerd/config.toml \u0026\u0026 grep 'sandbox_image' /etc/containerd/config.toml ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:6","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"7、重载服务器配置 systemctl daemon-reload \u0026\u0026 systemctl restart containerd.service ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:7","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"8、检查运行情况 systemctl status containerd ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:8","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"1、卸载可能存在的旧版本 sudo apt remove docker docker-engine docker-ce docker.io ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:1","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"2、安装依赖使 apt 可通过 HTTPS 下载包 sudo apt update \u0026\u0026 apt install -y apt-transport-https ca-certificates curl software-properties-common ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:2","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"3、添加 docker 密钥 3.1、阿里云 docker 源 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 3.2、官方 docker 源 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:3","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"4、添加对应的 docker 源「需要和第三部一致」 4.1、阿里云 「官方文档」 sudo add-apt-repository \"deb [arch=arm64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\" 4.2、官方源 sudo add-apt-repository \"deb [arch=arm64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" $(lsb_release -cs)是获取当前 Ubuntu 代号 如果没有科学上网手段，推荐使用阿里云源 ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:4","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"5、安装 docker sudo apt update \u0026\u0026 apt install -y docker-ce ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:5","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"6、配置镜像仓库 mkdir /etc/docker cat \u003e /etc/docker/daemon.json \u003c\u003c EOF { \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"100m\" }, \"registry-mirrors\": [\"https://xxx.mirror.aliyuncs.com\"] } EOF # 设置完成后重启 sudo systemctl daemon-reload sudo systemctl restart docker ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:6","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"7、验证安装 systemstl status docker 正常运行则会显示 ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:7","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"在 Hugo 的配置文件中添加一行 hasCJKLanguage = true # 字数统计添加中文支持 重新编译即可 ","date":"2022-05-11","objectID":"/%E8%A7%A3%E5%86%B3hugo%E5%AD%97%E6%95%B0%E7%BB%9F%E8%AE%A1%E4%B8%8D%E6%AD%A3%E7%A1%AE/:0:0","tags":["Hugo"],"title":"解决Hugo字数统计不正确","uri":"/%E8%A7%A3%E5%86%B3hugo%E5%AD%97%E6%95%B0%E7%BB%9F%E8%AE%A1%E4%B8%8D%E6%AD%A3%E7%A1%AE/"},{"categories":null,"content":"问题 Typora 可以方便的将文件保存在本地，但是不合理的设置将无法适应各种静态博客生成工具（比如：hugo）的图片存储方式，所以要对 Typora 进行设置。 ","date":"2022-05-11","objectID":"/%E5%A6%82%E4%BD%95%E5%9C%A8hugo%E5%92%8Ctypora%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87/:0:1","tags":["Typora","image"],"title":"如何在Hugo和Typora中显示图片","uri":"/%E5%A6%82%E4%BD%95%E5%9C%A8hugo%E5%92%8Ctypora%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87/"},{"categories":null,"content":"目标 hugo 的默认图片路径为 ${site}/static/images目录，所以我们需要配置 Typora 的图片默认复制到整个目录。并且达到在网站和 Typora 中同时可查看。 ","date":"2022-05-11","objectID":"/%E5%A6%82%E4%BD%95%E5%9C%A8hugo%E5%92%8Ctypora%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87/:0:2","tags":["Typora","image"],"title":"如何在Hugo和Typora中显示图片","uri":"/%E5%A6%82%E4%BD%95%E5%9C%A8hugo%E5%92%8Ctypora%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87/"},{"categories":null,"content":"解决 对于 Typora 图片的默认复制路径可以直接进行配置，如下图所示： 也可以再加上 static/images/${filename}/，这样可以更加方便的管理图片。 但是这样配置完会发现，Hugo 读取图片的条件满足了，Typora 预览没法满足，在设置里我们也找到调整的位置。 其实 Typora 有一个隐藏的配置，格式( Format ) -\u003e 图像( Image ) -\u003e 设置图片根目录( Use Image Root Path )，具体可以依据下图。 配置是在当个 md 文件中生效的，在设置后在文件的开头会添加上typora-root-url: ../../../static/，也就是具体的原理了。 ","date":"2022-05-11","objectID":"/%E5%A6%82%E4%BD%95%E5%9C%A8hugo%E5%92%8Ctypora%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87/:0:3","tags":["Typora","image"],"title":"如何在Hugo和Typora中显示图片","uri":"/%E5%A6%82%E4%BD%95%E5%9C%A8hugo%E5%92%8Ctypora%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87/"},{"categories":null,"content":"常用命令 rustc rustc xxx.rs // 编译Rust程序 cargo cargo build // 编译Rust项目，如block在更新lock文件，可执行 rm -rf ~/.cargo/.package-cache cargo run // 立刻运行Rust项目 cargo doc –open // 生成并打开项目文档 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:1:0","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"常见概念 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:0","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"变量和可变性 使用let xxx 声明一个变量，此时这个变量是不可变的，但是可以被隐藏 使用let mut xxx 声明一个可变变量，此时变量可以被重新赋值 使用const XXX声明一个常量，常量不可被重新赋值 隐藏 ​ 重复使用let定义一个与之前变量同名的变量，我们称第一个变量被第二个变量隐藏了，此时使用该名称的变量会使用第二个变量，我们可以重复使用let来多次隐藏。 fn main() { let x = 5; let x = x + 1; { let x = x * 2; println!(\"block inner x:{}\", x); } println!(\"block outer x:{}\", x); } 上面例子会输出： block inner x:12 block outer x:6 ​ 这个程序首先将 x 绑定到值 5 上。接着通过 let x = 隐藏 x，获取初始值并加 1，这样 x 的值就变成 6 了。然后，在内部作用域内，第三个 let 语句也隐藏了 x，将之前的值乘以 2，x 得到的值是 12。当该作用域结束时，内部 shadowing 的作用域也结束了，x 又返回到 6。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:1","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"数据类型 标量类型 整型 长度 有符号 无符号 8-bit i8 u8 16-bit i16 u16 32-bit i32 u32 64-bit i64 u64 128-bit i128 u128 arch isize usize 浮点型 ​ Rust 的浮点数类型是 f32 和 f64，分别占 32 位和 64 位。默认类型是 f64 布尔型 ​ Rust 中的布尔类型有两个可能的值：true 和 false。Rust 中的布尔类型使用 bool 表示。 字符型 ​ Rust 的 char 类型的大小为四个字节(four bytes)，并代表了一个 Unicode 标量值（意味着你可以使用emoji）。 复合类型 元组类型 相当于把一个或者多个类型的值组合成一个类型。元组的长度是固定的：一旦声明。其长度不会改变。 我们可以使用圆括号中逗号分割的值列表来创建一个元组。 fn main() { let one: (i32, f64, u8) = (500, 6.4 ,1); let one = (500, 6.4 ,1); } 同时可以对元组进行解构，或者只用点号（.）跟着值的索引（从0开始）直接访问 fn main() { let one = (500, 6.4 ,1); let (x, y, z) = one; println(\"x:{} y:{} z:{}\",x, y, z); println(\"x:{} y:{} z:{}\",one.0, one.1, one.2); } 数组类型 另一个包含多个值的方式是 数组（array）。与元组不同，数组中的每个元素的类型必须相同。Rust 中的数组与一些其他语言中的数组不同，因为 Rust 中的数组是固定长度的：一旦声明，它们的长度不能增长或缩小。 可以使用以下两种方式来声明数组： fn main() { let a = [1, 2, 3, 4, 5]; // 当你想定义类型或者长度时可使用下面这种方式 // 在方括号中包含每个元素的类型，后跟分号，再后跟数组元素的数量 let a: [i64; 5] = [1, 2, 3, 4, 5]; } ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:2","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"函数 Rust 中的函数定义以 fn 开始并在函数名后跟一对圆括号。大括号告诉编译器哪里是函数体的开始和结尾。 在函数签名中，必须 声明每个参数的类型。这是 Rust 设计中一个经过慎重考虑的决定：要求在函数定义中提供类型注解，意味着编译器不需要你在代码的其他地方注明类型来指出你的意图。在有多个参数时，使用,来分割多个参数。 函数可以向调用它的代码返回值。使用（-\u003e）后声明它的类型。在 Rust 中，函数的返回值等同于函数体最后一个表达式的值。使用 return 关键字和指定值，可从函数中提前返回；但大部分函数隐式的返回最后的表达式。 fn five() -\u003e i32 { 5 } fn four() -\u003e i32 { let a = 4; return a; } fn main() { let x = five(); println!(\"The value of x is: {}\", x); } 语句和表达式 Rust是一门基于表达式（expression-based）的语言。 使用let关键字创建变量并绑定一个值是一个语句（let y = 6;）。 语句不返回值。不能把let语句赋值给另外一个变量（let x = (let y = 6)）。 表达式可以计算出一个值，考虑一个数学运算，比如5+6，这是一个表达式并计算出值11。表达式可以是语句的一部分。函数调用是一个表达式。宏调用是一个表达式。我们用来创建新作用于的大括号（代码块），{}，也是一个表达式。 fn main() { let x = 5; let y = { let x = 3; x + 1 } println!(\"x:{} y:{}\") } 这个表达式： { let x = 3; x + 1 } 是一个代码块，它的值是 4。这个值作为 let 语句的一部分被绑定到 y 上。注意结尾没有分号的那一行 x+1，与你见过的大部分代码行不同。表达式的结尾没有分号。如果在表达式的结尾加上分号，它就变成了语句，而语句不会返回值。在接下来探索具有返回值的函数和表达式时要谨记这一点。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:3","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"控制流 if表达式 if 表达式允许根据条件执行不同的代码分支。你提供一个条件并表示 “如果条件满足，运行这段代码；如果条件不满足，不运行这段代码。” fn main() { let number = 3; if number \u003c 5 { // xxx } else { // yyy } } 代码中的条件必须是bool值。如果不是bool值，我们会得到一个错误。 因为if是一个表达式，所以我们可以在let语句的右侧使用它。注意，if和else分支的结果都必须是相同类型 fn main() { let conditioin = true; let number = if condition { 5 } else { 6 }; println!(\"number:{}\", number); } ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:4","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"循环 Rust 中有三种循环：loop、while和for。 loop表达式 loop就是一个无限循环，需要显式的调用break来退出这个循环。 如果存在嵌套循环，此时单独只用break 和 continue只应用于此时语句最内层的循环。可以在循环上指定一个循环标签，然后将标签与break 和 continue一起使用，此时这些关键字生效的则是已标记的循环。 fn main() { let mut count = 0; 'counting_up: loop { let mut remaining = 10; loop { println!(\"remaining = {}\", remaining); if remaining == 9 { break; } if count == 2 { break 'counting_up; } remaining -= 1; } count += 1; } println!(\"End count = {}\", count); } loop的另外一个用法是重试可能会失败的操作，比如检查线程是否完成了任务。如果将返回值加入你用来停止循环的break表达式，它会被停止的循环返回。 fn main() { let mut counter = 0; let result = loop { counter += 1; if counter == 10 { break counter * 2; } }; println!(\"The result is {}\", result); } while条件循环 当条件为真，执行循环。当条件不再为真，则停止循环。这个循环类型可以通过组合 loop、if、else 和 break 来实现。或者直接使用while。 fn main() { let mut number = 3; while number != 0 { println!(\"{}!\", number); number = number - 1; } println!(\"LIFTOFF!!!\"); } for遍历集合 可以使用 for 循环来对一个集合的每个元素执行一些代码。 fn main() { let a = [10, 20, 30, 40, 50]; for element in a.iter() { println!(\"the value is: {}\", element); } } Rust的循环不像“C风格”的循环 for (x = 0; x \u003c 10; x++) { printf(\"%d\\n\", x); } 相反，Rust是这样的 for x in 0..10 { println!(\"{}\", x); } // 当你需要 x \u003c= 10 这种类型的时候 for x in 0..=10 { println!(\"{}\", x); } 当你需要知道当前已经循环多少次时，可以使用.enumerate()函数 for (i,j) in (5..10).enumerate() { println!(\"i = {} and j = {}\", i, j); } 输出： i = 0 and j = 5 i = 1 and j = 6 i = 2 and j = 7 i = 3 and j = 8 i = 4 and j = 9 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:5","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"所有权 首先，让我们看一下所有权的规则。当我们通过举例说明时，请谨记这些规则： Rust 中的每一个值都有一个被称为其 所有者（owner）的变量。 值在任一时刻有且只有一个所有者。 当所有者（变量）离开作用域，这个值将被丢弃。 变量作用域 变量 s 绑定到了一个字符串字面值，这个字符串值是硬编码进程序代码中的。这个变量从声明的点开始直到当前 作用域 结束时都是有效的。示例 4-1 的注释标明了变量 s 在何处是有效的。 { // s 在这里无效, 它尚未声明 let s = \"hello\"; // 从此处起，s 是有效的 // 使用 s } // 此作用域已结束，s 不再有效 内存与分配 首先我们要知道变量的两种内存分配位置：堆和栈。这个概念再此不做赘述。 当我们声明一个变量的类型，它的内存分配在堆上，我这习惯将其成为引用类型，如果它的内存分配在栈上，则称为值类型。 值类型，如i32、f64。引用类型，如string： fn main() { let x = 1;// i32 值类型 let str = String::from(\"hello world!\");// string 引用类型 } 值类型的传递方式都是copy fn main() { let x = 1; let y = x; } 此时 x、y都在栈上拥有属于自己的内存空间。 而引用类型的传递方式则不一样。 fn main() { let x = String::from(\"hello world!\");// x 获得 string 的所有权 let y = x;// string 的所有权交给了 y // 此时 x 与 y 的地址共同指向堆的同一个地方 // 我们只拷贝了其长度和容量信息，其在堆上的指针是相同的 // 如果想拷贝其在堆上的数据 let z = y.clone();// z clone 了一个 y，没有获得 string 的所有权 // 此时则是 z 与 y 是地址完全不同的两个变量 // 如果我们在这使用 let z = x.clone() 则对得到一个错误，因为Rust禁止你使用无效的引用 } 那如果是在函数里呢？ fn main() { let str = String::from(\"hello world!\");// str 进入作用域 test_one(str);// str 所有权移动到函数内 // str再此不在有效 let x = 12;// x 进入作用域 test_two(x);// x copy 进入函数内 // x 是copy的,所以 x 在此依然有效 }// x移除作用域。 str 所有权已经移交，不做操作 fn test_one(some_string: String) {// some_string 进入作用域 println!(\"{}\", some_string); }// some_string 离开作用域，调用 `drop` 方法释放内存 fn test_two(some_integer: i32) {// some_integer 进入作用域 println!(\"{}\", some_integer); }// some_integer 离开作用域，不会有特殊操作 函数的返回值也可以转移所有权。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:6","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"引用与借用 规则 在任意给定时间，要么 只能有一个可变引用，要么 只能有多个不可变引用。 引用必须总是有效的。 如果我们只是想使用一个变量，而不是获取这个变量的所有权。我们则需要使用引用这个操作。 fn main() { let s1 = String::from(\"hello\"); let len = calculate_length(\u0026s1); println!(\"The length of '{}' is {}.\", s1, len); } fn calculate_length(s: \u0026String) -\u003e usize { s.len() } 我们在这里获得的是s1的引用，并没有获取s1的所有权。所以上述代码可以正常的运行。 使用的\u0026符号就是引用，它允许你使用值但不获取其所有权。就像其他语言类似，获取一个变量的地址，也就是指针。 因为没有获取到所有权，所以当引用离开作用域时，不会将内存释放。但是这里的引用只能使用被引用的变量，当我们想修改这个变量时，则会发现会抛出一个错误。正如变量默认不可变一样，引用默认也是不可改变的。 fn main() { let s = String::from(\"hello\"); change(\u0026s); } fn change(some_string: \u0026String) { some_string.push_str(\", world\"); } error[E0596]: cannot borrow immutable borrowed content `*some_string` as mutable --\u003e error.rs:8:5 | 7 | fn change(some_string: \u0026String) { | ------- use `\u0026mut String` here to make mutable 8 | some_string.push_str(\", world\"); | ^^^^^^^^^^^ cannot borrow as mutable 如果我们想修改一个引用的值，我们只需做一个小调整： fn main() { let mut s = String::from(\"hello\"); change(\u0026mut s); } fn change(some_string: \u0026mut String) { some_string.push_str(\", world\"); } 这里使用\u0026mut获取到的是 s的可变引用，这就清除的表明，我需要修改这个引用的值。不过可变引用有一个很大的限制。 在同一时间只能有一个对某一特定数据的可变引用 这个限制的好处是 Rust 可以在编译时就避免数据竞争。 不可变引用可以存在多个，但不能同时与可变引用存在。原因也很明显，谁也不想自己引用的变量在某一时间被修改。 这种概念和读写锁类似。可以拥有多个读锁（不可变引用），只能存在一个写锁并与读锁互斥（可变引用）。当了解这个概念之后就很好理解了。 注意一个引用的作用域从声明的地方开始一直持续到最后一次使用为止。例如以下代码是可以编译的： let mut s = String::from(\"hello\"); let r1 = \u0026s; // 没问题 let r2 = \u0026s; // 没问题 println!(\"{} and {}\", r1, r2); // 此位置之后 r1 和 r2 不再使用，作用域也再此结束 let r3 = \u0026mut s; // 没问题 r1，r2的作用域已经结束 println!(\"{}\", r3); 不可变引用 r1 和 r2 的作用域在 println! 最后一次使用之后结束，这也是创建可变引用 r3 的地方。它们的作用域没有重叠，所以代码是可以编译的。编译器在作用域结束之前判断不再使用的引用的能力被称为非词法作用域生命周期（Non-Lexical Lifetimes，简称NLL）。你可以在 The Edition Guide 中阅读更多关于它的信息。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:7","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"结构体 定义结构体，需要使用 struct 关键字并为整个结构体提供一个名字。结构体的名字需要描述它所组合的数据的意义。接着，在大括号中，定义每一部分数据的名字和类型，我们称为 字段（field）。例如，示例 5-1 展示了一个存储用户账号信息的结构体： struct User { username: String, email: String, sign_in_count: u64, active: bool, } 当变量名与字段名相同时，可以简写 fn build_user(email: String, username: String) -\u003e User { User { email, username, active: true, sign_in_count: 1, } } 我们还可以使用结构体更新语法 let user2 = User { email: String::from(\"another@example.com\"), ..user1 }; 在这里..user1必须放在最后，其他字段实际是使用=的赋值，所以要注意所有权的移动。 我们还可以创建没有字段的元组结构体，使用.接上索引来访问单独的值。 struct Color(i32, i32, i32); struct Point(i32, i32, i32); let black = Color(0, 0, 0); let origin = Point(0, 0, 0); 或者创建一个没有任何字段的结构体（类单元结构体） 单元结构体常常在你想要在某个类型上实现 trait 但不需要在类型中存储数据的时候发挥作用。 struct AlwaysEqual; let subject = AlwaysEqual; todo 字段的生命周期 打印结构体 #[derive(Debug)] struct Rectangle { width: u32, height: u32, } fn main() { let rect1 = Rectangle { width: 30, height: 50 }; println!(\"{:#?}\", rect1); println!(\"{:#?}\", rect1); dbg!(\u0026rect1); } 分别输出： Rectangle { width: 30, height: 30, } Rectangle { width: 30, height: 30, } [src/main.rs:15] \u0026rect1 = Rectangle { width: 30, height: 30, } 给struct绑定方法 定义方法 #[derive(Debug)] struct Rectangle { width: u32, height: u32, } impl Rectangle { fn area(\u0026self) -\u003e u32 { self.width * self.height } } fn main() { let rect1 = Rectangle { width: 30, height: 30, }; println!(\"这个长方体的面积是：{}\", rect1.area()); } 为了使函数定义在Rectangle的上下文中，我们定义了一个impl块。在这个块中的所有内容都与Rectangle相关联。 在area的函数前面上，使用\u0026self来代替rectangle: \u0026Rectangle，\u0026self其实是self: \u0026Self的缩写。在一个impl块中，方法的第一个参数必须有一个名为self的Self类型的参数，所以Rust在这里提供了self这个名字来缩写，在这里我们使用\u0026来表示只是借用这个示例，并没有获取所有权。同时，我们也一样可以获取所有权，或者可变借用。 那我们的\u0026运算符去哪里了呢？ area()函数的参数是\u0026self，但是我们调用的地方并没有借用rect1；那是Rust有一个叫做自动引用和解引用的功能。方法调用是Rust中少数几个拥有这种行为的地方。 这样我们的代码实际是这样工作的： rect1.area(); (\u0026rect1).area(); 这样看起来第一种方式简洁的多。 关联函数 所有在impl块中定义的函数被称为关联函数。我们可以定义一个不以self为第一参数的关联函数（它不是方法），我们已经使用过这样的函数了，String::from()。通常这样的函数被我们用作为返回一个结构体新实例的构造函数。 impl Rectangle { fn square(size: u32) -\u003e Rectangle { Rectangle { width: size, height: size } } } fn main() { let sq = Rectangle::square(3); } ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:8","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"枚举 在 Rust 中我们使用enum来定义一个枚举类型。 enum IpAddrKind { V4, V6, } 在上述代码中定义了一个IpAddrKind枚举来列出可能的 IP 地址类型，V4和V6。这两种类型被称为枚举的成员。 我们可以像这样创建IpAddrKind两个不同成员的实例。 let four = IpAddrKind::V4; let six = IpAddrKind::V6; fn route(ip_type: IpAddrKind) {} route(four); route(six); 可以看到我们可以使用任意成员来调用route函数。 枚举的成员也可以关联一个值。 enum IpAddr { V4(String), V6(String), } let home = IpAddr::V4(String::from(\"127.0.0.1\")); let loopback = IpAddr::V4(String::from(\"::1\")); 或者关联上一个元组。 enum IpAddr { V4(u8, u8, u8, u8), V6(String), } let home = IpAddr::V4(127, 0, 0, 1); let loopback = IpAddr::V4(String::from(\"::1\")); 我们还可以对枚举类型关联上方法。 impl IpAddr { fn call(\u0026self) { dbg!(self) } } 我们就可以直接使用home.call()来调用这个方法。 todo option ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:9","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"相关控制流运算符 match运算符 如果有其他语言基础的话，看到match这个关键字，应该能联想到switch。它的用法和switch是差不多的，只是有一些细节不同。这里我们用上面的IpAddr绑定的方法call举例： fn call(\u0026self) { match self { IpAddr::V4(a, b, c, d) =\u003e println!(\"{}:{}:{}:{}\", a, b, c, d), IpAddr::V6(str) =\u003e println!(\"{}\", str), } } 可以看到，我们使用了match匹配了self这个变量，在 case 里我们用上了IpAddr::V4(a, b, c, d)，使用了a b c d四个变量来分别匹配绑定上的V4(u8, u8, u8, u8)4个值。而在IpAddr::V6(str)使用了str来接收绑定的String这样我们就可以根据不同的类型在做出不同的操作了。 但是注意 Rust 默认需要我们处理match后变量的所有可能情况，也就是说，下述代码是不正确的： fn call(\u0026self) { match self { IpAddr::V4(a, b, c, d) =\u003e println!(\"{}:{}:{}:{}\", a, b, c, d), } } Rust 会提示我们少了IpAddr::V6的case。 上述例子只有2种情况，那如果是10种？20种呢？如果真的全部都要列出来的话，那未免太蠢了。所以 Rust 和其他语言一样，提供了类似default的功能，使用的关键字是_，我们来看看例子。 fn call(\u0026self) { match self { IpAddr::V4(a, b, c, d) =\u003e println!(\"{}:{}:{}:{}\", a, b, c, d), _ =\u003e (), } } 注意必须要显式调用_ =\u003e () Rust不会默认给你加上。这样的话就可以忽略掉V6的匹配了。 if let简单控制流 想上面的例子，只有2种情况，我们还需要显式的用_去忽略匹配，实在是过于冗长，所以 Rust给了我们另外一种方式来处理这种情况。 fn call(\u0026self) { if let IpAddr::V4(a, b, c, d) = self { println!(\"{}:{}:{}:{}\", a, b, c, d); } } 这样我们就不用再用那么冗长的方式来编写了。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:10","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"package / crate / module cargo new会生成项目的雏形，提供了 src/main.rshe src/lib.rs文件，随着项目复杂度的增长，代码量也会随之增长，如果靠一个文件来维护一大堆代码，肯定是不合适的。一般都会使用模块来拆分文件。 在这里学习一下rust中代码的组织方式，主要涉及到一下几个名词： package：Cargo中的概念，用于管理crate crate：模块的集合，编译单位，有bin和lib两种，分别是可执行文件，和供他人调用 module：用户在crate内组织代码 workspace：项目复杂时，管理多个package package 使用cargo new命令会创建一个新项目，也就是一个package，里面带有一个Cargo.toml文件，用于定义package、所需外部依赖，以及如何编译crate等 crate Rust里有两种crate，lib类型和bin类型，并且默认以文件名为标准处理crate: src/main.rs：表示该crate时一个bin类型大crate src/lib.rs：表示该crate时一个lib类型的crate 并且，一个package中的crate还有如下与约束： 可以有多个bin类型的crate 只能有0个或者1个lib类型的crate 以上两条约束并不互斥，也就是说一个项目下可以有一个lib和多个bin类型的crate，也就是可以编译出多个可执行文件 只是如果有多个bin类型的crate，一个src/main.rs就不够了，需要放到src/bin下，每个crate一个文件 mod 当项目逐渐膨胀后，可以对代码以mod「文件/文件夹」为单位进行拆分，而不是把所有代码都写在src/main.rs或者src/lib.rs里 以lib类型的crate为例，该类型的crate入口在src/lib.rs，也就是crate的根。定义一个模块也很简单 // src/lib.rs mod testMod { fn test() { println!(\"test\") } } 而在实际项目中，我们不会只有一个lib.rs文件，而是会将代码按功能进行拆分成多个模块 模块拆分 一般来说，一个文件都会被看作为一个mod，并且mod可以嵌套定义。嵌套定义的mod可以卸载一个文件里，也可以通过文件夹的形式来实现。具体的我们来看几个例子。 假设当前项目文件结构如下: src ├── lib.rs ├── mod_a │ ├── mod.rs │ └── mod_b.rs └── mod_c.rs 在这里定义了3个mod：mod_a、mod_b 和 mod_c，其中mod_a为文件夹形式，而mod_b和mod_c都有对应的文件。其中mod_b是mod_a的子模块。 我们来看下各个模块之间如何声明和引用。 首先我们先来看看crate的根，也就是lib.rs pub mod mod_a; mod mod_c; 在这里声明了两个mod，如果需要在crate外部访问，需要在mod前面加上pub关键字。注意这里不需要声明mod_a的子模块mod_b,这个需要mod_a来声明。 再来看一下这两个mod。先看mod_a，这是一个文件夹形式存在的mod，按cargo规定，这时候需要在该文件夹下有一个名为mod.rs的文件定义该mod下的内容。该文件内容如下： // src/mod_a/mod.rs pub mod mod_b; 可以看到，这个文件和lib.rs类似，都可以声明mod。但该文件声明的mod可以保存到mod.rs： // src/mod_a/mod_b.rs use super::super::mod_c; pub fn test() { println!(\"i'm mod_b\") } fn call_mod_c() { mod_c::test(); } 我们再来看看mod_c.rs的代码： // src/mod_c.rs use crate::mod_a::mod_b; pub fn test() { mod_b::test(); println!(\"i'm mod_c\"); } 除了如何定义mod，我们还需要的是如何引用其他mod的定义。在mod_c中，要想使用mod_b，可以使用： 绝对路径use crate::mod_a::mod_b 而在mod_b中使用mod_c的时候，使用了use super::super::mod_c这种相对路径的形式。 添加main.rs 最后在上面代码的基础上添加main.rs，看看作为外部crate如何使用上面的mod_a // src/main.rs use testlib::mod_a::mod_b; fn main() { println!(\"main\") mod_b::test(); } 在这里需要注意的是，引用自己lib的方法不能使用上面说的绝对路径或者相对路径这两种引用方式，必须使用该crate的名称「也就是Cargo.toml里的名称」来应用。因为main和lib属于不同的crate pub 修饰符 要想访问其他mod中的结构体、方法、枚举等，需要对方声明为pub。如果是想操作结构体中的字段，可以有一下两种方法 提供对应的pub方法 直接修改字段为pub use 语句 讲了这么做如何定义mod，我们来看下如何使用 在crate和模块中我们可能定义了函数、结构体等，要想在其他模块或者crate中使用，需要将其引入到当前文件中，类似php的use，或者java中的import，在Rust中我们需要使用use 如何表示要被引用的对象，Rust里称之为path，我们可以理解为操作系统中的文件目录 path有两种形式，也和文件系统一样，有绝对路径和相对路径： 绝对路径始于crate的根（src/main.rs or src/lib.rs），可以使用crate名或者crate这个字面值表示 相对路径可以使用当前模块名，当前模块中可以使用的对象，super和self等 path中的层级使用两个冒号::，类似文件系统中的斜线. 假设有一下代码（来自官方文档）： mod front_of_house { pub mod hosting { pub fn add_to_waitlist() {} } } pub fn eat_at_restautant() { // 绝对路径 crate::front_of_house::hosting::add_to_waitlist(); // 相对路径 front_of_house::hosting::add_to_waitlist(); } 有一些限制也需要知道： 在夫模块中不能使用子模块中的私有项目 子模块可以使用父模块中的所有项目 同一模块内可以直接互相使用 下面是一个使用了super的例子： fn server_order() {} mod back_of_house() { fn fix_incorrect_order() { cook_order(); super::server_order(); } fn cook_order() {} } fix_incorrect_order方法和cook_order同属于一个模块，可以直接调用。server_order方法和back_of_house同级，因此需要使用super访问到同级的server_order方法 如果use后面的路径具有共同的父路径，可以使用简化的模式。比如： use std::io; use std::cmp::Ordering; 可以简化为： use std::{cmp::Ordering, io}; 如果use的mod直接有父子关系，也可以像上面那样简化，使用self代表父mod。比如： use std::io; use std::io::Write; 可以简化为： use std::io::{self, Write}; 如果想将某一路径下的所有pub的item都引入到当前文件中，可以使用* use std::collections::*; 一般会在单元测试中常用，不推荐在业务代码中使用 #[cfg(test)] mod tests{ use super::*; #[test] fn it_works() {} } 引用层级 对比一下两种引用方式: // case 1 use crate::front_of_house::hosting; hosting::add_to_waitlist(); // case 2 use crate::front_of_house::hosting::add_to_waitlist; add_to_waitlist(); 这两种方法的结果都是一样的，但是阅读起来给人的感觉不一样。一般来说推荐第一个 case ，这样能明确的知道使用的方法是外部 hosting 模块的方法，后者的话不知道是 use 进来的，还是本模块定义的 重命名 有时候从不同的 crate 或者 mod 引入了同名的 item，这个时候最简单的方式是使用as关键字进行重命名。 use std::fmt; use std::io; fn function1() -\u003e fmt::Result {} fn function2() -\u003e io::Result\u003c()\u003e {} ########################### use std::fmt::Result; use std::io::Result as IoResult; fn function1","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:11","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"常见集合 一般来说在 Rust 常用的集合 vector允许我们一个挨着一个地存储一系列数量可变的值 字符串是字符的集合，String 哈希 map 允许我们将值与一个特定的键相关联 vector 新建vector let v: Vec\u003ci32\u003e = Vec::new(); let v = vec![1, 2, 3]; 更新vector let mut v = Vec::new(); v.push(1); v.push(2); let a = v.pop(); 类似于其他任何的struct，vector 在离开其作用域时会被释放。 访问vector let v = vec![1, 2, 3]; let v1 = \u0026v[1]; // 索引语法 let v2 = v.get(2); // 方法 使用索引语法访问vector会导致程序panic，而使用 get 方法访问时 会返回一个 None 在拿到 vector 中任意一个有效的引用，借用检查器将会窒息所有权和借用规则，来确保 vector 内容的这个引用和任何其他引用保持有效。当我们获取到了 vector 的第一个元素的不可变引用并在 vector 末尾增加一个元素的时候，编译无法通过。 let mut v = vec![1, 2, 3, 4, 5]; let first = \u0026v[0]; v.push(6); // 不通过编译 println!(\"The first element is: {}\", first); 为什么第一元素的引用会关心到末尾的变化？那是因为 vector 和 golang 的 slice 一样，在内部的空间不足时，会进行拷贝扩容，这样第一个元素的引用就指向了被释放的内存。 遍历 vector let mut v = vec![1, 2, 3]; for i in \u0026v { println!(\"{}\", i) } for i in \u0026mut v { *i += 50; } 同时 vector 也可以使用枚举来存储多种类型的值 enum Test { Int(i32), Text(String), } let row = vec![ Test::Int(3), Test::Text(String::from(\"test\")) ]; 字符串 创建一个字符串 let s1 = String::new(); // 创建一个空字符串 // 使用初始数据创建字符串 let s2 = \"test\".to_string(); let s3 = String::from(\"test\"); 更新字符串 let mut s = String::from(\"foo\"); let mut x = String::from(\" bar\"); s.push_str(x); s.push('~'); println!(\"x is {}\", x); let s1 = String::from(\"Hello, \"); let s2 = String::from(\"world!\"); let s3 = s1 + \u0026s2; // 这里 s1 被移动了，不能继续使用 执行上述代码之后，s将会包含x，x还可以继续使用，因为push_str方法使用了字符串 slice，因此我们不需要获取参数的所有权。 然而直接使用+运算符将两个String值合并到一个新String值中，此时s1在相加后失去了所有权。因为+调用了add函数，这个函数看起来像这样 fn add(self, s: \u0026str) -\u003e String{} 这并不是标准库当中实际的签名，标准库中的add使用泛型定义。 那为什么add方法的第二个参数是\u0026str，我们在调用时却是\u0026String，并且可以通过编译。 那是因为 Rust 使用了一个被称为 Deref 强制转换 的技术，可以理解为把\u0026s2变成了\u0026s2[..] 并且在签名中add方法获取self的所有权，这意味着s1的所有权将被移动到add调用中，之后不在生效，这样的好处是不会生成很多拷贝，这个实现比拷贝更加高效。 如果想获取多个字符相加： let s1 = String::from(\"hello\"); let s2 = String::from(\" \"); let s3 = String::from(\"world\"); let s = format!(\"{}{}{}\", s1, s2, s3); 上述代码会将s设置为hello world。format!与println!的工作原理相同，并且它使用索引不会获取任何参数的所有权。 索引字符串 在很多语言中，通过索引来一用字符串中的单独字符是很常见的操作，比如说 golang。然而在 Rust 中，不允许使用索引语法访问String的一部分，会出现错误。 let s = String::from(\"hello\"); let h = s[0]; // error 原因则是在 Rust 中，String是一个Vec\u003cu8\u003e的封装，相当于在底层存储的是字节，和大多数编程语言一样。直接使用索引语法获取String的一部分，相当于获取UTF-8字符的一个字节，这样可能会返回意外的值，Rust 根本不会编译这些代码。 在Golong中可以直接索引访问，那是因为Golang会默认把字符串按照rune来 遍历。 在 Rust 中也有这样的操作，只不过需要显示使用： for c in \"hello world\".chars() { println!(\"{}\", c); } 这样可以获取到每个UTF-8编码的字符，也就相当于 Golang 中的rune。 fn main() { let s = String::from(\"你好世界👋\"); let c = s.chars().nth(10000); match c { Some(tmp) =\u003e println!(\"{}\",tmp), None =\u003e ( println!(\"this index is none\") ), } } 上述代码可以安全的使用索引来获取单个字符。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:12","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"Hash Map 新建 可以使用new来创建一个空的HashMap，并使用insert增加元素。 use std::collections::HashMap; let mut map = HashMap::new(); map.insert(String::from(\"hello\"), String::form(\"world\")); 注意，使用HashMap需要引入 访问 可以 使用get方法传入对应的键，从HashMap中获取值 let name = String::from(\"hello\"); let s = map.get(\u0026name); // s : Option\u003cV\u003e 或者使用与 vector 类似的方式来遍历 for (key, value) in \u0026map { println!(\"{}: {}\", key, value); } 更新 直接使用相同的键重新调用insert方法，这样会直接替换成新值。 当我们需要检查对应键是否存在值时，可以使用entry方法 map.insert(String::from(\"Ronin\")); let s = map.entry(String::from(\"hello\")).or_insert(\"世界\"); *s = farmat!(\"{}\", s, String::from(\"~\")); 并且or_insert方法返回这个值的可变引用\u0026mut V，我们可以直接改变它。 所有权 对于类似i32这样实现了Copy trait 的类型，值可以直接拷贝进HashMap。对于拥有所有权的值，其值将被移动而HashMap会成为这些值的所有者。或者将值的引用传入HashMap，但是需要保证生命周期，后续会了解。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:13","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"今年嫖了一波良心云的服务器（2c4g8m），打算把 github page迁移到自己的服务器上。 又不想每次都 ssh 上服务器去拉取，也不想 ftp 去上传文件（公司安全要求）。所以想通过webhooks通知，让服务器自动的去更新博客。具体实现希望通过 docker 来解决，这样可以通用，下次迁移服务的时候可以直接拿个 docker-compose 文件就迁移完成了。毕竟良心云续费可不良心。 说干就干。 首先，我们需要一个能接收到请求的东西，任意方式都行，我这里使用的是 golang 。 build镜像需要以下目录结构，也可以自行调整。 . ├── Dockerfile ├── src │ ├── cmd │ │ ├── main.go │ │ └── sync.sh │ ├── go.mod │ └── go.sum └── ssh ├── id_rsa ├── id_rsa.pub └── known_hosts main.go package main import ( \"fmt\" \"net/http\" \"os/exec\" \"github.com/go-playground/webhooks/v6/github\" ) const ( path = \"/webhooks\" // 可以自行修改 ) func main() { hook, err := github.New(github.Options.Secret(\"你自己设置的秘钥\")) if err != nil { panic(err) } http.HandleFunc(path, func(w http.ResponseWriter, r *http.Request) { cmd := exec.Command(\"/bin/sh\", \"./cmd/sync.sh\") out, err := cmd.Output() if err != nil { fmt.Println(err) } fmt.Println(out) payload, err := hook.Parse(r, github.ReleaseEvent, github.PushEvent) if err != nil { if err == github.ErrEventNotFound { fmt.Println(err) } } switch payload.(type) { case github.PushPayload: fmt.Println(\"received push event\") exec.Command(\"/bin/sh\", \"./cmd/sync.sh\").Run() default: fmt.Println(payload) } }) http.ListenAndServe(\":8888\", nil) } 接收到请求并校验通过之后，会执行 sync.sh 脚本。里面的内容可以根据自己需要进行修改 sync.sh #!/bin/bash cd /data/www echo $(pwd) echo $(git pull) 运行的服务现在准备好了，得准备运行的环境 因为是个小功能所以使用的镜像也希望轻量一些，选用的是 golang:alpine镜像 如果需要其他功能也可以自行修改 Dockerfile FROM golang:alpine # 设置 go mod 代理 ENV GOPROXY=https://goproxy.cn,direct # 替换apk镜像源 RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g' /etc/apk/repositories # 设置ssh pub key COPY ./ssh /root/.ssh RUN chmod -R 600 /root/.ssh # 设置工作目录 WORKDIR /tmp/src # 复制代码 COPY ./src /tmp/src RUN apk update RUN apk add git \u0026\u0026 apk add openssh RUN go mod tidy RUN go build -o bin/hugo cmd/main.go ENTRYPOINT [\"./bin/hugo\"] CMD [\"-logtostderr\"] 可以看到这里需要ssh信息，自行添加文件即可。 这里也直接给出 docker-compose 文件 hugo: container_name: hugo build: ./services/go-hugo/ volumes: - {你需要同步的git目录}:/data/www:rw # 资源目录 links: - nginx # 如果你不需要nginx做转发，可以去除这里 nginx: container_name: nginx build: context: ./services/nginx args: NGINX_VERSION: 1.21.3-alpine CONTAINER_PACKAGE_URL: mirrors.aliyun.com ports: - \"80:80\" - \"443:443\" volumes: - {你的资源目录}:/www/:rw - {你的https目录}:/ssl:rw - {你的配置文件目录}:/etc/nginx/conf.d/:rw - {你的根配置文件}:/etc/nginx/nginx.conf:ro - {nginx日志目录}:/var/log/nginx/:rw environment: TZ: \"Asia/Shanghai\" restart: always networks: - default 可以直接把端口暴露出公网，也可以使用nginx做一层转发，可以提高安全性不暴露端口 nginx的Dockerfile ARG NGINX_VERSION FROM nginx:${NGINX_VERSION} ARG TZ ARG NGINX_VERSION ARG CONTAINER_PACKAGE_URL ARG NGINX_INSTALL_APPS ENV INSTALL_APPS=\",${NGINX_INSTALL_APPS},\" RUN if [ \"${CONTAINER_PACKAGE_URL}\" != \"\" ]; then \\ sed -i \"s/dl-cdn.alpinelinux.org/${CONTAINER_PACKAGE_URL}/g\" /etc/apk/repositories; \\ fi RUN if [ -z \"${INSTALL_APPS##*,certbot,*}\" ]; then \\ echo \"---------- Install certbot ----------\"; \\ apk add --no-cache certbot; \\ fi WORKDIR /www nginx配置文件 server { listen 80; server_name 你的域名; return 301 https://$server_name$request_uri; } server { listen 443 ssl; server_name 你的域名; # server_name localhost; root {根地址}; # ssl证书地址 ssl_certificate /ssl/xxx.pem; # pem文件的路径 ssl_certificate_key /ssl/xxx.key; # key文件的路径 location /webhook { proxy_pass http://hugo:8888; # HTTP 代理转发port。这里因为使用了已命名为 hugo 的 docker 容器，所以可以在nginx配置中直接使用。 proxy_set_header Host localhost; # 不要忘记这句 Host $host proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto https; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location / { index index.html; } } 配置都完成后，直接使用 docker-compose up -d 启动容器。在github上设置webhooks的部分就不再此赘述。 ","date":"2021-11-08","objectID":"/webhooks%E5%AE%9E%E7%8E%B0%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/:0:0","tags":["Webhooks","docker"],"title":"Webhooks实现博客自动更新","uri":"/webhooks%E5%AE%9E%E7%8E%B0%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/"},{"categories":null,"content":"题目 请你仅使用两个栈实现先入先出队列。队列应当支持一般队列的支持的所有操作（push、pop、peek、empty）： 实现 MyQueue 类： void push(int x) 将元素 x 推到队列的末尾 int pop() 从队列的开头移除并返回元素 int peek() 返回队列开头的元素 boolean empty() 如果队列为空，返回 true ；否则，返回 false 说明： 你只能使用标准的栈操作 —— 也就是只有 push to top, peek/pop from top, size, 和 is empty 操作是合法的。 你所使用的语言也许不支持栈。你可以使用 list 或者 deque（双端队列）来模拟一个栈，只要是标准的栈操作即可。 进阶： 你能否实现每个操作均摊时间复杂度为 O(1) 的队列？换句话说，执行 n 个操作的总时间复杂度为 O(n) ，即使其中一个操作可能花费较长时间。 示例： 输入： [\"MyQueue\", \"push\", \"push\", \"peek\", \"pop\", \"empty\"] [[], [1], [2], [], [], []] 输出： [null, null, null, 1, 1, false] 解释： MyQueue myQueue = new MyQueue(); myQueue.push(1); // queue is: [1] myQueue.push(2); // queue is: [1, 2] (leftmost is front of the queue) myQueue.peek(); // return 1 myQueue.pop(); // return 1, queue is [2] myQueue.empty(); // return false 提示： 1 \u003c= x \u003c= 9 最多调用 100 次 push、pop、peek 和 empty 假设所有操作都是有效的 （例如，一个空的队列不会调用 pop 或者 peek 操作） 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/implement-queue-using-stacks 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 ","date":"2021-03-05","objectID":"/leetcode-232%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/:0:1","tags":["LeetCode"],"title":"LeetCode 232:用栈实现队列","uri":"/leetcode-232%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/"},{"categories":null,"content":"思路 这题比较简单，主要是实现队列的基本功能，即先进先出。而我们知道栈是先进后出的，这就需要我们额外的操作了。 题目提示的比较明显，使用两个栈来实现。我们可以做出如下模型： 两个栈分别为输入栈和输出栈 输入栈负责接收 push 的内容 输出栈负责 pop 和 peek 的内容 当执行 pop 或者 peek 时，当输出栈为空时，将输入栈的内容输出到输入栈中 in : [] out: [] --push(1) in : [1] out: [] --push(2) in : [2,1] out: [] --peek in : [] out: [1,2] peek = 1 --pop in : [] out: [2] pop = 1 --isEmpty isEmpty(in) \u0026\u0026 isEmpty(out) ","date":"2021-03-05","objectID":"/leetcode-232%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/:0:2","tags":["LeetCode"],"title":"LeetCode 232:用栈实现队列","uri":"/leetcode-232%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/"},{"categories":null,"content":"代码 // MyQueue 队列 type MyQueue struct { in Stack out Stack } // Constructor MyQueue构造方法 func Constructor() MyQueue { in := new(Stack) out := new(Stack) return MyQueue{ in: *in, out: *out, } } func (mq *MyQueue) in2out() { for len(mq.in) \u003e 0 { mq.out.Push(mq.in.Pop()) } } // Push Push func (mq *MyQueue) Push(x int) { mq.in.Push(x) } // Pop Pop func (mq *MyQueue) Pop() int { if mq.out.Len() == 0 { mq.in2out() } return mq.out.Pop() } // Peek Peek func (mq *MyQueue) Peek() int { if mq.out.Len() == 0 { mq.in2out() } return mq.out.Top() } // Empty Empty func (mq *MyQueue) Empty() bool { return mq.in.IsEmpty() \u0026\u0026 mq.out.IsEmpty() } // ------------------------------------------------------- // Stack 栈 type Stack []int // Len 获取栈的长度 func (stack *Stack) Len() int { return len(*stack) } // Push push func (stack *Stack) Push(value int) { *stack = append(*stack, value) } // Top 获取栈的第一个 func (stack *Stack) Top() int { return (*stack)[len(*stack)-1] } // Pop 弹出最后一个 func (stack *Stack) Pop() int { value := (*stack)[len(*stack)-1] *stack = (*stack)[:len(*stack)-1] return value } // IsEmpty 判断是否为空 func (stack *Stack) IsEmpty() bool { return len(*stack) == 0 } ","date":"2021-03-05","objectID":"/leetcode-232%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/:0:3","tags":["LeetCode"],"title":"LeetCode 232:用栈实现队列","uri":"/leetcode-232%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/"},{"categories":null,"content":"题目 给定一些标记了宽度和高度的信封，宽度和高度以整数对形式 (w, h) 出现。当另一个信封的宽度和高度都比这个信封大的时候，这个信封就可以放进另一个信封里，如同俄罗斯套娃一样。 请计算最多能有多少个信封能组成一组“俄罗斯套娃”信封（即可以把一个信封放到另一个信封里面）。 说明: 不允许旋转信封。 示例: 输入: envelopes = [[5,4],[6,4],[6,7],[2,3]] 输出: 3 解释: 最多信封的个数为 3, 组合为: [2,3] =\u003e [5,4] =\u003e [6,7]。 ","date":"2021-03-05","objectID":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/:0:1","tags":["LeetCode"],"title":"LeetCode 354:俄罗斯信封套娃问题","uri":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"思路 来源：labuladong 这道题目其实是最长递增子序列 (Longes Increasing Subsequence, 简写为 LIS) 的一个变种，因为很显然，每次合法的嵌套都是大的套小的，相当于找一个最长递增的子序列，其长度就是最多能嵌套的信封个数。 但是难点在于，标准的LIS算法只能在数组中寻找最长子序列，而我们的信封是由[w, h]这样的二维数对形式表示的，如何把LIS算法运用过来呢？ w * h计算面积的形式是行不通的，1 * 10 大于 3 * 3，但是明显这样的两个信封是无法相互嵌套的。 ","date":"2021-03-05","objectID":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/:0:2","tags":["LeetCode"],"title":"LeetCode 354:俄罗斯信封套娃问题","uri":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"解法 这道题的解法是比较巧妙的： 先对宽度 w 进行升序排列，如果遇到 w 相同的情况，则按照高度 h 降序排列。之后把所有的 h 取出，填入一个数组，在这个数组上计算 LIS 的长度就是我们的答案。 示例： | 宽度w 高度h | [ 1 , 8 ] | [ 2 , 3 ] | [ 5 , 4 ]|降 | [ 5 , 2 ]|序 | [ 6 , 7 ]|降 | [ 6 , 4 ]|序 升 序 很明显，高度 h 组成的数组中 3 -\u003e 4 -\u003e 7 ，就是我们要找的LIS，其最大长度为3 这个解法的关键在于，对于宽度 w 相同的数对，要对其高度 h 进行降序排序。因为两个宽度相同的信封不能相互包含的，逆序排序保证 w 相同的数对中最多只选取一个。 ","date":"2021-03-05","objectID":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/:0:3","tags":["LeetCode"],"title":"LeetCode 354:俄罗斯信封套娃问题","uri":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"代码 func maxEnvelopes(envelopes [][]int) int { count := len(envelopes) // 快速排序 sort.Slice(envelopes, func(i, j int) bool { if envelopes[i][0] == envelopes[j][0] { return envelopes[i][1] \u003e envelopes[j][1] } return envelopes[i][0] \u003c envelopes[j][0] }) // 取出h height := make([]int, count) for i := 0; i \u003c count; i++ { height[i] = envelopes[i][1] } // 计算LIS return lengthOfLIS(height) } // LIS 计算 func lengthOfLIS(nums []int) int { piles, count := 0, len(nums) top := make([]int, count) for i := 0; i \u003c count; i++ { num := nums[i] left, right := 0, piles for left \u003c right { mid := (left + right) / 2 if top[mid] \u003e= num { right = mid } else { left = mid + 1 } } if left == piles { piles++ } top[left] = num } return piles } ","date":"2021-03-05","objectID":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/:0:4","tags":["LeetCode"],"title":"LeetCode 354:俄罗斯信封套娃问题","uri":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"wiki 最长递增子序列扩展到二维而已 动态规划设计方法\u0026\u0026纸牌游戏讲解二分解法 ","date":"2021-03-05","objectID":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/:0:5","tags":["LeetCode"],"title":"LeetCode 354:俄罗斯信封套娃问题","uri":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"题目 给定一个非负整数 num。对于 0 ≤ i ≤ num 范围中的每个数字 i ，计算其二进制数中的 1 的数目并将它们作为数组返回 示例1: 输入: 2 输出: [0, 1, 1] 示例2: 输入: 5 输出: [0, 1, 1, 2, 1, 2] 进阶: 给出时间复杂度为 O(n * sizeof(integer)) 的解答非常容易. 但你可以在线性时间 O(n) 内用一趟扫描做到吗? 要求算法的空间复杂度为 O(n) 你能进一步完善解法吗？要求在C++或任何其他语言中不使用任何内置函数（如 C++ 中的 __builtin_popcount）来执行此操作 ","date":"2021-03-03","objectID":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/:0:1","tags":["LeetCode"],"title":"LeetCode 338:比特位计数","uri":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/"},{"categories":null,"content":"开始的思路 先不考虑进阶, 使用语言自带的函数进行解答，Golang中可以使用bits.OnesCount()函数来计算 func countBits(num int) []int { nums := make([]int, num+1) for i := 0; i \u003c= num; i++ { nums[i] = bits.OnesCount(uint(i)) } return nums } 这种解答十分简单，我们来尝试一下手写一个 OneCount() leetcode 官方解答内提到有一个位运算的小技巧 对于任意整数x, 令 x = x \u0026 (x - 1) , 该运算将 x 的二进制表示的最后一个1变成0. 因此, 对x重复该操作, 直到x变成0, 则操作次数即为x的「一比特数」 我们来实际操作一下试试 // 8的二进制为 1000 // 7的二进制为 0111 // 我们进行 \u0026 操作 1000 \u0026 0111 = 0000 // x 变成了 0 , 8的二进制数为1, 这符合我们的答案 // 让我们再来一个 // 6的二进制为 0110 // 5的二进制为 0101 // 4的二进制为 0100 // 3的二进制为 0011 0111 \u0026 0110 = 0110 // ones + 1 0110 \u0026 0101 = 0100 // ones + 1 0101 \u0026 0100 = 0100 // ones + 1 0100 \u0026 0011 = 0000 // ones = 3 // 对此我只能发出咸鱼的声音，妙啊 对此技巧，我们可以写出: func onesCount(x int) (ones int) { for ; x \u003e 0; x \u0026= x - 1 { ones++ } return } 但是这依然不满足进阶解答的需求，所以我们继续 ","date":"2021-03-03","objectID":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/:0:2","tags":["LeetCode"],"title":"LeetCode 338:比特位计数","uri":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/"},{"categories":null,"content":"进阶 要给出时间复杂度为 O(n) 的解法, 代表我们不能使用系统的内置函数, 且不能进入循环. 我们必须进行逻辑梳理 官方给出的解答: 动态规划–最高有效位 有些晦涩难懂 需要对每个数遍历其二进制表示的每一位。可以换一个思路，当计算 i 的「一比特数」时，如果存在 0 ≤ j \u003c i，j 的「一比特数」已知，且 i 和 j 相比，i 的二进制表示只多了一个 1，则可以快速得到 i 的「一比特数」。 令 bits[i] 表示 i 的「一比特数」，则上述关系可以表示成：bits[i] = bits[j] + 1。 对于正整数 x，如果可以知道最大的正整数 y，使得 y ≤ x 且 y 是 2 的整数次幂，则 y 的二进制表示中只有最高位是 1，其余都是 0，此时称 y 为 x 的「最高有效位」。令 z = x − y，显然 0 ≤ z \u003c x，则 bits[x] = bits[z] + 1。 为了判断一个正整数是不是 2 的整数次幂，可以利用方法一中提到的按位与运算的性质。如果正整数 y 是 2 的整数次幂，则 y 的二进制表示中只有最高位是 1，其余都是 0，因此 y \u0026 ( y − 1 ) = 0。由此可见，正整数 y 是 2 的整数次幂，当且仅当 y \u0026 ( y − 1 ) = 0。 显然，0 的「一比特数」为 0。使用 highBit 表示当前的最高有效位，遍历从 1 到 num 的每个正整数 i，进行如下操作。 如果 i\u0026(i−1)=0，则令 highBit = i，更新当前的最高有效位。 i 比 i−highBit 的「一比特数」多 1，由于是从小到大遍历每个数，因此遍历到 i 时，i−highBit 的「一比特数」已知，令 bits[i] = bits[i−highBit] + 1。 最终得到的数组 bits 即为答案。 作者：LeetCode-Solution 链接：https://leetcode-cn.com/problems/counting-bits/solution/bi-te-wei-ji-shu-by-leetcode-solution-0t1i/ 来源：力扣（LeetCode） 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 我这尝试做出自己的解释： 当一个数是 2 的整数次幂时, 它的二进制中1的数量只会是1 当一个数不是2的整数次幂时，它的二进制中1的数量为 (它 与 它上次为2的整数次幂的数的差值)的「一比特数」+ 1 我们可以来实际试试: // 8的二进制为 1000 它是2的整数次幂 所以它的二进制中1的数量只会是1 // 那 9 呢？根据上面的总结 它的上次2的整数次幂的数为 8,9-8=1(0001) 的「一比特数」为1 // 9 的二进制位是 1001 ,「一比特数」为 2, 完美 // 那 10 呢？它的上次2的整数次幂的数依然为 8, 10-8=2(0010) 的「一比特数」为1 // 10 的二进制位为 1010, 「一比特数」为 2 // 继续 11 二进制为 1011, 11-8=3 , 3(0011)的「一比特数」为2 // 对此我只能发出咸鱼的声音，妙啊 // 所以我们能写出下面的方法 func countBits(num int) []int { bits := make([]int, num+1) highBit := 0 // 最高比特位 即 上次为2的整数次幂的数 // 0的「一比特数」为 0，不需要进入循环 for i := 1; i \u003c= num; i++ { // 这里是根据上面的位运算的技巧，判断是否为2的整数次幂，因为2的整数次幂只有一个1 if i\u0026(i-1) == 0 { highBit = i // 更新最高比特位 } // 它与它上次为2的整数次幂的数的差值 的「一比特数」+ 1 bits[i] = bits[i-highBit] + 1 } return bits } 应该还是有些晦涩难懂，但是我也没得办法，这太抽象了，官方解答的其他动态规划思想就不继续了，我们还有新办法。 ","date":"2021-03-03","objectID":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/:0:3","tags":["LeetCode"],"title":"LeetCode 338:比特位计数","uri":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/"},{"categories":null,"content":"新的办法 对于所有的数字，只有两类 奇数|偶数: 奇数: 在二进制中表示，奇数一定比前面的那个偶数多一个1，多的就是最低位的1 举例： 0 = 0000 1 = 0001 2 = 0010 3 = 0011 发现了没有，偶数的最低位总是0，奇数的最低位总是1，我们再考虑偶数 偶数: 二进制中，偶数中的1一定和除以2之后的那个数一样多，因为偶数的最低位总是0 除以2就只是右移一位，把最低位的0去掉而已，所以1的数量是不变的 举例: 0 = 0000 1 = 0001 // 0不算, 1的「一比特数」= 0 + 1 2 = 0010 3 = 0011 // 2 / 2 = 1, 1的「一比特数」= 1 … 4 = 0100 5 = 0101 6 = 0110 7 = 0111 我们能根据上面的规律来写出以下代码 func countBits(num int) []int { nums := make([]int, num+1) for i := 1; i \u003c= num; i++ { // 判断是否为偶数，奇数的最后一位永远是1 if i\u00261 == 1 { nums[i] = nums[i-1] + 1 } else { nums[i] = nums[i/2] } } return nums } 以上思路来自: 作者：duadua 链接：https://leetcode-cn.com/problems/counting-bits/solution/hen-qing-xi-de-si-lu-by-duadua/ 来源：力扣（LeetCode） ","date":"2021-03-03","objectID":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/:0:4","tags":["LeetCode"],"title":"LeetCode 338:比特位计数","uri":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/"},{"categories":null,"content":" 本主题为系列文章，分上下两篇。本文主要介绍 time/rate 的具体使用方法，另外一篇文章 《Golang 限流器 time/rate 实现剖析》 则着重介绍其内部实现原理。 限流器是后台服务中的非常重要的组件，可以用来限制请求速率，保护服务，以免服务过载。 限流器的实现方法有很多种，例如滑动窗口法、Token Bucket、Leaky Bucket 等。 其实 Golang 标准库中就自带了限流算法的实现，即 golang.org/x/time/rate。该限流器是基于 Token Bucket(令牌桶) 实现的。 简单来说，令牌桶就是想象有一个固定大小的桶，系统会以恒定速率向桶中放 Token，桶满则暂时不放。 而用户则从桶中取 Token，如果有剩余 Token 就可以一直取。如果没有剩余 Token，则需要等到系统中被放置了 Token 才行。 本文则主要集中介绍下该组件的具体使用方法： 构造一个限流器 我们可以使用以下方法构造一个限流器对象： limiter := NewLimiter(10, 1); 这里有两个参数： 第一个参数是 r Limit。代表每秒可以向 Token 桶中产生多少 token。Limit 实际上是 float64 的别名。 第二个参数是 b int。b 代表 Token 桶的容量大小。 那么，对于以上例子来说，其构造出的限流器含义为，其令牌桶大小为 1, 以每秒 10 个 Token 的速率向桶中放置 Token。 除了直接指定每秒产生的 Token 个数外，还可以用 Every 方法来指定向 Token 桶中放置 Token 的间隔，例如： limit := Every(100 * time.Millisecond); limiter := NewLimiter(limit, 1); 以上就表示每 100ms 往桶中放一个 Token。本质上也就是一秒钟产生 10 个。 Limiter 提供了三类方法供用户消费 Token，用户可以每次消费一个 Token，也可以一次性消费多个 Token。 而每种方法代表了当 Token 不足时，各自不同的对应手段。 Wait/WaitN func (lim *Limiter) Wait(ctx context.Context) (err error) func (lim *Limiter) WaitN(ctx context.Context, n int) (err error) Wait 实际上就是 WaitN(ctx,1)。 当使用 Wait 方法消费 Token 时，如果此时桶内 Token 数组不足 (小于 N)，那么 Wait 方法将会阻塞一段时间，直至 Token 满足条件。如果充足则直接返回。 这里可以看到，Wait 方法有一个 context 参数。 我们可以设置 context 的 Deadline 或者 Timeout，来决定此次 Wait 的最长时间。 Allow/AllowN func (lim *Limiter) Allow() bool func (lim *Limiter) AllowN(now time.Time, n int) bool Allow 实际上就是 AllowN(time.Now(),1)。 AllowN 方法表示，截止到某一时刻，目前桶中数目是否至少为 n 个，满足则返回 true，同时从桶中消费 n 个 token。 反之返回不消费 Token，false。 通常对应这样的线上场景，如果请求速率过快，就直接丢到某些请求。 Reserve/ReserveN func (lim *Limiter) Reserve() *Reservation func (lim *Limiter) ReserveN(now time.Time, n int) *Reservation Reserve 相当于 ReserveN(time.Now(), 1)。 ReserveN 的用法就相对来说复杂一些，当调用完成后，无论 Token 是否充足，都会返回一个 Reservation * 对象。 你可以调用该对象的 Delay() 方法，该方法返回了需要等待的时间。如果等待时间为 0，则说明不用等待。 必须等到等待时间之后，才能进行接下来的工作。 或者，如果不想等待，可以调用 Cancel() 方法，该方法会将 Token 归还。 举一个简单的例子，我们可以这么使用 Reserve 方法。 r := lim.Reserve() f !r.OK() { // Not allowed to act! Did you remember to set lim.burst to be \u003e 0 ? return } time.Sleep(r.Delay()) Act() // 执行相关逻辑 动态调整速率 Limiter 支持可以调整速率和桶大小： SetLimit(Limit) 改变放入 Token 的速率 SetBurst(int) 改变 Token 桶大小 有了这两个方法，可以根据现有环境和条件，根据我们的需求，动态的改变 Token 桶大小和速率。 相关文章 Golang 限流器 time/rate 实现剖析 uber-go 漏桶限流器使用与原理分析 本文作者： cyhone 本文链接： https://www.cyhone.com/articles/usage-of-golang-rate/ 版权声明： 本博客所有文章除特别声明外，均采用 BY-NC-SA 许可协议。转载请注明出处！ ","date":"2021-03-03","objectID":"/golang%E6%A0%87%E5%87%86%E5%BA%93%E9%99%90%E6%B5%81%E5%99%A8timerate%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/:0:0","tags":["Go标准库"],"title":"Golang标准库限流器timerate使用介绍","uri":"/golang%E6%A0%87%E5%87%86%E5%BA%93%E9%99%90%E6%B5%81%E5%99%A8timerate%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/"},{"categories":null,"content":"限流器是微服务中必不缺少的一环，可以起到保护下游服务，防止服务过载等作用。上一篇文章 《Golang 限流器 time/rate 使用介绍》 简单介绍了 time/rate 的使用方法，本文则着重分析下其实现原理。建议在正式阅读本文之前，先阅读下上一篇文章。 上一篇文章讲到，time/rate 是基于 Token Bucket(令牌桶) 算法实现的限流。本文将会基于源码，深入剖析下 Golang 是如何实现 Token Bucket 的。其代码也非常简洁，去除注释后，也就 200 行左右的代码量。 同时，我也提供了 time/rate 注释版，辅助大家理解该组件的实现。 背景 简单来说，令牌桶就是想象有一个固定大小的桶，系统会以恒定速率向桶中放 Token，桶满则暂时不放。 而用户则从桶中取 Token，如果有剩余 Token 就可以一直取。如果没有剩余 Token，则需要等到系统中被放置了 Token 才行。 一般介绍 Token Bucket 的时候，都会有一张这样的原理图： 从这个图中看起来，似乎令牌桶实现应该是这样的： 有一个 Timer 和一个 BlockingQueue。Timer 固定的往 BlockingQueue 中放 token。用户则从 BlockingQueue 中取数据。 这固然是 Token Bucket 的一种实现方式，这么做也非常直观，但是效率太低了：我们需要不仅多维护一个 Timer 和 BlockingQueue，而且还耗费了一些不必要的内存。 在 Golang 的 timer/rate 中的实现, 并没有单独维护一个 Timer，而是采用了 lazyload 的方式，直到每次消费之前才根据时间差更新 Token 数目，而且也不是用 BlockingQueue 来存放 Token，而是仅仅通过计数的方式。 Token 的生成和消费 我们在 上一篇文章 中讲到，Token 的消费方式有三种。但其实在内部实现，最终三种消费方式都调用了 reserveN 函数来生成和消费 Token。 我们看下 reserveN 函数的具体实现，整个过程非常简单。在正式讲之前，我们先了解一个简单的概念： 在 time/rate 中，NewLimiter 的第一个参数是速率 limit，代表了一秒钟可以产生多少 Token。 那么简单换算一下，我们就可以知道一个 Token 的生成间隔是多少。 有了这个生成间隔，我们就可以轻易地得到两个数据： 1. 生成 N 个新的 Token 一共需要多久。time/rate 中对应的实现函数为 durationFromTokens。 2. 给定一段时长，这段时间一共可以生成多少个 Token。time/rate 中对应的实现函数为 tokensFromDuration。 那么，有了这些转换函数，整个过程就很清晰了，如下： 计算从上次取 Token 的时间到当前时刻，期间一共新产生了多少 Token： 我们只在取 Token 之前生成新的 Token，也就意味着每次取 Token 的间隔，实际上也是生成 Token 的间隔。我们可以利用 tokensFromDuration, 轻易的算出这段时间一共产生 Token 的数目。 那么，当前 Token 数目 = 新产生的 Token 数目 + 之前剩余的 Token 数目 - 要消费的 Token 数目。 如果消费后剩余 Token 数目大于零，说明此时 Token 桶内仍不为空，此时 Token 充足，无需调用侧等待。 如果 Token 数目小于零，则需等待一段时间。 那么这个时候，我们可以利用 durationFromTokens 将当前负值的 Token 数转化为需要等待的时间。 将需要等待的时间等相关结果返回给调用方。 从上面可以看出，其实整个过程就是利用了 Token 数可以和时间相互转化 的原理。而如果 Token 数为负，则需要等待相应时间即可。 注意 如果当消费时，Token 桶中的 Token 数目已经为负值了，依然可以按照上述流程进行消费。随着负值越来越小，等待的时间将会越来越长。 从结果来看，这个行为跟用 Timer+BlockQueue 实现是一样的。 此外，整个过程为了保证线程安全，更新令牌桶相关数据时都用了 mutex 加锁。 我们模拟下请求与 Token 数变化的关系： 当某一时间，桶内 Token 数为 3, 此时 A 线程请求 5 个 Token。那么此时桶内 Token 不足，因此 A 线程需要等待 2 个 Token 的时间。 且此时桶内 Token 数变为 - 2。 同时，B 线程请求 4 个 Token，此时桶内 Token 数为 - 2，因此 B 线程需要等待 2+4=6 个 Token 的时间，且此时桶内 Token 数变为 - 6。 对于 Allow 函数实现时，只要判断需要等待的时间是否为 0 即可，如果大于 0 说明需要等待，则返回 False，反之返回 True。 对于 Wait 函数，直接 t := time.NewTimer(delay)，等待对应的时间即可。 float 精度问题 从上面原理讲述可以看出，在 Token 和时间的相互转化函数 durationFromTokens 和 tokensFromDuration 中，涉及到 float64 的乘除运算。 一谈到 float 的乘除，我们就需要小心精度问题了。 而 Golang 在这里也踩了坑，以下是 tokensFromDuration 最初的实现版本 func (limit Limit) tokensFromDuration(d time.Duration) float64 { return d.Seconds() * float64(limit) } 这个操作看起来一点问题都没：每秒生成的 Token 数乘于秒数。 然而，这里的问题在于，d.Seconds() 已经是小数了。两个小数相乘，会带来精度的损失。 所以就有了这个 issue:golang.org/issues/34861。 修改后新的版本如下： func (limit Limit) tokensFromDuration(d time.Duration) float64 { sec := float64(d/time.Second) * float64(limit) nsec := float64(d%time.Second) * float64(limit) return sec + nsec/1e9 } time.Duration 是 int64 的别名，代表纳秒。分别求出秒的整数部分和小数部分，进行相乘后再相加，这样可以得到最精确的精度。 数值溢出问题 我们讲 reserveN 函数的具体实现时，第一步就是计算从当前时间到上次取 Token 的时刻，期间一共新产生了多少 Token，同时也可得出当前的 Token 是多少。 我最开始的理解是，直接可以这么做： // elapsed 表示过去的时间差 elapsed := now.Sub(lim.last) // delta 表示这段时间一共新产生了多少 Token delta = tokensFromDuration(now.Sub(lim.last)) tokens := lim.tokens + delta if(token\u003e lim.burst){ token = lim.burst } 其中，lim.tokens 是当前剩余的 Token，lim.last 是上次取 token 的时刻。lim.burst 是 Token 桶的大小。 使用 tokensFromDuration 计算出新生成了多少 Token，累加起来后，不能超过桶的容量即可。 这么做看起来也没什么问题，然而并不是这样。 在 time/rate 里面是这么做的，如下代码所示： maxElapsed := lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens) elapsed := now.Sub(last) if elapsed \u003e maxElapsed { elapsed = maxElapsed } delta := lim.limit.tokensFromDuration(elapsed) tokens := lim.tokens + delta if burst := float64(lim.burst); tokens \u003e burst { tokens = burst } 与我们最开始的代码不一样的是，它没有直接用 now.Sub(lim.last) 来转化为对应的 Token 数，而是 先用 lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens)，计算把桶填满的时间 maxElapsed。 取 elapsed 和 maxElapsed 的最小值。 这么做算出的结果肯定是正确的，但是这么做相比于我们的做法，好处在哪里？ 对于我们的代码，当 last 非常小的时候（或者当其为初始值 0 的时候），此时 now.Sub(lim.last) 的值就会非常大，如果 lim.limit 即每秒生成的 Token 数目也非常大时，直接将二者进行乘法运算，结果有可能会溢出。 因此，time/rate 先计算了把桶填满的时间，将其作为时间差值的上限，这样就规避了溢出的问题。 Token 的归还 而对于 Reserve 函","date":"2021-03-03","objectID":"/golang%E6%A0%87%E5%87%86%E5%BA%93%E9%99%90%E6%B5%81%E5%99%A8timerate%E5%AE%9E%E7%8E%B0%E5%89%96%E6%9E%90/:0:0","tags":["Go标准库"],"title":"Golang标准库限流器timerate实现剖析","uri":"/golang%E6%A0%87%E5%87%86%E5%BA%93%E9%99%90%E6%B5%81%E5%99%A8timerate%E5%AE%9E%E7%8E%B0%E5%89%96%E6%9E%90/"},{"categories":null,"content":"前言 继前文RSA(六) X.509 CA 证书 所述，X.509 CA 证书是由 𝐶𝐴CA 认证中心签名并颁发的；但是最后，作者留下了这么一个疑问，就是如果在企业内网，我同样需要对公钥进行认证，但是因为不需要连接外网，所以并不需要 𝐶𝐴CA 证书(因为，𝐶𝐴CA 证书毕竟开销不菲)；那么是否有这样的一种可替代的方案，在不使用 𝐶𝐴CA 证书的前提下，能否保证公钥的合法性？答案是自签名证书； 备注，本文是作者的原创作品，转载请注明出处。 转载至https://www.shangyang.me/2017/05/27/encrypt-rsa-selfsigned-certificate/ 定义 看下 wikipedia https://en.wikipedia.org/wiki/Self-signed_certificate 上的最重要的一段解释 In technical terms a self-signed certificate is one signed with its own private key. 自签名证书说穿了，就是一个由自己的私钥进行签名的证书； 与 CA 证书的区别 通过 RSA(六) X.509 CA 证书 章节我们知道，要保证公钥的合法性，我们需要把自己的公钥交给第三方 𝐶𝐴CA 机构，通过它的私钥来进行签名，并生成一张 𝐶𝐴CA 证书并颁发给用户；而与 𝐶𝐴CA 证书相对应的就是自签名证书，也就是说，我自己的公钥不交给第三方的 𝐶𝐴CA 机构进行签名，而是直接由自己的私钥进行签名，并生成一张自签名的证书； 如何生成 这里我主要讲解一下，如果通过 openssl 来生成自签名的证书， $ openssl req \\ \u003e -newkey rsa:2048 -nodes -keyout private.key \\ \u003e -x509 -days 365 -out self-signed.crt 然后同样需要输入 CSR 相关的信息来申请；最后，会在本地目录中生成一个私钥 private.key 和一张自签名的证书 self-signed.crt；注意，自签名证书文件的后缀为 .crt；下面来看看各个参数的简要说明， -x509告诉 openssl 生成一张自签名的证书； -nodes告诉 openssl 在生成私钥的时候忽略密码 参考 How To Create a Self-Signed SSL Certificate for Apache in Ubuntu 16.04 OpenSSL Essentials: Working with SSL Certificates, Private Keys and CSRs 内部结构 我们来查看一下刚才通过 openssl 生成的自签名证书 self-signed.crt 的内部结构； $ openssl x509 -text -noout -in domain.crt 内容如下， Certificate: Data: Version: 3 (0x2) Serial Number: 9f:56:fd:f5:9d:13:2e:d2 Signature Algorithm: sha1WithRSAEncryption Issuer: C=CN, ST=ChengDu, L=ChengDu, O=HRX, OU=HRX, CN=HRX/emailAddress=comedshang@163.com Validity Not Before: May 27 13:42:23 2017 GMT Not After : May 27 13:42:23 2018 GMT Subject: C=CN, ST=ChengDu, L=ChengDu, O=HRX, OU=HRX, CN=HRX/emailAddress=comedshang@163.com Subject Public Key Info: Public Key Algorithm: rsaEncryption RSA Public Key: (2048 bit) Modulus (2048 bit): 00:e5:06:e7:94:b4:ff:ad:ae:26:9c:2c:76:2e:d2: c7:f6:b3:51:9a:15:1f:d6:6f:ee:f7:7b:13:61:b5: d5:07:de:6f:e4:78:05:cc:b3:74:fc:c4:ec:7f:07: c7:b3:1b:c3:b6:c5:e8:9a:00:48:5c:e3:7c:51:e2: 34:1d:0e:e0:2f:4f:3d:4a:68:e3:fd:b4:c2:79:7f: f3:ac:24:6d:71:d6:44:7a:97:7a:10:e0:5b:2e:1c: 80:91:71:4c:45:e8:97:2c:5d:30:68:1c:2a:28:96: 24:1a:a2:40:ad:d8:aa:9b:d8:3b:89:e4:eb:a0:77: a4:1f:ab:5f:7d:8e:82:37:1d:c5:f5:9d:d6:5a:19: ea:5e:57:35:f9:ba:63:66:f0:4c:48:97:22:8f:2f: bf:7f:51:fe:bf:20:01:3c:17:11:9d:82:01:7c:f5: 31:04:c7:33:10:75:5c:2a:b0:ae:d1:12:fe:6e:b9: 5b:cf:67:1e:78:b6:ae:87:70:65:f8:c6:88:c6:10: 7c:58:f5:7e:15:8a:47:97:9c:e1:68:7b:ed:7c:db: e5:6a:de:c1:4b:a1:05:6d:da:1e:bf:44:f9:05:6b: bb:c3:41:f3:f5:a8:39:7a:2b:eb:ac:d9:61:30:bf: 0d:56:54:f8:39:b9:fc:01:93:5a:1d:aa:bf:2f:c8: 30:97 Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Subject Key Identifier: CB:3C:17:D8:D4:F1:C2:7C:00:57:46:48:1F:9B:A2:4F:DA:9A:92:66 X509v3 Authority Key Identifier: keyid:CB:3C:17:D8:D4:F1:C2:7C:00:57:46:48:1F:9B:A2:4F:DA:9A:92:66 DirName:/C=CN/ST=ChengDu/L=ChengDu/O=HRX/OU=HRX/CN=HRX/emailAddress=comedshang@163.com serial:9F:56:FD:F5:9D:13:2E:D2 X509v3 Basic Constraints: CA:TRUE Signature Algorithm: sha1WithRSAEncryption b1:6e:10:48:3c:4b:d1:4d:6e:5c:14:34:79:89:e0:95:3e:48: 3d:53:6c:65:64:ce:90:e2:da:17:2f:e2:8e:13:6a:1c:e2:d8: b9:4c:f2:24:19:60:64:ae:66:cb:e6:82:de:a5:22:40:8e:50: 94:4c:5f:87:6e:f6:c4:be:ff:3b:75:eb:3a:f5:eb:aa:47:c4: 5c:14:d9:7d:38:ee:28:8c:96:8f:22:a1:85:63:a9:e3:23:d2: 64:fe:50:dd:ab:4e:53:f6:f7:67:c1:ec:39:89:20:04:f1:3f: f1:18:5a:ab:77:eb:02:d3:93:34:ca:e8:81:6b:6f:60:5c:9d: b7:1f:e9:be:cb:9a:b2:73:47:52:d7:d6:89:ce:34:4c:46:3c: c3:73:9f:93:07:72:41:d4:64:f9:f1:52:56:78:ac:96:fe:da: b5:c0:b3:8f:e0:5e:8c:a3:bf:21:d7:99:27:ff:65:e4:62:8c: 15:14:8f:bb:04:54:30:4e:5e:32:a8:8c:ab:70:27:14:99:5e: 9b:11:dc:0a:e8:d4:59:8b:98:de:30:b3:5e:f2:8c:e4:b3:2b: 62:07:9a:74:52:c0:e3:54:4c:86:4b:cd:88:f3:6b:1a:c8:66: d6:ab:1d:c5:12:e2:66:0a:01:a8:3d:0c:f8:d4:ac:1d:74:80: 83:06:3f:6d 备注，要参看其它证书类型的内容，参考 https://www.digitalocean.com/community/tutorials/openssl-essentials-working-with-ssl-certificates-private-keys-and-csrs#view-certificates 一些特性， 首先，我们可以看到不像 𝐶𝐴CA 证书那样有多层证书结构，自签名证书只有一层证书结构；也就是没有 Certificate Chain 的概念； 再次，可以看到 Issuer 发布者和证书拥有者 Subje","date":"2021-03-03","objectID":"/rsa%E4%B8%83-x.509-%E8%87%AA%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6/:0:0","tags":["RSA"],"title":"RSA(七) X.509 自签名证书","uri":"/rsa%E4%B8%83-x.509-%E8%87%AA%E7%AD%BE%E5%90%8D%E8%AF%81%E4%B9%A6/"},{"categories":null,"content":"前言 由前文 RSA(五) PKI (Public Key Infrastructure) 公钥基础设施可知，CA 证书授权中心颁发给用户的是一张 X.509 证书；本篇文章，博主将带领大家一探 X.509 证书的究竟； 重要：本文为作者的原创作品，转载需注明出处； 转载至https://www.shangyang.me/2017/05/27/encrypt-rsa-selfsigned-certificate/ 通过 CSR 申请 X509 CA 证书 这里大致讲解如何申请 X.509 CA 证书的流程， 用户先在本地通过 RSA 生成一对公钥 𝐾𝑝Kp 和密钥 𝐾𝑠Ks， 然后，用户在本地生成一张 𝐶𝑆𝑅CSR 证书，既 Certificate Signing Request 需要填写诸如你的域名，公司名，部门名称，城市名，地区名，国家名，电子邮件等等证明你身份的信息， 添加用户公钥 𝐾𝑝 将上述信息通过 𝐾𝑠 进行签名得到 𝑆𝑐𝑠𝑟 将上述的签名 𝑆𝑐𝑠𝑟、𝐾𝑝 以及身份信息合并成为一张 𝐶𝑆𝑅 证书 ; TODO: 需要合并 𝑆𝑐𝑠𝑟 吗？这个还需要进一步求证…… 申请者通过向 CA 中心或者 RA 中心提交 𝐶𝑆𝑅 证书，申请 X.509 证书； 𝐶𝐴 中心用它的密钥 𝐾𝑠(𝑐𝑎)Ks(ca) 对用户提交的 𝐶𝑆𝑅 证书进行签名，将签名和 𝐶𝑆𝑅 合并生成一张 X.509 证书；详细的签名过程， 𝐶𝐴 中心通过签名算法(比如 MD5)对 𝐶𝑆𝑅 证书进行签名； 然后通过 𝐾𝑠(𝑐𝑎)) 对上述的签名进行加密，得到加密后的签名； 最后，将加密后的签名和用户提交的 𝐶𝑆𝑅合并成为一张 X.509 证书； 最后将该 X.509 证书 颁发给用户； 备注，如何生成 CSR 证书可以参考 https://www.sslshopper.com/article-most-common-openssl-commands.html 证书链 Certificate Chain ","date":"2021-03-03","objectID":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/:0:0","tags":["RSA"],"title":"RSA(六) X.509 CA 证书","uri":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/"},{"categories":null,"content":"什么是证书链 X.509 证书 中往往不止一张证书，而是由一系列的证书所组成的证书链，通常包含这样三层证书所构成的证书链， root certificate，根证书 intermediates certificates，一系列中间证书 end-user certificate，终端用户证书 相信大部分读者会和我一样，迷惑，为什么一张 X.509 证书要搞得这么复杂？ 这样做其实是有历史原因的，那是因为随系统和浏览器预安装的根证书毕竟是有限的，往往就那么些，一旦系统已经发布，大部分用户也已经安装好了，Root Certificate 既根证书就没有办法再通过预安装的方式来进行扩充了；但是我们知道，会有日新月异的新的 CA 公司成立，并被允许授权颁发 X.509 证书，毕竟，我们要允许市场的充分竞争，那么它们的公钥如何预安装到客户端的浏览器和操作系统上呢？如果不能预安装，由前文如何保证公钥不被篡改的分析可知，它们所颁发的证书是不可靠的，是可以被篡改的；那么如何调和这个矛盾呢？该怎么办呢？ 于是，intermediates certificates 中间证书就出现了，这些证书就是表示由 Root Certificate 证书所签名认证的证书，这样，新的 CA 公司所颁发的证书可以由 Root Certificate 进行认证，保证其合法性和可靠性，这样就充分允许了新的 CA 公司成立并参与 CA 这块市场的竞争了； 下面，就用这么一个形象的例子来描述，比如，有一天，中国成立了一家 ShangYang 公司，该公司的主营业务就是为广大客户进行证书授权，参与 CA 领域的商业竞争；那么这个时候呢，我需要向掌管 Root Certificate 的机构提交申请，请它签名我的 CA 公钥 (说好的市场充分竞争呢？Root Certificate 机构不就是赤裸裸的垄断机构？谁知道呢..)，生成一张 intermediates certificate 中间证书；这样，由 ShangYang 公司所签名的证书就得到了 Root Certificate 的认证，那么由该公司所颁发的 X.509 证书就是合法，正规的了； 由此，我们也能够大致知道整个证书链的验证过程了，证书链的验证过程将会在后续证书链的验证过程进行详细的描述； 总结一下， 根证书是被预装到客户端电脑或者用户其它终端设备上的(比如手机)，它的作用主要是验证 CA 证书签名的合法性，也就是保证 CA 的证书(含 CA 的公钥)的合法性；最后，end-user certificate 终端用户证书，该证书由 CA 的证书保证其合法性；所以，可以看到，各个证书的验证过程是一环扣一环的，根证书验证 CA 证书的合法性，CA 证书验证用户证书的合法性； ","date":"2021-03-03","objectID":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/:1:0","tags":["RSA"],"title":"RSA(六) X.509 CA 证书","uri":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/"},{"categories":null,"content":"证书链中每个证书所包含的内容 我们来看看 wikipedia.org 的 X.509 证书的情况，他是由 GlobalSign 机构颁发的， ","date":"2021-03-03","objectID":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/:2:0","tags":["RSA"],"title":"RSA(六) X.509 CA 证书","uri":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/"},{"categories":null,"content":"End-user(或 End-entity) certificate 既终端用户证书 Certificate: Data: Version: 3 (0x2) Serial Number: 10:e6:fc:62:b7:41:8a:d5:00:5e:45:b6 Signature Algorithm: sha256WithRSAEncryption Issuer: C=BE, O=GlobalSign nv-sa, CN=GlobalSign Organization Validation CA - SHA256 - G2 Validity Not Before: Nov 21 08:00:00 2016 GMT Not After : Nov 22 07:59:59 2017 GMT Subject: C=US, ST=California, L=San Francisco, O=Wikimedia Foundation, Inc., CN=*.wikipedia.org Subject Public Key Info: Public Key Algorithm: id-ecPublicKey Public-Key: (256 bit) pub: 04:c9:22:69:31:8a:d6:6c:ea:da:c3:7f:2c:ac:a5: af:c0:02:ea:81:cb:65:b9:fd:0c:6d:46:5b:c9:1e: ed:b2:ac:2a:1b:4a:ec:80:7b:e7:1a:51:e0:df:f7: c7:4a:20:7b:91:4b:20:07:21:ce:cf:68:65:8c:c6: 9d:3b:ef:d5:c1 ASN1 OID: prime256v1 NIST CURVE: P-256 X509v3 extensions: X509v3 Key Usage: critical Digital Signature, Key Agreement Authority Information Access: CA Issuers - URI:http://secure.globalsign.com/cacert/gsorganizationvalsha2g2r1.crt OCSP - URI:http://ocsp2.globalsign.com/gsorganizationvalsha2g2 X509v3 Certificate Policies: Policy: 1.3.6.1.4.1.4146.1.20 CPS: https://www.globalsign.com/repository/ Policy: 2.23.140.1.2.2 X509v3 Basic Constraints: CA:FALSE X509v3 CRL Distribution Points: Full Name: URI:http://crl.globalsign.com/gs/gsorganizationvalsha2g2.crl X509v3 Subject Alternative Name: DNS:*.wikipedia.org, DNS:*.m.mediawiki.org, DNS:*.m.wikibooks.org, DNS:*.m.wikidata.org, DNS:*.m.wikimedia.org, DNS:*.m.wikimediafoundation.org, DNS:*.m.wikinews.org, DNS:*.m.wikipedia.org, DNS:*.m.wikiquote.org, DNS:*.m.wikisource.org, DNS:*.m.wikiversity.org, DNS:*.m.wikivoyage.org, DNS:*.m.wiktionary.org, DNS:*.mediawiki.org, DNS:*.planet.wikimedia.org, DNS:*.wikibooks.org, DNS:*.wikidata.org, DNS:*.wikimedia.org, DNS:*.wikimediafoundation.org, DNS:*.wikinews.org, DNS:*.wikiquote.org, DNS:*.wikisource.org, DNS:*.wikiversity.org, DNS:*.wikivoyage.org, DNS:*.wiktionary.org, DNS:*.wmfusercontent.org, DNS:*.zero.wikipedia.org, DNS:mediawiki.org, DNS:w.wiki, DNS:wikibooks.org, DNS:wikidata.org, DNS:wikimedia.org, DNS:wikimediafoundation.org, DNS:wikinews.org, DNS:wikiquote.org, DNS:wikisource.org, DNS:wikiversity.org, DNS:wikivoyage.org, DNS:wiktionary.org, DNS:wmfusercontent.org, DNS:wikipedia.org X509v3 Extended Key Usage: TLS Web Server Authentication, TLS Web Client Authentication X509v3 Subject Key Identifier: 28:2A:26:2A:57:8B:3B:CE:B4:D6:AB:54:EF:D7:38:21:2C:49:5C:36 X509v3 Authority Key Identifier: keyid:96:DE:61:F1:BD:1C:16:29:53:1C:C0:CC:7D:3B:83:00:40:E6:1A:7C Signature Algorithm: sha256WithRSAEncryption 8b:c3:ed:d1:9d:39:6f:af:40:72:bd:1e:18:5e:30:54:23:35: ... 上面这张证书就是 wikipedia.org 的终端用户证书了，看看几个关键的属性 Subject Subject: C=US, ST=California, L=San Francisco, O=Wikimedia Foundation, Inc., CN=*.wikipedia.org 可以看到该证书的主体结构，表示该证书的主体机构是 wikipedia.org，以及相关的一些附属信息，比如国家，地域，公司名称等等； Subject Alternative Name 表述了该证书还可以用在哪些域名上，这里定义了好些其它的可用域名的验证上， X509v3 Subject Alternative Name: DNS:*.wikipedia.org, DNS:*.m.mediawiki.org, DNS:*.m.wikibooks.org, DNS:*.m.wikidata.org, DNS:*.m.wikimedia.org, DNS:*.m.wikimediafoundation.org, DNS:*.m.wikinews.org, DNS:*.m.wikipedia.org, DNS:*.m.wikiquote.org, DNS:*.m.wikisource.org, DNS:*.m.wikiversity.org, DNS:*.m.wikivoyage.org, DNS:*.m.wiktionary.org, DNS:*.mediawiki.org, DNS:*.planet.wikimedia.org, DNS:*.wikibooks.org, DNS:*.wikidata.org, DNS:*.wikimedia.org, DNS:*.wikimediafoundation.org, DNS:*.wikinews.org, DNS:*.wikiquote.org, DNS:*.wikisource.org, DNS:*.wikiversity.org, DNS:*.wikivoyage.org, DNS:*.wiktionary.org, DNS:*.wmfusercontent.org, DNS:*.zero.wikipedia.org, DNS:mediawiki.org, DNS:w.wiki, DNS:wikibooks.org, DNS:wikidata.org, DNS:wikimedia.org, DNS:wikimediafoundation.org, DNS:wikinews.org, DNS:wikiquote.org, DNS:wikisource.org, DNS:wikiversity.org, DNS:wikivoyage.org, DNS:wiktionary.org, DNS:wmfusercontent.org, DNS:wikipedia.org Subject Public Key Subject Public Key Info: Public Key Algorithm: id-ecPublicKey Public-Key: (256 bit) pub: 04:c9:22:69:31:8a:d6:6c:ea:da:c3:7f:2c:ac:a5: af:c0:02:ea:8","date":"2021-03-03","objectID":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/:2:1","tags":["RSA"],"title":"RSA(六) X.509 CA 证书","uri":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/"},{"categories":null,"content":"Intermediate certificate 既 CA 证书 Certificate: Data: Version: 3 (0x2) Serial Number: 04:00:00:00:00:01:44:4e:f0:42:47 Signature Algorithm: sha256WithRSAEncryption Issuer: C=BE, O=GlobalSign nv-sa, OU=Root CA, CN=GlobalSign Root CA Validity Not Before: Feb 20 10:00:00 2014 GMT Not After : Feb 20 10:00:00 2024 GMT Subject: C=BE, O=GlobalSign nv-sa, CN=GlobalSign Organization Validation CA - SHA256 - G2 Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) Modulus: 00:c7:0e:6c:3f:23:93:7f:cc:70:a5:9d:20:c3:0e: ... Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Key Usage: critical Certificate Sign, CRL Sign X509v3 Basic Constraints: critical CA:TRUE, pathlen:0 X509v3 Subject Key Identifier: 96:DE:61:F1:BD:1C:16:29:53:1C:C0:CC:7D:3B:83:00:40:E6:1A:7C X509v3 Certificate Policies: Policy: X509v3 Any Policy CPS: https://www.globalsign.com/repository/ X509v3 CRL Distribution Points: Full Name: URI:http://crl.globalsign.net/root.crl Authority Information Access: OCSP - URI:http://ocsp.globalsign.com/rootr1 X509v3 Authority Key Identifier: keyid:60:7B:66:1A:45:0D:97:CA:89:50:2F:7D:04:CD:34:A8:FF:FC:FD:4B Signature Algorithm: sha256WithRSAEncryption 46:2a:ee:5e:bd:ae:01:60:37:31:11:86:71:74:b6:46:49:c8: ... Intermidate certificate 既是 𝐶𝐴 证书，是用来验证用户终端证书(既 End-entity certificate)的；通过两个字段来匹配用户终端证书， 𝐶𝐴 证书中的 Issuer 和用户终端证书中的 Issuer 相匹配 𝐶𝐴 证书中的 Subject Key Identifier 与用户终端证书中的 Authority Key Identifier 相匹配； X509v3 Subject Key Identifier: 96:DE:61:F1:BD:1C:16:29:53:1C:C0:CC:7D:3B:83:00:40:E6:1A:7C 与 𝐶𝐴 证书相匹配的用户终端证书将会被该 𝐶𝐴 证书所验证； ","date":"2021-03-03","objectID":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/:2:2","tags":["RSA"],"title":"RSA(六) X.509 CA 证书","uri":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/"},{"categories":null,"content":"Root Certificate 既根证书 Certificate: Data: Version: 3 (0x2) Serial Number: 04:00:00:00:00:01:15:4b:5a:c3:94 Signature Algorithm: sha1WithRSAEncryption Issuer: C=BE, O=GlobalSign nv-sa, OU=Root CA, CN=GlobalSign Root CA Validity Not Before: Sep 1 12:00:00 1998 GMT Not After : Jan 28 12:00:00 2028 GMT Subject: C=BE, O=GlobalSign nv-sa, OU=Root CA, CN=GlobalSign Root CA Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) Modulus: 00:da:0e:e6:99:8d:ce:a3:e3:4f:8a:7e:fb:f1:8b: ... Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Key Usage: critical Certificate Sign, CRL Sign X509v3 Basic Constraints: critical CA:TRUE X509v3 Subject Key Identifier: 60:7B:66:1A:45:0D:97:CA:89:50:2F:7D:04:CD:34:A8:FF:FC:FD:4B Signature Algorithm: sha1WithRSAEncryption d6:73:e7:7c:4f:76:d0:8d:bf:ec:ba:a2:be:34:c5:28:32:b5: ... Intermediate certificate 既是 𝐶𝐴 证书将会被 Root certificate 进行验证，并且 Root certificate 是证书验证链中的最后一环，所以的验证将会到此为止；那么 𝐶𝐴 证书又是如何找到对应的 Root certificate 进行验证的呢？主要通过如下的规则进行匹配 𝐶𝐴 证书中的 Issuer 需要与 Root certificate 中的 Issuer 匹配 𝐶𝐴 证书中的 Authority Key Identifier 字段需要与 Root certificate 证书中的 Subject Key Identifier 字段相匹配 这样，与之匹配的 𝐶𝐴 证书将会由该 Root certificate 证书进行验证； 最后，需要强调的是，𝐶𝐴 证书并不会随浏览器和系统的安装而预安装到用户的设备上，被预安装到用户设备上的只有 Root certificate；这样呢，就保证了终端用户的公钥的可靠性和安全性；另外，通过 Root certificate 会被安装到系统的 trust store中，主流的有 Microsoft Root Program Apple Root Program Mozilla Root Program Oracle Java root program Adobe AATL and EUTL root programs (used for document signing) 后续有时间的话，准备对 Java 的 trust store 进行一下梳理和介绍； ","date":"2021-03-03","objectID":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/:2:3","tags":["RSA"],"title":"RSA(六) X.509 CA 证书","uri":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/"},{"categories":null,"content":"证书链的验证过程 有了上述分析以后，证书链的验证过程就显而易见了 End-user certificate 通过 𝐶𝐴 证书进行验证 𝐶𝐴 证书经过 Root certificate 证书进行验证 完毕 实践 那么这里作者带领大家通过 CSR 的方式申请一个免费的 CA 证书，现在通过阿里云可以免费申请一个固定域名的 Symantec 的 CA 证书； 登录阿里云产品中心，选择安全 -\u003e CA 证书 然后选择免费的 DV 类型的证书 购买好了以后，进入管理后台管理，进入安全（云盾）-\u003e 证书服务，然后对证书进行补全补全既是需要用户自己提交 CSR 申请证书； 填写域名信息，注意，这里只能绑定一个唯一的域名，且不能写任何的通配符 下一步将会填写一些个人信息，比如姓名、手机号码、地址等这里要强调的是，阿里云需要验证域名的归属，既验证该域名的确归你所有；可以通过 DNS 和 文件 的两种方式进行验证；这里呢，我选择的是通过 DNS 验证，验证的大致过程是，阿里会向你的申请邮箱中发送一份邮件，邮件的内容中包含了如何验证域名的方法，里面包含一条用于验证的 TXT 记录，这个需要到个人域名管理中心去配置 TXT 转发规则即可； 好了，这一步是关键了，这里有两个选项，由系统生成 CSR 或者自己生成 CSR，这里为了演示自提交 CSR 证书申请的方式，所以，我们选择自己生成 CSR 使用 openssl 命令生成 CSR $ openssl req -out CSR.csr -new -newkey rsa:2048 -nodes -keyout private.key 然后提示输入国家、地址、姓名、域名、邮箱等等信息；如果是为公司申请邮箱，那么这里填写公司相关信息即可；这里尤其要注意的是，在输入域名的时候，必须与第 4 步的域名相匹配，否则第 9 步审核不能通过，输入域名的时候，提示输入 Common Name (e.g. server FQDN or YOUR name) [] 的信息；最后会在本地生成两个文件，CSR.csr 和 private.key 用文本编辑器打开 CSR.csr，可以看到大致内容如下 -----BEGIN CERTIFICATE REQUEST----- MIIC3DCCAcQCAQAwgZYxCzAJBgNVBAYTAkNOMRAwDgYDVQQIEwdTaWNodWFuMRAw DgYDVQQHEwdDaGVuZ2R1MRQwEgYDVQQKEwtIdWlSb25nWGluZzEUMBIGA1UECxML SHVpUm9uZ1hpbmcxFDASBgNVBAMTC0h1aVJvbmdYaW5nMSEwHwYJKoZIhvcNAQkB FhJodWlyb25neGluZ0BocnguYWkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK AoIBAQC7MY7hTjbv7DkGoDTmvQ2toAe8nMTlQGPh+r4VvD+zzEiEudFPEI1cIFLr BLTfSyn9Awv7lgIjhJ4ghDkjAGwHnrTxzvldjfZkpKuBK9H8Vy2t7sorgoxEBF7j VbiiTBtSG6+ZNw8esqt5EECT19aP/RyJp65f8lysHwcHmZmVGaDq/VwQcbyuI6Vs ko/7sSchOAgUWn66oS+xw7mGYR212mQv6Bz0g0L1NVep8Doz8O2pWPHT1ZOdpBDU rzJJxHXzUgKVgYsAgMBAAGgADANBgkqhkiG9w0BAQUFAAOCAQEA V6rSXeGO4Z0q2sZ9gbdUBmpQ8AAdloByhd1BcwHuHt/nfPj59L3CT3EnTEez7cDt RUCbI2FbThBFfjngfTNE3PjsTsheCdAxoV6yRPo7Fpb5AKkhXDra1jjVjsY0maFl N23okpDCMzmUD2peKqumYhdHBw8wB3Y5HZQxxq688DwlHn0bLnylUPk/hDfuMzIs 5vLIyDSGQiCwq9sU8wjhQOXqzZ37FgJcZ8GyvaJ3kUWDlLDPIGMiXQ0p4T39/ZaE my/C0JxSLiAKJs3L2f7HfKwUoRZDDnCS0WMdQunvxC4Dd7hyddCij6E1ExnT7EzC kiPq8xiGl2HRGW/JfWC3XA== -----END CERTIFICATE REQUEST----- 可以看到，是一个经过 Base64 编码的 PEM 格式的内容； 将上述内容复制，粘贴到阿里证书服务页面，点击保存注意第 7 步的描述，必须保证 CSR 中的域名地址与第 4 步申请的时候填写的域名地址相匹配才行； 验证域名的归属 由于第 5 步中，作者是选择的 DNS 验证的方式，所以，第 9 步完成以后，阿里会发送一封邮件包含需要验证的 TXT 记录值，这里只需要到域名管理中心配置一下 TXT 值，即可验证通过；域名管理中心配置好了以后，大致内容如下，不过，有时候，邮件迟迟不发送，这个时候，你可以直接点击进度按钮，也可以显示相关的 TXT 记录； 申请成功，当验证通过以后，状态便会变为已签发这个时候，你就可以在证书管理后台中去下载该 CA 证书了.. All done… 后记于 2018-01-30 1:21 pm 阿里云上验证域名归属的步骤有变化，也就是上面的第 10 步，在添加主机记录的时候前面要加上 _dnsauth 前缀才行，如图 并且不再发邮件提示配置知己记录 TXT 值了；对应的域名配置如下， 更多详情参考 https://bbs.aliyun.com/read/573056.html?spm=a2c4e.11155515.0.0.kL3FVf 后续 这里主要讲解的是通过 𝐶𝐴 签名的证书，那如果，只是内网服务器，不需要连接外网，那么，实际上，我也就用不到这种公共的基础设施来保证我的证书的合法性；这个时候，X.509 证书还提供了一种自签名证书，什么意思呢？就是说，你可以自己生成 Root certificate，然后将它加入你本机的 trust store 中，用它来验证你的证书的合法性，这就是自签名证书了；详情参考 ","date":"2021-03-03","objectID":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/:3:0","tags":["RSA"],"title":"RSA(六) X.509 CA 证书","uri":"/rsa%E5%85%AD-x.509-ca-%E8%AF%81%E4%B9%A6/"},{"categories":null,"content":"前言 在上一篇《RSA(四) 签名 Signature》章节签名 Signature 中提到，要使用签名(Signature)机制来保证信息再传递过程中没有被第三方所篡改，有一个前提，就是必须保证，在公钥的传递过程中不被他人篡改，否则，整个签名机制就形同一张白纸，毫无用处；那么又该如何保证公钥的合法性，保证公钥本身没有被篡改过呢？这就是 PKI 公钥基础设施要完成的工作和达到的目的； 备注，本文是作者的原创作品，转载请注明出处。 转载至https://www.shangyang.me/2017/05/25/encrypt-rsa-pki/ 公钥被篡改 首先，我们来看看，在通讯过程中，公钥是如何被他人所篡改的？也就是 Man in Middle Attack 是怎么做到的？ 先来看一个正常的，通过公钥和私钥加密通讯的场景， 服务器端生成公钥和私钥，并将公钥通过网络发送给客户端，客户端使用公钥加密 DES 对称加密密钥，然后将 DES 密钥发送给服务器端，之后，双方便可以进行加密通讯了；备注，这也是基于 RSA 加密通讯的基础；但是，这样做，并不可靠，下面我们再来看一个公钥被挟持并被篡改的场景； 这次通讯的时候，不幸的是，客户端与服务器通讯的时候，正好经过了一个黑客的路由器，通过网络嗅探，它截获了服务器所发送的公钥，并利用自己的私钥，生成了一个新的公钥，并替代原有的公钥并将这个新的公钥发送给了客户端，这个过程就是公钥被截获，被篡改的过程；而后，客户端将使用被篡改过后的公钥进行加密通讯，所以，凡是经过客户端加密的信息，全部可以被黑客的私钥解密，也就导致了，加密通讯彻底失效；正是在这种背景之下，PKI (Public Key Infrasture) 公钥基础设施孕育而生； 后记，发现还漏了一环，首先要知道的是，当通过 RSA 建立好 SSL 通讯通道以后，实际上，为了效率，该通道上数据实际上是通过对称加密密钥 AES 进行加密传输的，所以，能否保证数据通讯的安全性的重中之重的环节就是保证 AES 密钥在传输过程中的安全性，正如上图所描述的那样，当黑客截获到加密后的 AES 密钥以后，首先需要通过黑客自己的私钥对其解密，然后再通过黑客所截获的服务器的公钥对该 AES 密钥进行加密，然后再传输给服务器端，如果不这样做的话，服务器是无法通过它自己的私钥解密出 AES 密钥的；（后记于 2018-01-30 10:45AM） PKI PKI 的核心职责就是通过一些列的措施保证公钥的合法性，那么它是如何保证公钥不被篡改，是合法的呢？ ","date":"2021-03-03","objectID":"/rsa%E4%BA%94-pki-public-key-infrastructure-%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/:0:0","tags":["RSA"],"title":"RSA(五) PKI (Public Key Infrastructure) 公钥基础设施","uri":"/rsa%E4%BA%94-pki-public-key-infrastructure-%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"},{"categories":null,"content":"如何保证公钥不被篡改的 比如 Alice 通过 RSA 生成了公钥 𝐾𝑝Kp 和密钥 𝐾𝑠Ks，她需要与 Bob 进行网络通讯，而且她必须通过网络将公钥 𝐾𝑝Kp 发送给 Bob；那么 PKI 是如何保证此公钥 𝐾𝑝Kp 在传输过程中不被篡改的呢？ 简而言之，PKI 的策略就是通过一个第三方机构 𝑀M，该机构 𝑀M 也有自己的公钥 𝐾𝑝(𝑚)Kp(m) 和密钥 𝐾𝑠(𝑚)Ks(m)； 首先通过该机构 𝑀M 进行如下的操作， Alice 将自己的公钥 𝐾𝑝Kp 提交给 𝑀M； 𝑀M 使用签名算法，比如 MD5，对 Alice 的原生公钥 𝐾𝑝Kp 进行签名得到 𝑆𝑝Sp； 然后再通过 𝐾𝑠(𝑚)Ks(m) 对 𝑆𝑝Sp 进行加密得到加密后的签名 𝐸𝑠𝑝Esp； 最后将 𝐸𝑠𝑝Esp 颁发给 Alice； Alice 如何将公钥发送给 Bob？ Alice 将加密后的签名 𝐸𝑠𝑝Esp 和公钥 𝐾𝑝Kp 一起发送给 Bob； 备注，其实签名 𝐸𝑠𝑝Esp 和公钥 𝐾𝑝Kp 被纳入一张证书(Certificate)中，Alice 发送给 Bob 的其实就是这么一张证书；但是，整整 X.509 证书包含的内容比这个复杂许多，不过概念上是等价的；这里，也就是证书的由来了。不仅要知其然，更要知其所以然.. Bob 如何保证接收到的 Alice 的公钥没有被篡改过？ Bob 拿到 Alice 的证书以后，做如下操作，(为了区分，这里将传输过程中 Alice 的公钥命名为 𝐾′𝑝Kp′) 通过 𝑀M 的公钥 𝐾𝑝(𝑚)Kp(m) 对 𝐸𝑠𝑝Esp 进行解密，得到 𝑆𝑝Sp； 注意，如果 𝐸𝑠𝑝Esp 被篡改了，这里是无法解密得到 𝑆𝑝Sp，也就是说，要保证解密成功，𝐸𝑠𝑝Esp 一定是没有被篡改过的； 然后使用双方所约定好的签名算法，比如 MD5，对 𝐾′𝑝Kp′ 进行签名，得到 𝑆′𝑝Sp′ 最后比较 𝑆𝑝Sp 与 𝑆′𝑝Sp′ 是否相等，若相等，则表示发送过程中的公钥 𝐾′𝑝Kp′ 没有被篡改过，否则，则可以断言，𝐾′𝑝Kp′ 被篡改过，于是整个通讯不安全、不可靠； （备注，这里的机构 𝑀M 有个行业用语叫做 𝐶𝐴CA 既是 Certification Authority；） 等等，第三方机构 CA，在 Bob 端使用 CA 的公钥 𝐾𝑝(𝑐𝑎)Kp(ca) 对 𝐸𝑠𝑝Esp 进行解密，得到签名 𝑆𝑝Sp，那如果 CA 的公钥 𝐾𝑝(𝑐𝑎)Kp(ca) 在传输过程中也被篡改了呢？好问题，第三方机构 CA 自身如何保证其公钥的合法性？如果不能保证 CA 公钥的合法性，上述基于签名保证 Alice 公钥合法性的措施也就是是一纸空谈。 那么，CA 又是如何保证自己的公钥的合法性的呢？ 这里将谈到的就是 KPI 的又一大特征，基础设施； 为了保证 CA 公钥的合法性，通常，CA 机构的公钥是随系统、浏览器等预安装到客户电脑上的，也就是说，你在装系统的时候，或者在安装浏览器的时候，CA 机构的公钥(一般是包含在 CA 证书中的) 被预装到了你的系统或者是浏览器中了；这样，黑客就没有办法通过网络拦截的办法去篡改 CA 机构的公钥了；这也就是基础设施命名的由来，既 Infrastructure；这样，也就保证了通过 CA 机构签名的证书即使是在不安全的网络环境中传播，依然是可靠并且是有效的； ","date":"2021-03-03","objectID":"/rsa%E4%BA%94-pki-public-key-infrastructure-%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/:1:0","tags":["RSA"],"title":"RSA(五) PKI (Public Key Infrastructure) 公钥基础设施","uri":"/rsa%E4%BA%94-pki-public-key-infrastructure-%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"},{"categories":null,"content":"概念流程图 真实过程中，用户是通过 𝐶𝑆𝑅CSR 证书向 𝐶𝐴CA 机构申请 𝑋.509X.509 证书，申请过程中会包含申请者的地址，单位，邮箱等信息，比下图要复杂；这里，主要是化繁为简，通过如下的概念图，将其核心逻辑阐述清楚，下面的逻辑流程图一一对应如何保证公钥不被篡改的中所描述的步骤； 注意两个关键步骤 Step 6.1.1: 断定签名 𝐸𝑠𝑝Esp 被篡改过； 要能够断定这种情况，保证 𝐸𝑠𝑝Esp 一定没有被篡改过，需要公钥基础设施(既 PKI )的保证，保证签名颁发机构 𝑀M 的公钥是无法被篡改的 Step 8.1: 𝑆𝑝!=𝑆′𝑝Sp!=Sp′，则可以断定公钥是被篡改过得； 这里面更深层次的原因是，通过公钥认证机构得到的签名 𝑆𝑝Sp 与 Bob 自己得到的公钥签名 𝑆𝑝Sp 不匹配，则可断定，Alice 的公钥 𝐾𝑝Kp 被篡改过； ","date":"2021-03-03","objectID":"/rsa%E4%BA%94-pki-public-key-infrastructure-%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/:2:0","tags":["RSA"],"title":"RSA(五) PKI (Public Key Infrastructure) 公钥基础设施","uri":"/rsa%E4%BA%94-pki-public-key-infrastructure-%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"},{"categories":null,"content":"KPI 包含哪些元素 在章节如何保证公钥不被篡改的中，作者用最通俗易懂的言语描述了 KPI 公钥基础设施是如何保证公钥的合法性的，以及其重要性；不过，在官方定义中，严格的定义了如下的角色， CA (Certificate Authority)，证书认证机构 对公钥、用户身份信息、域名等信息进行签名，生成相关的电子证书；并将电子证书颁发给申请用户； 另外还会通过其专有的协议来判断证书是否有效（是否超过使用有效期）,如果证书失效，将会生成证书回收列表既是 certificate revocation list ，该部分内容涉及到 Authority revocation lists 的相关内容，从 https://en.wikipedia.org/wiki/Certificate_authority 摘要其核心内容如下， An authority revocation list (ARL) is a form of certificate revocation list (CRL) containing certificates issued to certificate authorities, contrary to CRLs which contain revoked end-entity certificates. https://tools.ietf.org/html/rfc5280#section-4.1.2.6 标注中也描述了有关 CRL 协议和标准； RA (Registration Authority)，注册认证机构 看下 https://en.wikipedia.org/wiki/Public_key_infrastructure 中的描述， A registration authority which verifies the identity of entities requesting their digital certificates to be stored at the CA 是用来验证证书申请机构的身份的；不过现在 CA 和 RA 并没有完全区分，往往两者表示同一个角色； 用户需要像该机构提交一张 CSR 格式的证书(该证书的后缀名为 .csr)，既是 certificate signing request 来申请，里面需要填写诸如你的域名，公司名，部门名称，城市名，地区名，国家名，电子邮件等等证明你身份的信息； 从 #1 中，我们知道，CA 不但会对用户的身份信息以及公钥进行签名，而且会生成相应的电子证书来保存这些签名信息，最终将该证书颁发给用户；而事实上，该电子证书经过数个版本的变化，现在已经形成了一个事实标准，那就是 X.509 证书；作者会在后续的文章中对其进行详细的介绍； ","date":"2021-03-03","objectID":"/rsa%E4%BA%94-pki-public-key-infrastructure-%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/:3:0","tags":["RSA"],"title":"RSA(五) PKI (Public Key Infrastructure) 公钥基础设施","uri":"/rsa%E4%BA%94-pki-public-key-infrastructure-%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"},{"categories":null,"content":"CA 机构 这里描述一下国际知名的 CA 机构有哪些， 如下内容可以从 https://en.wikipedia.org/wiki/Certificate_authority 获得 ","date":"2021-03-03","objectID":"/rsa%E4%BA%94-pki-public-key-infrastructure-%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/:3:1","tags":["RSA"],"title":"RSA(五) PKI (Public Key Infrastructure) 公钥基础设施","uri":"/rsa%E4%BA%94-pki-public-key-infrastructure-%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"},{"categories":null,"content":"前言 由RSA(一) 背后的数学原理可知，RSA 既公钥加密技术主要是通过私钥加密信息，然后由公钥来解密信息；但是，从 RSA 的数学原理中我们可以知道，其实私钥加密信息，然后用公钥来解密也是可以的；而因为公钥是公开的，私钥加密的东西谁都可以进行解密，那这样做有什么意义呢？本章节就是来探讨这样做的意义何在？一句话概括，它的意义就在于签名( sign )； 备注，本文是作者的原创作品，转载请注明出处。 转载至https://www.shangyang.me/2017/05/24/encrypt-rsa-signature/ 场景 来看这样一个场景，Bob 给股票经纪人 Alice 发送了一封邮件，让 Alice 帮他大量购买某支股票；可是刚买不久，股票就大跌，于是 Bob 转而否认发过那封邮件，声称那封邮件是伪造的；那么作为法官的你，如何来验证之前发送的那封邮件到底是不是 Bob 发送的呢？ 要解决上述场景的问题，就需要使用到 RSA 签名技术了； 签名 Signature 为保证邮件是 Bob 发送的，在邮件收发协议上做了如下的操作约定， 首先双方通过邮件协议约定好签名的算法，比如都是用 MD5 或者是其它签名算法。 Bob 在发送邮件的同时，邮件系统将做如下的操作 通过签名算法 MD5 将邮件内容c进行 hash，得到邮件内容的签名(Sign)，记为 𝑆1； 通过 Bob 的私钥 𝑃 对 𝑆1 进行加密，得到加密后邮件内容的签名(Encrypted Sign)，记为 𝑆1𝑒； 最后，Bob 通过邮箱系统将签名 𝑆1𝑒S1e，邮件内容c，以及 Bob 的公钥 𝑃 三部分内容发送给 Alice； 如何保证公钥的安全性和可靠性，不在本文涉及； Alice 收到 Bob 的邮件以后，邮箱系统会做如下的操作 使用 Bob 的公钥对 𝑆1𝑒 进行解密，得到 𝑆1； 使用双方事先约定好的签名算法 MD5 对c进行 hash 得到签名 𝑆2； 比较签名 𝑆1 和签名 𝑆2 是否相等 如果相等，则表示邮件内容没有被篡改； 如果不相等，则表示邮件内容被他人篡改； 不过，要保证信息的确没有被篡改，还有一条基本原则，就是 Bob 的公钥 𝑃 不能被篡改，如果公钥 𝑃 在 Bob 发送给 Alice 的过程被人篡改了，那么 Attacker 就可以自己杜撰一封邮件，并通过自己的私钥签名邮件，并将自己篡改后的公钥 𝑃𝑐Pc 一同发送给 Alice，那么这个时候，Alice 是没有办法确认邮件是否是被篡改过的；所以，用 RSA 签名的方式来保证信息没有被篡改过，一个基本的前提就是 Bob 的公钥 𝑃P 不能被第三方篡改；而要保证公钥不能被第三方篡改，就需要 PKI (Public Key Infrasture) 公钥基础设施来保证公钥的合法性，涉及到 CA，Root Certificate 根证书相关知识；这部分知识不打算在本文进行描述；相关内容参考 RSA(五) PKI (Public Key Infrastructure) 公钥基础设施； 备注：Root Certificate 根证书就是 CA 证书认证机构用来签名验证公钥 𝑃 的； 总结 签名 sign 小节中详细的描述了 RSA 通过私钥签名的过程和作用；但是也知道，签名若要能起作用，必须借助 PKI 公钥基础设施来保证公钥的合法性；所以，可见，PKI 对于基于 RSA 的加密通讯协议起到至关重要的作用，没有它，一切基于 RSA 的加密通讯理论都白搭；后续章节，让我们来看看 PKI 是什么东西； ","date":"2021-03-03","objectID":"/rsa%E5%9B%9B-%E7%AD%BE%E5%90%8D-signature/:0:0","tags":["RSA"],"title":"RSA(四) 签名 Signature","uri":"/rsa%E5%9B%9B-%E7%AD%BE%E5%90%8D-signature/"},{"categories":null,"content":"前言 本篇博文重点描述密钥的种种格式； 备注，本文是作者的原创作品，转载请注明出处。 转载至https://www.shangyang.me/2017/05/24/encrypt-rsa-keyformat/ PEM 和 DER 首先我们来看看什么是 PEM 和 DER ","date":"2021-03-03","objectID":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/:0:0","tags":["RSA"],"title":"RSA(三) 密钥的格式","uri":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/"},{"categories":null,"content":"什么是 DER 格式 DER 是密钥的二进制表述格式； http://fileformats.archiveteam.org/wiki/DER Distinguished Encoding Rules (DER) is a binary serialization of ASN.1 format. It is often used for cryptographic data such as certificates, but has other uses. 很明显，DER 就是 ASN.1 的二进制格式； ","date":"2021-03-03","objectID":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/:1:0","tags":["RSA"],"title":"RSA(三) 密钥的格式","uri":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/"},{"categories":null,"content":"什么是 PEM 格式 PEM 格式既是对 DER 编码转码为 Base64 字符格式；通过解码，将会还原为 DER 格式； http://fileformats.archiveteam.org/wiki/PEM A PEM file is plain text. It contain one or more objects, such as certificates or keys, which may not all be the same type. Each object is delimited by lines similar to “—–BEGIN …—–” and “—–END …—–”. Data that is not between such lines is ignored, and is sometimes used for comments, or for a human-readable dump of the encoded data. Following the “BEGIN” and “END” keywords is a name (such as “CERTIFICATE”) that can be used as an identifier for the type of object. The data between the delimiter lines starts with an optional email-like header section, followed by base64-encoded payload data. After decoding, the payload data is in DER format. 总体而言，PEM 是明文格式，可以包含证书或者是密钥；其内容通常是以类似 “—–BEGIN …—–” 开头 “—–END …—–” 为结尾的这样的格式进行展示的；后续内容也描述到，PEM 格式的内容是 Base64 格式；通过解码，转换为 DER 格式，也就是说，PEM 是建立在 DER 编码之上的； ","date":"2021-03-03","objectID":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/:2:0","tags":["RSA"],"title":"RSA(三) 密钥的格式","uri":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/"},{"categories":null,"content":"总结 DER 实际上就是密钥的最原始的二进制格式；而 PEM 是对 DER 的 Base64 的编码，PEM 解码后得到的就是 DER 编码格式； 格式 由于 DER 是二进制格式，不便于阅读和理解，一般而言，密钥都是通过 PEM 的格式进行存储的，所以，这部分内容主要是梳理出公钥和密钥以 PEM 编码存储的格式； ","date":"2021-03-03","objectID":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/:3:0","tags":["RSA"],"title":"RSA(三) 密钥的格式","uri":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/"},{"categories":null,"content":"公钥 PEM 格式 ","date":"2021-03-03","objectID":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/:4:0","tags":["RSA"],"title":"RSA(三) 密钥的格式","uri":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/"},{"categories":null,"content":"PKCS #1 PKCS #1 标准是专门为 RSA 密钥进行定义的，其对应的 PEM 文件格式如下， -----BEGIN RSA PUBLIC KEY----- BASE64 ENCODED DATA -----END RSA PUBLIC KEY----- 上面的内容 BASE64 ENCODED DATA 指的就是 ANS.1 的 DER 的 Base64 编码，其内容类似于 MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQChHmaw+WUhWrStdxWBcAR39i2e 3yz+vfLiDALeTpWIH1jKiYtvw4nMg6453pXAJSvPn7mKaiGiC3USIt8qTL4eCPi9 yNRDpZ1JRHI8M87VYB4c9KMk6IuVFiYyZ4MBTP87t89yeL9EOrAD0eFgi5fPx3g8 b9QrmnyPhMVjP7ct+wIDAQAB 上述内容翻译成 ASN.1 的格式为，此部分内容参考 RSA public key syntax 公钥语法 小节内容； RSAPublicKey ::= SEQUENCE { modulus INTEGER, -- n publicExponent INTEGER -- e } ","date":"2021-03-03","objectID":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/:4:1","tags":["RSA"],"title":"RSA(三) 密钥的格式","uri":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/"},{"categories":null,"content":"PKCS #8 有前面的分析我们可以知道，PKCS#8 标准定义了一个密钥格式的通用方案，它不仅仅为 RSA 所使用，同样也可以被其它密钥所使用；具体分析参考 RFC5208 Private-Key Information Syntax Specification 其所对应的 PEM 格式定义如下， -----BEGIN PUBLIC KEY----- BASE64 ENCODED DATA -----END PUBLIC KEY----- 注意，这里就没有 RSA 字样了，因为 PKCS#8 是一个通用型的秘钥格式方案；其中的 BASE64 ENCODED DATA 所标注的内容为 PEM 格式中对 DER 原始二进制进行的 BASE64 编码； 所对应的 DER 原始二进制所表述的内容为 PublicKeyInfo ::= SEQUENCE { algorithm AlgorithmIdentifier, PublicKey BIT STRING } AlgorithmIdentifier ::= SEQUENCE { algorithm OBJECT IDENTIFIER, parameters ANY DEFINED BY algorithm OPTIONAL } 重要补充 从这里可以看到，PKCS#8 虽然名字叫做 Private-Key Information Syntax Specification，但是实际上，可以看到，它同样可以用作 Public Key 的格式定义；而 PKCS#8 是站在 PKCS#7 CMS 的基础之上进行编码格式定义的； ","date":"2021-03-03","objectID":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/:4:2","tags":["RSA"],"title":"RSA(三) 密钥的格式","uri":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/"},{"categories":null,"content":"私钥 PEM 格式 ","date":"2021-03-03","objectID":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/:5:0","tags":["RSA"],"title":"RSA(三) 密钥的格式","uri":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/"},{"categories":null,"content":"PKCS #1 PKCS#1 是专门为 RSA 所涉及的，其对应的 PEM 格式如下 -----BEGIN RSA PRIVATE KEY----- BASE64 ENCODED DATA -----END RSA PRIVATE KEY----- 其中的 BASE64 ENCODED DATA 所标注的内容为 PEM 格式中对 DER 原始二进制进行的 BASE64 编码； 原始的 DER 格式结构，既是 ASN.1 的数据结构，此部分内容参考 RSA private key syntax 私钥语法 小节内容； RSAPrivateKey ::= SEQUENCE { version Version, modulus INTEGER, -- n publicExponent INTEGER, -- e privateExponent INTEGER, -- d prime1 INTEGER, -- p prime2 INTEGER, -- q exponent1 INTEGER, -- d mod (p-1) exponent2 INTEGER, -- d mod (q-1) coefficient INTEGER, -- (inverse of q) mod p otherPrimeInfos OtherPrimeInfos OPTIONAL } ","date":"2021-03-03","objectID":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/:5:1","tags":["RSA"],"title":"RSA(三) 密钥的格式","uri":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/"},{"categories":null,"content":"PKCS #8 未加密 其所对应的 PEM 格式定义如下， -----BEGIN PRIVATE KEY----- BASE64 ENCODED DATA -----END PRIVATE KEY----- 注意，这里就没有 RSA 字样了，因为 PKCS#8 是一个通用型的秘钥格式方案；其中的 BASE64 ENCODED DATA 所标注的内容为 PEM 格式中对 DER 原始二进制进行的 BASE64 编码； 所对应的 DER 原始二进制所表述的内容为 PrivateKeyInfo ::= SEQUENCE { version Version, algorithm AlgorithmIdentifier, PrivateKey BIT STRING } AlgorithmIdentifier ::= SEQUENCE { algorithm OBJECT IDENTIFIER, parameters ANY DEFINED BY algorithm OPTIONAL } 加密 由于私钥是非常私密的，所以在存储到时候往往需要对私钥的内容也进行加密， PEM 格式 -----BEGIN ENCRYPTED PRIVATE KEY----- BASE64 ENCODED DATA -----END ENCRYPTED PRIVATE KEY----- DER 格式，既是根据 ASN.1 标准所定义的格式 EncryptedPrivateKeyInfo ::= SEQUENCE { encryptionAlgorithm EncryptionAlgorithmIdentifier, encryptedData EncryptedData } EncryptionAlgorithmIdentifier ::= AlgorithmIdentifier EncryptedData ::= OCTET STRING ","date":"2021-03-03","objectID":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/:5:2","tags":["RSA"],"title":"RSA(三) 密钥的格式","uri":"/rsa%E4%B8%89-%E5%AF%86%E9%92%A5%E7%9A%84%E6%A0%BC%E5%BC%8F/"},{"categories":null,"content":"前言 本章着重描述 RSA PCKS(Public-Key Cryptography Standards Series 公钥加密标准系列)，RSA 又称为公钥加密技术，主要的使用场景是公钥加密、私钥解密（补充，当然，私钥加密，公钥机密也是可行的，但是这样做并不安全，因为公钥是公开的，所有拿到公钥的人都可以解密，也就失去了加密的本质；不过，可以用私钥来进行签名，后续有专门的博文对此进行描述）； 为了定义 RSA 加密的标准系列，IETF 组织总共定义了 15 个子系列标准，分别用在定义标准格式、如何封装、公钥加密封装标准、私钥加密封装标准、网络传输序列化标准等等.. 具体可以参考 wikipedia PCKS 的解释: https://en.wikipedia.org/wiki/PKCS； 下面我就几个核心的系列标准进行描述， 重要：本文为作者的原创作品，转载需注明出处； 转载至https://www.shangyang.me/2017/05/24/encrypt-rsa-keyformat/ 未完待续…. PKCS #1 RSA Cryptography Standard 摘要 wikepedia 中的一段摘要， See RFC 3447. Defines the mathematical properties and format of RSA public and private keys (ASN.1-encoded in clear-text), and the basic algorithms and encoding/padding schemes for performing RSA encryption, decryption, and producing and verifying signatures. 定义了公钥加密技术(RSA)相关的数学属性以及相关的公钥和密钥的格式标准（通过 ASN.1 的格式标准来定义并明文展示），以及为 RSA 进行加密、解密，生成和验证签名等操作定义了基本的算法和编码/补零(padding)的方案； 可以看到，PCKS #1 主要定义了公钥加密技术 RSA 是如何通过计算机来来定义其编码、通讯格式包括公钥私钥的文本格式(通过 ASN.1 来定义)等一系列能够使用计算机来进行通讯和计算的方案； 要注意的是，PCKS #1 定义的都是明文的格式；下面我们来看看 ASN.1 是如何定义私钥和公钥的格式的，来加深我们的认知； ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:0:0","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"ASN.1 ASN.1: https://en.wikipedia.org/wiki/Abstract_Syntax_Notation_One Abstract Syntax Notation One (ASN.1) is an interface description language for defining data structures that can be serialized and deserialized in a standard, cross-platform way. It’s broadly used in telecommunications and computer networking, and especially in cryptography. ASN.1 是一种接口描述性语言，该语言定义了能够进行跨平台、序列化和反序列化的数据格式；它被广泛的用于电子通讯以及计算机网络中，特别是用在密码学的领域；由此可知，ASN.1 定义了一种专用于密码学领域的一种可以进行序列化和反序列化的数据格式； ASN.1 is used in X.509, which defines the format of certificates used in the HTTPS protocol for securely browsing the web, and in many other cryptographic systems. ASN.1 用在 X.509 中，用来定义其证书的格式，该证书用在 HTTPS 安全通讯领域； 那么 RSA 是如何通过 ASN.1 来定义公钥和私钥的数据格式的；看下面的章节，主要参考，https://tools.ietf.org/html/rfc3447#appendix-A ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:1:0","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"RSA public key syntax 公钥语法 https://tools.ietf.org/html/rfc3447#appendix-A.1.1 An RSA public key should be represented with the ASN.1 type RSAPublicKey: RSAPublicKey ::= SEQUENCE { modulus INTEGER, -- n publicExponent INTEGER -- e } The fields of type RSAPublicKey have the following meanings: * modulus is the RSA modulus n. * publicExponent is the RSA public exponent e. 上面通过 ASN.1 定义了公钥的格式，通过一个 ASN.1 的 SEQUENCE 元素分别定义了 modules 和 publicExponent，而 modules 正是代表的 模 N，而 publicExponent 正式代表的随机数 e，而 {𝑁,𝑒}{N,e} 正好表示了公钥； 可见，通过 ASN.1 的 SEQUENCE 元素RSAPublicKey定义了公钥的数据格式，该格式便可以在网络通讯中进行序列化和反序列化； ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:1:1","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"RSA private key syntax 私钥语法 https://tools.ietf.org/html/rfc3447#appendix-A.1.2 RSAPrivateKey ::= SEQUENCE { version Version, modulus INTEGER, -- n publicExponent INTEGER, -- e privateExponent INTEGER, -- d prime1 INTEGER, -- p prime2 INTEGER, -- q exponent1 INTEGER, -- d mod (p-1) exponent2 INTEGER, -- d mod (q-1) coefficient INTEGER, -- (inverse of q) mod p otherPrimeInfos OtherPrimeInfos OPTIONAL } 可见，ASN.1 同样通过一个 SEQUENCE 元素RSAPrivateKey定义了私钥的数据格式，d 既是模反元素，p、q 两质数，exponent1 和 exponent2 分别表示 d 与 (p-1) 和 (p-2) 的余数； 可以看到 ASN.1 定义了 private key 的数据格式； ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:1:2","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"补充 要查看明文的 public key / private key 的 ASN.1 的源数据格式，可以通过工具 http://phpseclib.sourceforge.net/x509/asn1parse.php 查看； PKCS #7 Cryptographic Message Syntax Standard Cryptographic Message Syntax Standard 被加密消息的格式标准，与 PKCS #1 不同，PKCS #7 描述的是如何对公钥和私钥 ASN.1 的文本进行加密的标准；PKCS #1 标准描述的是 RSA 加密技术相关标准的定义；先来看 Wikipedia 上的一段摘要， See RFC 2315. Used to sign and/or encrypt messages under a PKI. Used also for certificate dissemination (for instance as a response to a PKCS #10 message). Formed the basis for S/MIME, which is as of 2010 based on RFC 5652, an updated Cryptographic Message Syntax Standard (CMS). Often used for single sign-on. PKCS #7 通常在一个 PKI 中用来签名或者加密信息，也通常用于证书的传递；PKCS #7 的更新版本参考Cryptographic Message Syntax Standard (CMS)； 从上述的描述中可以知道，PKCS #7 主要定义了消息的加密语法标准； 摘要CMS介绍中的相关重要部分, The CMS describes an encapsulation syntax for data protection. The CMS can support a variety of architectures for certificate-based key management, such as the one defined by the PKIX (Public Key Infrastructure using X.509) working group [PROFILE]. CMS 用来描述数据加密的一种封装语法； CMS 可以用于支持多种多样的证书管理实现，比如 PKIX (X.509 中的公钥管理的内部实现)； Ok，从上述的描述中可以看到，PKCS #7 主要用在 PKI/PKIX 领域中，主要是用来进行公钥加密保存、传输等； ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:2:0","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"PKCS #7 Format https://crypto.stackexchange.com/questions/37084/is-pkcs7-a-signature-format-or-a-certificate-format 这篇文章对 PKCS #7 进行了比较详细的讨论；摘要部分如下， The .p7b or .p7c format is a special case of PKCS#7/CMS: a SignedData structure containing no “content” and zero SignerInfos, but one or more certificates (usually) and/or CRLs (rarely). 可以知道，如果使用 PKCS#7 原生格式，将会使用 .p7c 后缀名，如果使用的是 CMS，那么使用的是 .p7b 后缀； 从 https://tools.ietf.org/html/rfc5652#section-12.1 可以看到详细的 ASN.1 中有关 CMS 的标准定义， 摘要部分信息如下， 数据内容信息 ContentInfo ::= SEQUENCE { contentType ContentType, content [0] EXPLICIT ANY DEFINED BY contentType } ContentType ::= OBJECT IDENTIFIER 数据签名信息 SignedData ::= SEQUENCE { version CMSVersion, digestAlgorithms DigestAlgorithmIdentifiers, encapContentInfo EncapsulatedContentInfo, certificates [0] IMPLICIT CertificateSet OPTIONAL, crls [1] IMPLICIT RevocationInfoChoices OPTIONAL, signerInfos SignerInfos } 签名者信息 SignerInfo ::= SEQUENCE { version CMSVersion, sid SignerIdentifier, digestAlgorithm DigestAlgorithmIdentifier, signedAttrs [0] IMPLICIT SignedAttributes OPTIONAL, signatureAlgorithm SignatureAlgorithmIdentifier, signature SignatureValue, unsignedAttrs [1] IMPLICIT UnsignedAttributes OPTIONAL } 密钥加密算法信息 KeyTransRecipientInfo ::= SEQUENCE { version CMSVersion, -- always set to 0 or 2 rid RecipientIdentifier, keyEncryptionAlgorithm KeyEncryptionAlgorithmIdentifier, encryptedKey EncryptedKey } 被加密数据的信息 EncryptedData ::= SEQUENCE { version CMSVersion, encryptedContentInfo EncryptedContentInfo, unprotectedAttrs [1] IMPLICIT UnprotectedAttributes OPTIONAL } 可见，PKCS#7 定义完整的一整套的用于加密数据，签名，签名者，加密算法等等一系列信息；由此，奠定了其作为 PKI 的基础； ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:3:0","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"PKCS #7 的用途 http://stackoverflow.com/questions/3344527/what-for-are-the-commonly-used-pkcs-standards-pkcs7-pkcs10-and-pkcs12 摘抄部分如下， PKCS#7 lets you sign and encrypt generic data using X.509 certificates. Also PKCS#7 format can be used to store one or more certificates without private keys (private keys can be put as a data payload and encrypted this way). PKCS#7 使得你可以通过使用 X.509 证书对普通的数据进行签名和加密；PKCS#7 也可以用来存放不包含私钥的一个或者多个证书； ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:4:0","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"PKI 前文提到了，PKCS#7 用来保证 PKI 的加密格式标准，保证公钥证书的安全性； Public key infrastructure：https://en.wikipedia.org/wiki/Public_key_infrastructure 公钥基础设施，基础设施包含 CA(certificate authority)、RA、VA 等，从 wikipedia 的描述上来看，主要是为了保证公钥证书颁发途径中的安全性、保密性.. 等等相关措施，目的就是为了在公钥证书传递过程中，避免公钥被串改以后信息的不安全性.. TODO，将来准备单独写一章关于 PKI 的博文来详细的描述此类相关内容。 PKCS #8 Private-Key Information Syntax Standard Private-Key Information Syntax Standard 私钥信息格式标准，看 Wikipedia 的描述， See RFC 5958. Used to carry private certificate keypairs (encrypted or unencrypted). 用来携带加密的或者未加密的私钥证书；也就是说，PKCS#8 定义了私钥的加密和未加密的格式； 备注，最开始 PKCS#8 标准是由 RFC5208 标准定义，但是后来为了更好的支持 PKI 基础设施，由新的标准 RFC 5958 替换了原来的 RFC5208 标准，这部分内容可以从后续部分 RFC5958 Asymmetric Key Packages中了解；但因为 RFC5208 更简明，所以，这里首先介绍 RFC5208 的标准内容； ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:5:0","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"RFC5208 Private-Key Information Syntax Specification 该文档中主要包含了两个部分，private key 的原始格式 private key info 和 private key 的加密格式 encrypted private key info； https://tools.ietf.org/html/rfc5208 ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:6:0","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"private key info Private-key information shall have ASN.1 type PrivateKeyInfo: PrivateKeyInfo ::= SEQUENCE { version Version, privateKeyAlgorithm PrivateKeyAlgorithmIdentifier, privateKey PrivateKey, attributes [0] IMPLICIT Attributes OPTIONAL } Version ::= INTEGER PrivateKeyAlgorithmIdentifier ::= AlgorithmIdentifier PrivateKey ::= OCTET STRING Attributes ::= SET OF Attribute 可以看到，通过 ASN.1 格式封装了私钥，重要的有两个字段，privateKeyAlgorithm 和 privateKey； privateKeyAlgorithm 表示采用的是什么算法，可以是 RSA，也可以是其它的算法，比如 DES、AES 等对称加密算法等。 privateKey 通过其类型可以知道，是一个 PrivateKey ::= OCTET STRING 可见，其由一个八位字节字符串组成；这就是私钥的内容，如果采用的是 RSA，那么自然存储的就是 {N,d} 等相关的私钥信息，详情参考RSA private key syntax，如果采用的是 DES 算法呢，那么存储的就是 DES key 相关的信息… 摘抄两端核心的内容如下 privateKeyAlgorithm identifies the private-key algorithm. One example of a private-key algorithm is PKCS #1’s rsaEncryption [PKCS#1]. privateKeyAlgorithm 表示私钥所使用的算法，一个例子就是 PKCS#1 所表述的 PKCS#1 的 rsa 加密技术； privateKey is an octet string whose contents are the value of the private key. The interpretation of the contents is defined in the registration of the private-key algorithm. For an RSA private key, for example, the contents are a BER encoding of a value of type RSAPrivateKey. privateKey 是一个包含私钥内容的八位字节字符串 octet string，该内容由其加密算法所描述和解释；比如 RSA 私钥，其内容表示一个通过 BER 编码的私钥； 总结一下， 可以看到，PKCS #8 在原来私钥的格式上做了一层抽象封装，这样使得它可以兼容任何的私钥格式；使得 PKCS 的私钥标准可以使用到任何加密算法，这个同 PKCS#1 中定义的 RSA 私钥语法是不同的，PKCS #1 定义的只是特定的 RSA 私钥的语法格式； Ok，从这里就可以清晰的看到 PKCS 的发展方向了，PKCS 体系已经突破了单纯的 RSA 加密算法，而是扩展到了可以适配任何的加密算法，所以，PKCS 已经成为了一种通用的密码学格式标准。当然，CMS 在此基础上更进一步，建立了 PKI 体系中所需的其它类型信息，包括加密数据，签名，签名者，加密算法等等公钥加密技术基础设施相关的东西，详情参考PKCS #7 Format部分，而这部分正是 RFC5958 标准淘汰当前 RFC5208 标准的地方，不过精华其实还是在 RFC5208； ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:6:1","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"encrypted private key info https://tools.ietf.org/html/rfc5208#section-6 EncryptedPrivateKeyInfo ::= SEQUENCE { encryptionAlgorithm EncryptionAlgorithmIdentifier, encryptedData EncryptedData } EncryptionAlgorithmIdentifier ::= AlgorithmIdentifier 相关核心内容摘抄如下， The fields of type EncryptedPrivateKeyInfo have the following meanings: encryptionAlgorithm identifies the algorithm under which the private-key information is encrypted. Two examples are PKCS #5’s pbeWithMD2AndDES-CBC and pbeWithMD5AndDES-CBC [PKCS#5]. encryptionAlgorithm 字段表示私钥使用什么算法进行加密的；通常使用 PKCS#5 的 MD2AndDES 或者 MD5AndDES 两种加密算法； encryptedData is the result of encrypting the private-key information. encryptedData 是私钥通过加密算法 encryptionAlgorithm 加密以后的内容； The encryption process involves the following two steps: The private-key information is BER encoded, yielding an octet string. The result of step 1 is encrypted with the secret key to give an octet string, the result of the encryption process. 加密过程包含两个步骤， 私钥的内容通过 BER 编码，并产生相关的八位字节字符串 octet string 第一步产生的结果将会通过密钥(secret key)进行加密并再产生一个 octet string，该 octet string 便是这个加密过程的结果； 可以看到，私钥的整个内容都被 encryptionAlgorithm 所指明的加密算法进行了加密； ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:6:2","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"RFC5958 Asymmetric Key Packages 看看 RFC5958 的 Introduction 章节， This document defines the syntax for private-key information and a Cryptographic Message Syntax (CMS) [RFC5652] content type for it. Private-key information includes a private key for a specified public-key algorithm and a set of attributes. The CMS can be used to digitally sign, digest, authenticate, or encrypt the asymmetric key format content type. This document obsoletes PKCS #8 v1.2 [RFC5208]. 可见 RFC5958 定义了不但私钥的语法还定义了相关的 CMS 的文本类型(content type)；Private-key information 包含了一个特定公钥算法的私钥以及一些列的属性；CMS 可以用来进行数字签名，digest，验证或者用来加密非对称密钥的内容和格式；该文档淘汰了过时的 PKCS #8 v1.2 [RFC5208]； RFC5958 Asymmetric Key Packages: https://tools.ietf.org/html/rfc5958 淘汰了过时的 RFC5208 PKCS #8: Private-Key Information Syntax Specification Version 1.2 https://tools.ietf.org/html/rfc5208； 虽然是淘汰了 RFC5208，不过笔者在阅览完 RFC5208 以后，发现 RFC5208 内容更为清晰易懂，所以，还是打算从 RFC5208 入手进行梳理；这部分内容参考 RFC5208 Private-Key Information Syntax Specification 后续 RFC5958 非常详细的描述了有关 CMS 的内容定义，以及私钥加密 ASN.1 格式的定义，这里就不再一一赘述了； ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:7:0","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"私钥文件的格式 RFC5958 用不多的篇幅来描述了私钥的文件存储格式；不过以下内容比较零散，主要是翻译官方文档并做一些个人的理解； 该小节主要来讲解私钥的存储格式，看下 RFC5958 中的一段描述， To extract the private-key information from the AsymmetricKeyPackage, the encapsulating layers need to be removed. At a minimum, the outer ContentInfo [RFC5652] layer needs to be removed. If the AsymmetricKeyPackage is encapsulated in a SignedData [RFC5652], then the SignedData and EncapsulatedContentInfo layers [RFC5652] also need to be removed. The same is true for EnvelopedData, EncryptedData, and AuthenticatedData all from [RFC5652] as well as AuthEnvelopedData from [RFC5083]. 这段话的意思就是说，要提取通过 AsymmetricKeyPackage 格式所封装的私钥，必须剥离其外部的封装层；至少，外部的 ContentInfo[RFC5652] 是需要被剥离出去的；如果封装了签名，同样该签名需要被剥离；同样的，如果有其它的封装数据，比如加密的数据，验证的数据等同样需要剥离出去； Once all the outer layers are removed, there are as many sets of private-key information as there are OneAsymmetricKey structures. OneAsymmetricKey and PrivateKeyInfo are the same structure; therefore, either can be saved as a .p8 file or copied in to the P12 KeyBag BAG-TYPE. Removing encapsulating security layers will invalidate any signature and may expose the key to unauthorized disclosure. 当所有的外部层次都被剥离以后，所剩下的也就是最终私钥的信息结构了；该私钥的信息可以通过.p8格式文件或者是通过P12 KeyBag BAG-TYPE 格式进行存储；不过注意的是，通过之前的步骤层层剥离，若将安全层也剥离以后，将会使得任何签名无效并且会将私钥暴露给非授权机构； 下面这段有意思了，基本上阐述了通过.p8格式存储的私钥的格式，不过就是不够细致，也不够生动形象，官网的内容就是这样，点到为止，看得人痛不欲生； .p8 files are sometimes PEM-encoded. When .p8 files are PEM encoded they use the .pem file extension. PEM encoding is either the Base64 encoding, from Section 4 of [RFC4648], of the DER-encoded EncryptedPrivateKeyInfo sandwiched between: -----BEGIN ENCRYPTED PRIVATE KEY----- -----END ENCRYPTED PRIVATE KEY----- or the Base64 encoding, see Section 4 of [RFC4648], of the DER -encoded PrivateKeyInfo sandwiched between: -----BEGIN PRIVATE KEY----- -----END PRIVATE KEY----- 上面这段比较重要了，阐述了密钥通过.p8加密存储的格式，.p8文件是一种通过PEM编码的文件，当.p8文件通过PEM进行编码的时候，它们的文件后缀为.pem；PEM编码格式有两种方式 使用DER编码的EncryptedPrivateKeyInfo通过Base64转码后被包裹下面的两段标识符中 -----BEGIN ENCRYPTED PRIVATE KEY----- -----END ENCRYPTED PRIVATE KEY----- 看过官网解释，你此时的状态应该是云里雾里的；这里作者想表达的是什么意思呢… 这里就是表示的如果私钥本身是经过加密存储的，既是 RFC5208 中所定义的 EncryptedPrivateKeyInfo 所表述的信息，那么会使用如上的格式来进行存储； 使用DER编码的PrivateKeyInfo通过Base64转码后被包裹下面的两段标识符中 -----BEGIN PRIVATE KEY----- -----END PRIVATE KEY----- PrivateKeyInfo这里表示的就是明文，既是密钥没有经过加密，是通过Base64所存储的明文格式； 更多有关此部分的介绍查看 RSA(三) 密钥的格式部分内容； ","date":"2021-03-03","objectID":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/:7:1","tags":["RSA"],"title":"RSA(二) PKCS 公钥加密标准系列","uri":"/rsa%E4%BA%8C-pkcs-%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86%E7%B3%BB%E5%88%97/"},{"categories":null,"content":"前言 本篇文章将试图从数学原理上理清 RSA 的加密解密的原理；并写一个简单的加密解密的用例来使用； 备注，本文是作者的原创作品，转载请注明出处。 转载至https://www.shangyang.me/2017/05/24/encrypt-rsa-keyformat/ 数论相关 ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:0:0","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"模 N 随机选择两个大的质数 p 和 q，p 不等于 q, 计算得到 𝑁=𝑝𝑞N=pq ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:1:0","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"欧拉函数的值 r = 𝜑(pq) 𝑟=𝜑(𝑝𝑞)=𝜑(𝑝)𝜑(𝑞)=(𝑝−1)(𝑞−1)r=𝜑(pq)=𝜑(p)𝜑(q)=(p−1)(q−1) 欧拉函数值求的是有多少个小于 N 的数与 N 互质，如果 N 本身为质数，那么就有 N-1 个数与 N 互质； ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:2:0","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"随机数 e 选择一个整数 e 且 1\u003c𝑒\u003c𝑟1\u003ce\u003cr，使得 e 与 r 互质(两个数的公约数为 1)；取 e 的目的是为了求得 e 关于 r 的模反元素 d； ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:3:0","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"模反元素 d ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:4:0","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"什么是模反元素 d 由e小节可知，模反元素 d 是 e 关于 r 的模反元素且若模反元素 d 存在，当且仅当 e 与 r 互质； 模反元素的数学意义 𝑒𝑑≡1(mod𝑟)ed≡1(modr) 若 e 与 r 互质，那么总会找到这么一个数 d，使得 ed 和 1 与模 r 同余；通俗的说法既是，ed 除以 r 的余数与 1 除以 r 的余数相等，因为 1 除以 r 的余数恒等于 1，所以 ed 除以 r 的余数为 1，也就推出 𝑒𝑑−1=𝑘𝑟ed−1=kr ，该表达式的意思就是 ed - 1 是 r 的倍数； ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:4:1","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"如何计算得到 d 那么如何计算得出此模反元素 d 呢？ 根据扩展欧几里得算法的公式有，在(mod𝑟)(modr)之下， 𝑒𝑥+𝑟𝑦=1ex+ry=1 ，此时 x 的解既是 e 关于模 r 的一个模反元素；认真的读者读到这里，肯定会产生疑问，上面的公式 𝑒𝑑−1=𝑘𝑟ed−1=kr 怎么看起来与 𝑒𝑥+𝑟𝑦=1ex+ry=1 怎么这么像呢，但是又有差别，我们将公式 𝑒𝑑−1=𝑘𝑟ed−1=kr 调整一下，得到 𝑒𝑑−𝑘𝑟=1…①ed−kr=1…① 将扩展欧几里得算法的公式 𝑒𝑥+𝑟𝑦=1ex+ry=1 的 x、y 值进行替换，x = d, y = k，得到 𝑒𝑑+𝑘𝑟=1…②ed+kr=1…② 什么，两个看似如此矛盾的两个不同的方程(公式 ① 和公式 ②)… 什么意思？谁是对的？谁是错的？ 摘抄模反元素中的一段内容如下， 事实上， 𝑥+𝑘𝑛(𝑘∈ℤ)x+kn(k∈ℤ)都是a关于模n的模逆元，这里我们取最小的正整数解 𝑥(mod𝑛)(𝑥\u003c𝑛)x(modn)(x\u003cn) 对应到我们的例子中来，也就是 𝑑+𝑘𝑟(𝑘∈ℤ)d+kr(k∈ℤ) 都是 e 关于模 r 的模逆元，这里我们取最小的正整数解 𝑑(mod𝑟)(𝑑\u003c𝑟)d(modr)(d\u003cr)；由此可知，d 的解实际上有无限多个，满足 𝑑+𝑘𝑟(𝑘∈ℤ)d+kr(k∈ℤ)；k 是整数集合，包含正整数、负整数和零； 其实，公式①和公式②其实可以理解为同一个方程，只是 Y 轴（这里指 K 轴）的方向发生了变化而已； 加密和解密 假设 Bob 想给 Alice 送一个消息 m； ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:4:2","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"公钥和密钥 在 Alice 端，经过上述的步骤，我们总共得到了 6 个数字，p、q、N、r、e、d；并生成公钥和密钥，公钥就是(𝑁、𝑒)(N、e)组合；秘钥就是(𝑁、𝑑)(N、d)组合；并且 Alice 将公钥发送给 Bob； ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:5:0","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"加密过程 Bob 想给 Alice 送一个消息 M，他拥有 Alice 的公钥，既是 (𝑁、𝑒)(N、e) 。他使用起先与 Alice 约好的编码格式将 M 转换为一个小于 模 N，且与 N 互质的整数 m；通常，我们传递的是字符串，但是字符可以转换为对应的 ASCII 码值或者 UNICODE 等整数数值；由于转换后的数字必须要小于 N，所以，一般的做法是，将原来的文本切割为很多小份，然后分别加密，将每一段转换为 m 后再传输； 加密公式， 𝑐≡𝑚𝑒(mod𝑁)c≡me(modN) 将 m 转换为加密数值c，然后 Bob 将c传输给 Alice；那么c是如何计算得到的？其实这个求c的过程非常的简单，直接是 𝑐=𝑚𝑒%𝑁c=me%N 推导过程，𝑢=𝑚𝑒%𝑁u=me%N，因为 𝑢\u003c𝑁u\u003cN 导出 𝑢=𝑢%𝑁u=u%N 导出 𝑐=𝑢c=u 导出 余数 u 既是c https://l2x.gitbooks.io/understanding-cryptography/docs/chapter-3/rsa.html ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:6:0","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"解密过程 Alice 拿到 Bob 的加密信息c以后，她使用下面的公式来将c解密得到 m： 𝑐𝑑≡𝑚(mod𝑁)cd≡m(modN) 同加密过程求c一样，这里，得出 𝑚=𝑐𝑑%𝑁m=cd%N 这里的关键问题是，如何得到的解密方程式 𝑐𝑑≡𝑚(mod𝑁)cd≡m(modN)？ ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:7:0","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"公式推导 由加密公式， 𝑐≡𝑚𝑒(mod𝑁)c≡me(modN) 通过同余的基本运算规则 那么可以得出 𝑐𝑑≡𝑚𝑒𝑑(mod𝑁)cd≡med(modN) 下面相关部分摘要自 wikipedia，稍有不同的是，上述过程的原始消息是 m，下面过程的原始消息是 n 上面推论的重点在于，𝑛(𝑛φ(𝑁))ℎ≡𝑛(1)ℎ(mod𝑁)n(nφ(N))h≡n(1)h(modN) 是怎么导出来的？参考欧拉定理 所以，有 𝑛φ(𝑁)≡1(mod𝑁)nφ(N)≡1(modN)，难道是将 𝑛φ(𝑁)≡1(mod𝑁)nφ(N)≡1(modN) 直接代入 𝑛(𝑛φ(𝑁))ℎn(nφ(N))h，所以得到 𝑛(𝑛φ(𝑁))ℎ≡𝑛(1)ℎ(mod𝑁)n(nφ(N))h≡n(1)h(modN)，除此之外，想不到原因了… 但是在同余中没找到这种参数代入法.. 所以会有些怀疑；好吧，姑且给自己有一个悬念吧.. 最终，经过上述的论证，我们得到了解密要用到的公式， 𝑐𝑑≡𝑚(mod𝑁)cd≡m(modN) https://l2x.gitbooks.io/understanding-cryptography/docs/chapter-3/rsa.html 例证 上面的原理性的东西说了一堆，这里通过一个实际的例子来看看 RSA 是如何做到加密解密的？ Bob 试图通过 RSA 的加密的方式向 Alice 发送数据， ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:7:1","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"生成密钥 如下步骤描述了 Alice 如何通过 RSA 算法生成自己的密钥(公钥和公钥)； 模 N，Alice 选择两个质数 5、13，得到 𝑁=5×13=65N=5×13=65 备注，这里选择的时候一定要注意，之前就是因为错选了不是质数的 9，导致入坑很久没爬出来； 欧拉函数值 r 𝑟=φ(𝑁)=φ(5)φ(13)=(5−1)(13−1)=48r=φ(N)=φ(5)φ(13)=(5−1)(13−1)=48 随机数 e，随机选择 e 且 (1\u003c𝑒\u003c𝑟)(1\u003ce\u003cr)，e 必须与 r 互质，这里，我随机选择一个 𝑒=5e=5 求 e 关于 r 的模反元素 d，有公式 𝑒𝑑≡1(mod𝑟)ed≡1(modr) 等价于求解 5×𝑑≡1(mod48)5×d≡1(mod48) 按照 如何计算得到 d 中所介绍的扩展欧几里得算法，得到公式 5×𝑑+48𝑘=15×d+48k=1 ，同样也可以按照公式 5×𝑑−48𝑘=15×d−48k=1 来进行求解，两者之间的相互区别在 如何计算得到 d 有详细的描述； 为了计算出 d，我按照求解的公式 5×𝑑−48𝑘=15×d−48k=1 写了一段程序来求解 d，从 k = -20 开始，不断的试探出 d 的取值， int k = -20; int e = 5; int r = 48; while( true ){ int d_mod = (r*k + 1)%e; if( d_mod == 0 ){ int d = ( (r*k + 1)/e ); System.out.println(\"=====\u003e k=\"+k+\"; d=\" + d ); //break; } //System.out.println(\"tried k=\"+k); k ++; if( k \u003e 10 ) break; } 求得取值范围如下， =====\u003e k=-17; d=-163 =====\u003e k=-12; d=-115 =====\u003e k=-7; d=-67 =====\u003e k=-2; d=-19 =====\u003e k=3; d=29 =====\u003e k=8; d=77 这里要求取最小正整数的模反元素，所以取得 d = 29，k = 3；因为这里是按照𝑒𝑑−𝑘𝑟=1ed−kr=1的逻辑进行求解，所以，这里 k 的值为正整数 3，如果是按照扩展欧几里得算法的方式𝑒𝑑+𝑘𝑟=1ed+kr=1求解，那么 k = -3 Ok，至此，重要的 6 个元素已经集合完毕，他们分别是 𝑝=5,𝑞=13,𝑁=65,𝑟=48,𝑒=5,𝑑=29p=5,q=13,N=65,r=48,e=5,d=29 于是，得到公钥为 65,565,5；得到私钥为 65,2965,29；最后 Alice 通过某种方式将公钥发送给 Bob； ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:8:0","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"传输加密信息 Bob 通过 RSA 加密方式向 Alice 发送字符感叹号 !， 首先，将字符 ! 转换成其对应的 ASCII 码值，对应为 41，记为 𝑚m 再次，通过加密公式 𝑐=𝑚𝑒%𝑁c=me%N 既 𝑐=415%65=6c=415%65=6，由此得到 m 的加密后的数字为 𝑐=6c=6；注意，过程中使用到了 (N,e)；备注，这里可用编程的方式求解， System.out.println( Math.pow(41,5) % 65); 最后，Bob 将加密数字 c = 6 发送给了 Alice； ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:9:0","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"解密加密信息 Alice 接收到了 Bob 发送的加密数字 c (6)，之后使用私钥(65, 29)进行解密， 首先，根据解密公式 𝑚=𝑐𝑑%𝑁m=cd%N 既 𝑚=629%65m=629%65，解出 𝑚=41m=41，正好得到 Bob 未加密之前的字符 ! 的 ASCII 码，因此，这里成功将其解密；备注，这里可以通过编程的方式求解， System.out.println( Math.pow(6,29) % 65); 为什么 RSA 很难被破解 因为要通过密文 c 反推得到明文 m，根据解密方程式 𝑚=𝑐𝑑%𝑁m=cd%N 我们知道， 在公钥公开的前提下，既是知道 N、e 的前提下，必须要知道 d，才能解密出明文 m； 而要知道 d，那么就必须对素数模 N 进行因式分解，得到 p 和 q， 再通过欧拉函数的计算 𝜑(𝑝𝑞)=𝜑(𝑝)𝜑(𝑞)𝜑(pq)=𝜑(p)𝜑(q) 得到 r， 最后通过 r 和 e，求出 e 于 r 的模反元素的计算才能最终推导出 d； 而一切的一切的前提都必须对 N 进行因式分解，而如果 N 是一个非常大的素数，因式分解几乎是不可能的；这样，也就保证了 RSA 的加密技术的可靠性； 使用注意 可以看到，在加密和解密过程中都会涉及到特大指数级别的运算，所以，运算过程是非常耗费计算机资源和时间的；所以一般的通讯中不直接使用 RSA 来进行加密通讯；而是通过公钥加密一段 DES 密钥来进行通讯，比如 Bob 使用 Alice 的公钥生成一个 DES 对称密钥，然后发送给 Alice，然后 Alice 再使用密钥解密得到 DES 密钥，这样双发最后实际上是通过 DES 密钥在进行通讯； ","date":"2021-03-03","objectID":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/:10:0","tags":["RSA"],"title":"RSA(一) 背后的数学原理","uri":"/rsa%E4%B8%80-%E8%83%8C%E5%90%8E%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":null,"content":"个人博客，瞎写写。OTG ","date":"2021-03-03","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"}]