[{"categories":null,"content":"问题 这个问题是本人在折腾自己的良心云（凉心云）的时候发现的，当时是想使用一个前置 Nginx 转发所有的请求，同时进行日志的记录等等。 当我写完配置文件，测试时没有任何问题。但是当我关闭了自己搭建的 es 服务，我发现我访问所有的服务都 500 了，这时我查看 nginx error 日志，记录如下 [emerg] 1#1: host not found in upstream \"es\" in /etc/nginx/conf.d/es.conf:13 ","date":"2022-07-20","objectID":"/docker%E9%83%A8%E7%BD%B2nginx%E5%87%BA%E7%8E%B0host-not-found-in-upstream%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/:1:0","tags":["Docker","Nginx"],"title":"Docker 部署 Nginx 出现「host not found in upstream」问题解决","uri":"/docker%E9%83%A8%E7%BD%B2nginx%E5%87%BA%E7%8E%B0host-not-found-in-upstream%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"categories":null,"content":"解决 在 nginx 的配置文件中添加以下内容 server { listen 80; server_name test.com; # 添加额外的 dns 解析地址，此地址为 docker 内部 dns 地址 # 当 proxy_pass 为变量时 必须添加 resolver 127.0.0.11; location / { set $tmp es; proxy_pass http://$tmp; } } ","date":"2022-07-20","objectID":"/docker%E9%83%A8%E7%BD%B2nginx%E5%87%BA%E7%8E%B0host-not-found-in-upstream%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/:2:0","tags":["Docker","Nginx"],"title":"Docker 部署 Nginx 出现「host not found in upstream」问题解决","uri":"/docker%E9%83%A8%E7%BD%B2nginx%E5%87%BA%E7%8E%B0host-not-found-in-upstream%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"categories":null,"content":"原理 nginx 启动时，会对其配置的 upstream 进行 DNS 解析测试，如果无法解析成功则会报错无法启动。 但是，当我们将 upstream 修改为变量时，nginx 不会进行测试，以此绕过这个问题。 resolver 则为 Nginx 设置 DNS 服务器，Nginx会动态利用 resolver 设置的DNS服务器（本机设置的 DNS 服务器或 /etc/hosts 无效），将域名解析成 IP，proxy 模块会将请求转发到解析后的IP上。 如果不添加的话，访问将会502 Bad Gateway，同时日志会显示 no resolver defined to resolve es ","date":"2022-07-20","objectID":"/docker%E9%83%A8%E7%BD%B2nginx%E5%87%BA%E7%8E%B0host-not-found-in-upstream%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/:2:1","tags":["Docker","Nginx"],"title":"Docker 部署 Nginx 出现「host not found in upstream」问题解决","uri":"/docker%E9%83%A8%E7%BD%B2nginx%E5%87%BA%E7%8E%B0host-not-found-in-upstream%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"categories":null,"content":" 这篇文章用作自己学习 k8s 的笔记，学习的资料为b站的视频 2021 年末倾力打造 Kubernetes 入门至精通 - 2022 年幸福的开胃菜_哔哩哔哩_bilibili 本文章为本人学习所用，如需转载请注明出处 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:0:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"1、基础概念 基础组件 kubectl api server scheduler replication controller etcd kubelet kube proxy firewall 插件 CoreDNS 负责为整个集群提供 DNS 服务 Ingress Controller 为 k8s 中的服务提供外网入口 Prometheus 为整个集群提供资源监控能力，时序数据库 Dashboard 提供 B/S 的访问体系，允许用户通过 web 进行集群管理和设置，比较常用的如：rancher Federation 提供跨可用区的集群，提供不同数据中心的 K8S 集群的管理能力 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:1:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"2、Pod 在下达创建 pod 的时候，第一个被初始化的容器为pause，作用为初始化网络栈，挂载存储卷等。后续继续创建对应的 container，这些创建的 container 都会与初始容器pause 共享网络栈和存储等，类似 docker 中的--net和--volumes-from。这样在一个 Pod 中的 container 可以直接通过回环接口相互访问。 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Pod种类 自主式 Pod 控制器管理的 Pod（推荐） ReplicationController \u0026 ReplicaSet \u0026 Deployment HPA（HorizontalPodAutoScale） StatefullSet DarmonSet Job \u0026 Cronjob 自定义控制器… 不做讨论 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"控制器种类 Replication Controller （RC）\u0026 ReplicaSet（RS） \u0026 Deployment 用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的 Pod 来替代，而如果异常多出的容器也会自动回收。 在新版本的 K8S 中建议使用 RS 来取代 RC。 RS 的本质和 RC 没有本质区别，只是名字不一样，并且 RS 支持集合式的标签选择器（tag selector）。 虽然 RS 可以独立使用，但是一般建议使用 Deployment 来自动管理 RS，这样可以无需担心和其他机制不兼容的问题。比如 RS 不支持滚动更新（rolling-update）但 Deployment 支持。 滚动更新 # 更新前 Deployment「Pod模板:v1，副本数量：3」 └─ RS「副本数量：3」 ├─ Pod:v1 ├─ Pod:v1 └─ Pod:v1 # 更新Pod模板:v2 # 更新中： Deployment「Pod模板:v1，副本数量：3」 ├─ RS「副本数量：2」 │ ├── Pod:v1 │ └── Pod:v1 └─ RS「副本数量：1」 └─ Pod:v2 # 更新完毕： Deployment「Pod模板:v1，副本数量：3」 ├─ RS「副本数量：0」 └─ RS「副本数量：3」 ├─ Pod:v2 ├─ Pod:v2 └─ Pod:v2 滚动更新会创建一个新的 RS 控制器，以此来创建新版本的 Pod，此时把老版本的 RS 控制器的期望数量一个个调整至0，这样就完成了滚动更新。 HPA（HorizontalPodAutoScale）自动扩缩容 可以根据 Pod 的资源使用情况，调整副本数量，依赖于 RC、RS、Deployment 之上 StatefulSet 服务分类 有状态的服务 无状态服务 中心化服务 去中心化服务 为了解决有状态服务的问题而设计出来，可用来有序扩容缩，其应用场景包括： 稳定的持久化存储，即 Pod 重新调度后还是能访问到相同的持久化数据，基于 PVC 实现 稳定的网络标志，即 Pod 重新调度后，其 PodName 和 HostName 不变，基于 Headless Service（即没有 Cluster IP 的 Service）实现 有序部署，有序扩展，即 Pod 是有顺序的，在部署或者扩展的时候要依据定义的顺序依次进行（即从 0 到 N-1，在下一个 Pod 运行之前，所有之前的 Pod 必须都是 Running 和 Ready 状态），基于 init containers 来实现 有序收缩，有序删除（即 N-1到 0） DaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除所有由它创建的 Pod 经典用法： 运行集群存储 daemon，例如在每个 Node 上运行 glusterd，ceph 在每个 Node 上运行日志手机 deamon，例如 fluentd，logstash 在每个 Node 上运行监控 deamon，例如 Prometheus Node Exporter Job \u0026 cronJob Job 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束 Cron Job 管理基于时间的 Job，即： 在给定时间点只运行一次 周期性的在给定时间点运行 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"网络模型 K8S 的网络模型假定了所有 Pod 都在一个可以直接连通的扁平的网络空间中，这在 GCE（Google Compute Engine）里面是现成的网络模型，K8S 假定这个网络已经存在。而在私有云里搭建 K8S 集群，就不能假定这个网络已经存在了。我们需要自己实现这个网络假设，将不同节点上的 Docker 容器之间的互相访问先打通，然后运行 K8S。 Flannel Flannel 是 CoreOS 团队针对 Kubernetes 设计的一个网络规划服务，简单来说，它的功能是让集群中的不同节点主机创建的 Docker 容器都具有全集群唯一的虚拟 IP 地址。而且它还能在这些 IP 地址之间建立一个覆盖网络（Overlay Network），通过这个覆盖网络，将数据包原封不动地传输到目标容器内。基于 etcd 实现。 实现步骤： Flanneld 向 etcd 申请当前 Pod 的网段，修改当前 Docker0 的IP 会带上当前机器的物理网卡地址，这样就在 etcd 里标识了虚拟网段与真实IP之间的关系 当一个 Pod 发送网络数据的时候，通过对方的虚拟IP就可以找到真实IP了 请求流转（根据图观察） app2 发送一个数据包给10.1.20.3，发现无法直接访问，数据包传递给网关 此时数据包被 Flanneld 所捕获（Flannel0 监听的为 10.1.15.0，注意这个0）传递给对应的另外一个 Flanneld（从etcd获取） 此时 Flanneld 会对数据包进行二次封装，类似一个快递里是另外一个快递 接收到数据包后进行拆包，在对应的 Docker0 中广播，这样也就能收到了 回应同理 网络通讯模式 同 Pod 间不同容器间的网络通讯：本地回环 不同 Pod 间的通讯 同物理机：Docker0 网桥实现报文转发 不同物理机：flannel UDP 数据包二次封装 svc 网络与 Pod 间的通讯 隔离：namespace network ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:2:3","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"3、K8S安装 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"前置准备 安装配置 推荐安装在单网卡机器 CPU \u003e= 2，内存 3G 以上，磁盘 100G 关闭 SWAP 分区 /boot 800m / 全部 seliunx，firewall stop，iptable none K8S安装3个节点，可以配置一个软路由，双网卡 网卡1: 仅主机 网卡2: NAT 上网 安装工具包（可选） sudo apt-get install -y conntrack ntpdate ntp ipvsadm ipset iptables curl sysstat wget net-tools git 同步时区 sudo apt install ntpdate sudo ntpdate ntp.aliyun.com 关闭swap sudo swapoff -a # 临时关闭 sed -ri 's/.swap./#\u0026/' /etc/fstab # 永久关闭 允许 iptables 桥接流量 cat \u003c\u003cEOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF # 设置网卡允许转发 ipv4 流量 sudo sysctl -w net.ipv4.ip_forward=1 sudo sysctl --system ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"安装 Kubernetes 源码包编译安装（难度过高） 可参考Kubernetes - 二进制版本安装 - v1.18 (cloudmessage.top) 容器化安装 kubeadm 官方 证书有效期 1 年（需要修改源码，设置生成证书有效时间） rancher sealos 1、安装容器组件 docker ARM 系统安装 X86_64 可参考上文，注意修改对应系统架构即可 containerd k8s v1.24.0后 K8Sv1.24.0-containerd安装教程 2、安装 Kubeadm （主从配置） Kubeadm 启动流程 Master Systemd \u003e kubelet \u003e 容器组件 \u003e Kubernetes 容器组件在 k8s v1.24.0 版本已弃用 Docker shim 使用了新组件 CRI DOCKERD # 添加阿里云镜像源 sudo apt update \u0026\u0026 sudo apt install -y apt-transport-https sudo curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add - # 添加阿里云或者官方 api 源 # 阿里云 echo \"deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main\" | sudo tee /etc/apt/sources.list.d/kubernetes.list # 官方 sudo curl -o /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg echo \"deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee /etc/apt/sources.list.d/kubernetes.list # 安装软件 sudo apt update \u0026\u0026 sudo apt install -y kubelet kubeadm kubectl # 开机自启 systemctl enable kubelet.service # 注意，此时可能 kublet 没正常运行，不用管继续往下走 3、初始化主节点 # 打印 kubeadm 默认配置 sudo kubeadm config print init-defaults \u003e kubeadm-config.yaml # 修改：`localAPIEndpoint.advertiseAddress`的值为当前主节点的 ip 地址 ... localAPIEndpoint: advertiseAddress: 1.2.3.4 # 这里 bindPort: 6443 ... # 修改：`nodeRegistration.name` 的值为当前主节点名称 ··· nodeRegistration: criSocket: unix:///var/run/containerd/containerd.sock imagePullPolicy: IfNotPresent name: k8s-master01 # 这里 taints: null ··· # 添加 Pod 网段，Flannel 需要工作在指定的网段 ... networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 podSubnet: 10.244.0.0/16 # 新增该行 ··· # 设置负载均衡方式为 ipvs（可选），下列配置添加到末尾，注意 --- 也需要添加 ··· --- apiVersion: kubeproxy.config.k8s.io/v1alpha1 kind: KubeProxyConfiguration featureGates: SupportIPVSProxyMode: true mode: ipvs ··· # k8s.gcr.io 国内无法直接访问，所以替换为阿里云镜像地址 sed -i 's/k8s.gcr.io/registry.cn-hangzhou.aliyuncs.com\\/google_containers/g' kubeadm-config.yaml # 配置文件准备完毕，开始初始化 sudo kubeadm init --config=kubeadm-config.yaml --ignore-preflight-errors=all --v=5 | tee kubeadm-init.log # 初始化成功根据页面提示 # 非 root 用户 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # root 用户 export KUBECONFIG=/etc/kubernetes/admin.conf # 查看集群信息 kubectl cluster-info 4、工作节点加入 # 在初始化主节点成功后，打印出的日志内的最后一段，告诉了我们应该如何加入一个主节点 # 也可以 cat kubeadm-init.log 查看 # 加入前查看当前主机名称 hostnamectl，可以修改为自己便于识别的名称 sudo hostnamectl set-hostname k8s-node01 --static # 加入节点 sudo kubeadm join 192.168.31.100:6443 --token xxx.xxx \\ --discovery-token-ca-cert-hash sha256:xxx # 如果提示 unable to fetch the kubeadm-config ConfigMap: faild to get config map: Unauthorized # 这个代表 token 过期，重新生成即可 sudo kubeadm token create --ttl 0 --print-join-command # 如果提示 # [kubelet-check] Initial timeout of 40s passed. # error execution phase kubelet-start: error uploading crisocket: timed out waiting for the condition # To see the stack trace of this error execute with --v=5 or higher sudo kubeadm reset -f 5、工作节点退出 # 1、将节点设置为维护模式 kubectl drain k8s-node01 --delete-local-data --force --ignore-daemonsets node/k8s-node01 # 2、删除节点 kubectl delete node k8s-node01 # 登陆上节点机器 # 3、停止 kubelet systemctl stop kubelet # 4、k8s 重置 sudo kubeadm reset -f 6、创建网络「flannel」 # 拷贝配置文件 sudo mkdir -p /usr/local/kubernetes/cni/flannel/ cd /usr/local/kubernetes/cni/flannel/ wget https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml # 应用配置 kubectl apply -f kube-flannel.yml # 等待2～3分钟，查看是否成功 kubectl get nodes # 可以看到所有节点都显示 ready 7、集群测试 7.1、创建pod # 创建一个 deployment 任务 指定镜像 kubectl create deployment nginx --image=nginx # 获取 pod 列表 kubectl get po -o wide 7.2、创建 svc 网络 # 创建一个 svc 网络 kubectl create svc clusterip nginx --tcp=80:80 # 查看当前 svc 网络 kubectl get svc ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:3:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"4、资源清单 在 k8s 中所有的内容都是资源，资源实例化之后，叫做对象 资源： 命名空间级别 工作负载型资源：Pod、ReplicaSet、Deployment 等 服务发现及负载均衡型资源：Service、Ingress 等 配置与存储型资源：Volume、CSI 等 特殊类型的存储卷：ConfigMap、Secre 等 集群级资源 Namespace、Node、ClusterRole、ClusterRoleBinding 元数据类型资源 HPA、PodTemplate、LimitRange 在 k8s 中，一般使用 yaml 格式的文件来创建符合我们预期期望的对象，这样的 yaml 文件我们一般称为资源清单 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"格式 apiVersion: group/apiversion # 如果没有给定 group 名称，那么默认为 core，可以使用 kubectl apt-versions 获取当前 k8s 版本上所有的 apiVersion 版本信息（每个版本可能不同） kind: # 资源类别 metadate: # 资源元数据 name namespace lables annotations # 主要目的是方便用户阅读查找 spec: # 期望的状态 （disired state） status: # 当前状态，本字段由 kubernetes 自身维护，用户不能定义 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"常用命令 必须记住的命令 kubectl explain xxx.xxx 必须记住的命令 kubectl explain xxx.xxx 必须记住的命令 kubectl explain xxx.xxx # 查询 # -n 指定命名空间，默认为 default kuebctl get pod -o wide -l [key/key=values] # 获取 pod 列表 kubectl get pod podName -o json/yaml # 获取 pod 详细信息 kubectl log podName # 获取 pod 日志 kubectl describe pod podName # 获取 pod 事件信息 # 操作 kubectl create -f filename # 创建资源 kubectl exec -it podName -c containerName -- [script] # 在某个容器内执行脚本 kubectl delete [res] [--all | name] # 删除资源 kubectl scale --replicas=[num] [controllerKind]/[resName] # 修改某个控制器的副本数量 获取 apiversion 版本信息 kubectl api-versions # output: admissionregistration.k8s.io/v1 apiextensions.k8s.io/v1 apiregistration.k8s.io/v1 apps/v1 ... 字段配置格式 apiVersion \u003cstring\u003e # 表示字符串类型 metadata \u003cobject\u003e # 表示需要嵌套多层字段 labels \u003cmap[string]string\u003e # 表示由 k:v 组成的映射 finalizers \u003c[]string\u003e # 表示字符串列表 ownerReferences \u003c[]object\u003e # 表示对象列表 hostPID \u003cboolean\u003e # true | flase priority \u003cinteger\u003e # 整型 name \u003cstring\u003e -required- # 如果类型后面接 required，表示为必填字段 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"通过定义清单文件创建 Pod apiVersion: v1 kind: Pod metadate: name: pod-demo namespace: default lables: app: myPod spec: containers: - name: myPod-1 image: nginx - name: myPod-2 image: busybos:1.34.1 command: - \"/bin/sh\" - \"-c\" - \"sleep 3600\" # 使用 -o 选项加 yaml，可以将资源的配置以 yaml 的格式输出，也可以使用 json kubectl get pod xxx.xxx.xxx -o yaml ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:4:3","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"5、Pod 生命周期 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"执行流程 Pause：在一个 Pod 启动前，会先启动一个 Pause 容器。它会初始化相应的网络栈，同时把自身的网络卷共享给 Pod 内的容器 初始化容器「initC」，可以有0到无限个 它是批处理类型的任务 它的运行是有序的，第一个不运行成功，第二个不会运行 如果执行失败，会直接重载整个 Pod，直到 Init 容器成功为止。然而，如果 Pod 对应的 restartPolicy 为 Never 则不会重启 主容器「mainC」，至少存在一个 多个 mainC 并行启动 多个 mainC 共享同一个网络卷，绑定的端口不能重复 hook 启动前「和主进程同时运行，不一定在主进程运行前执行完成」 关闭前「可以保证在关闭前执行完成」 探针「tcp｜http｜script」 可以进行就绪、存活探测探针：判断是否可以进行后续探针，新版本才存在 就绪探针：判断一个 mainC 是否已经准备好提供服务，可以定义探测间隔 存活探针：判断一个 mainC 是否存活，如无响应则重启容器 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"init 容器 因为 Init 容器具有与应用容器分离的单独镜像，所以它们的启动相关代码具有如下优势： 它们可以包含并运行实用工具，但是出于安全考虑，不建议在应用容器镜像中包含这些工具 应用程序镜像可以分离出创建和部署的角色，而没有必要联合它们构建一个单独的镜像 Init 容器使用 Linux Namespace，所以相对于应用容器来说具有不同的文件系统视图。因此，他们能够具有访问 Secret 的权限，而应用程序则不能 他们必须在应用容器启动之前运行完成，而应用容器是并行运行的，所以 Init 容器能够提供一种简单的阻塞或延迟应用容器启动的方法，直到满足啦一组先决条件 Init 容器具有应用容器的所有字段。除了 readinessProbe，因为 Init 容器无法定义不同于完成和就绪之外的其他状态，这会在验证过程中强制执行 在 Pod 中的每个 app 和 init 容器的名称必须唯一；与其他任何容器共享同一个名称，会在验证时抛出错误 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"简单实操 # testpod.yaml apiVersion: v1 kind: Pod metadata: name: my-nginx-pod labels: app: my-nginx spec: containers: - name: my-nginx image: nginx initContainers: - name: init-my-service image: busybox command: ['sh', '-c', 'until nslookup my-service; do echo waiting for my-service; sleep 2; done;'] - name: init-my-db image: busybox command: ['sh', '-c', 'until nslookup my-db; do echo waiting for my-db; sleep 2; done;'] # init-testpod.yaml apiVersion: v1 kind: Service metadata: name: my-service spec: ports: - protocol: TCP port: 80 targetPort: 9376 --- apiVersion: v1 kind: Service metadata: name: my-db spec: ports: - protocol: TCP port: 80 targetPort: 9377 先创建 init 模板 kubectl create -f init-pod.yaml 查看 Pod 状态 kubectl get po 查看初始化容器日志 kubectl logs my-nginx-pod -c init-my-service 发现一直在解析域名，这时我们创建响应的 service kubectl create -f init-test-pod.yaml 然后我们再去查看容器的状态，可能需要等待一定的时间 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:3","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"探针 探针是由 kubelet 对容器执行的定期诊断，要执行诊断，kubelet 调用容器实现的 Handler。有三种类型的处理程序： ExecAction：在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功 TCPSocketAction：对指定端口上的容器 IP 地址进行 TCP 检查。如果端口打开，则诊断被任务时成功的 HTTPGetAction：对指定的端口和路径上的容器 IP 地址执行 HTTP Get 请求。如果响应的状态码大于等于 200 且小于 400，则诊断被认为是成功的 每次探测都将获得以下三种结果： 成功：容器通过诊断 失败：容器未通过诊断 未知：诊断失败，但不会采取任何行动 readinessProbe「就绪探针」 指示容器是否准备好服务请求。如果就绪探测失败，端点控制器将从与 Pod 匹配的所有 Service 的端点中删除该 Pod 的 IP 地址。初始延迟前的就绪状态默认为 Failure。如果容器不提供就绪探针，则默认状态为 SUCCESS # readinessProbe-httpget apiVersion: v1 kind: Pod metadata: name: reaadiness-httpget-pod namespace: default labels: app: myapp spec: containers: - name: readiness-httpget-container image: nginx imagePullPolice: IfNotPresent readinessProbe: # 配置就绪探针 httpGet: # 探针类型，请求端口和 path port: 80 path: readiness.html initialDelaySeconds: 1 # 开始探测延迟 periodSeconds: 3 # 探测间隔 创建该 Pod 后，会发现 Pod 处于运行状态，但是 READY 却是 0/1。这时我们查看容器日志，发现探针返回为 404，此时表示探针正常生效。 我们进入容器，在 nginx 的根目录下创建readiness.html文件，退出后发现容器已处于就绪状态。 livenessProbe「存活探针」 指示容器是否正在运行。如果存活探测失败，则 kubelet 会杀死容器，并且容器将根据重启策略来判断是否重新拉起。如果容器不提供存活探针，则默认状态为 SUCCESS # livenessProbe-exec apiVersion: v1 kind: Pod metadata: name: liveness-exec-pod namespace: default spec: containers: - name: liveness-exec-container image: busybox imagePullPolicy: IfNotPresent command: [\"/bin/sh\", \"-c\", \"touch /tmp/live; sleep 60; rm -rf /tmp/live; sleep 3600\"] # 运行脚本 livenessProbe: exec: # exec 类型探针 command: [\"test\", \"-e\", \"/tmp/live\"] # 执行脚本 initialDelaySeconds: 1 # 开始探测延迟 periodSeconds: 3 # 探测间隔 创建该 Pod 后，在前 60 秒内正常运行，之后发现 Pod 被杀死并重新创建。 # livenessProbe-httpget apiVersion: v1 kind: Pod metadata: name: liveness-httpget-pod namespace: default spec: containers: - name: liveness-httpget-container image: nginx imagePullPolicy: IfNotPresent ports: - name: http containerPort: 80 livenessProbe: httpGet: # 探针类型，请求端口和 path port: 80 path: index.html initialDelaySeconds: 3 # 开始探测延迟 periodSeconds: 3 # 探测间隔 timeoutSeconds: 3 # 超时时间 # livenessProbe-tcp apiVersion: v1 kind: Pod metadata: name: liveness-tcp-pod namespace: default spec: containers: - name: liveness-tcp-container image: nginx imagePullPolicy: IfNotPresent ports: - name: tcp containerPort: 80 livenessProbe: tcpSocket: # 探针类型，请求端口 port: 80 initialDelaySeconds: 5 # 开始探测延迟 timeoutSeconds: 1 # 超时时间 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:4","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"启动、退出动作「hook」 apiVersion: v1 kind: Pod metadata: name: lifecycle-demo spec: containers: - name: lifecycle-demo-container image: nginx lifecycle: # 生命周期 postStart: # 启动前 exec: command: [\"/bin/sh\", \"-c\", \"echo postStart \u003e /usr/share/message\"] preStart: # 关闭前 exec: command: [\"/bin/sh\", \"-c\", \"echo preStart \u003e /usr/share/message\"] 在进入容器后，就可以看到/usr/share/message存在，并且内容是我们自定义的postStart。我们进去容器死循环打印文件 while true; do cat /usr/share/message; done 在外部关闭容器后，发现打印变成了preStart ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:5:5","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"6、控制器详解 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"RC 控制器 # file: rc.yaml apiVersion: v1 kind: ReplicationController metadata: name: frontend spec: replicas: 3 # 副本数量 selector: # 标签选择器，寻找 app=nginx 的 Pod app: nginx template: # 创建 Pod 模板 metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 在创建上述文件后，我们执行 kubectl create -f rc.yaml 然后我们查看对应 Pod： 这也就是 RC 控制器的功能，我们可以尝试删除其中一个 Pod 会发现又被重新创建 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"RS 控制器 apiVersion: v1 kind: ReplicaSet metadata: name: frontend spec: replicas: 3 # 副本数量 selector: # 标签选择器，寻找 app=nginx 的 Pod matchLabels: app: nginx1 # matchExpressions: 可选 template: # 创建 Pod 模板 metadata: labels: app: nginx1 spec: containers: - name: nginx image: nginx ports: - containerPort: 80 RS 控制器相比 RC 控制器，只是多了一种标签选择器，我们可以通过下面的命令查看对应的文档： kubectl explain rs.spec.selector 可以看到除了和 RC 控制器功能一致的matchLabels，还多了一种matchExpressions可选择。 matchExpressions目前能支持的操作包括： In：label 的值在某个列表中 NotIn：label 的值不在某一个列表中 Exists：某个 label 存在 DoesNotExist：某个 label 不存在 示例 # selector exists demo apiVersion: v1 kind: ReplicaSet metadata: name: rs-demo spec: selector: matchExpressions: # 这里 - key: app operator: Exists # label 中 key 为 app 存在即可 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 # selector In demo apiVersion: v1 kind: ReplicaSet metadata: name: rs-demo spec: selector: matchExpressions: # 这里 - key: app operator: In # label 中 key 对应的 value 在枚举的 values 中即可 values: - nginx - nginx1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Deployment 控制器 命令的定义方式 命令式定义 kubectl create -f xxxxx 声明式定义 kubectl apply -f xxxxx 区别：声明式命令可以重复使用，系统会自动判断当前操作是修改还是创建 推荐直接使用 apply，在遇到命令式资源时会自动降级成命令式 Deployment 为 Pod 和 ReplicaSet 提供来一个声明式定义方法，用来代替之前的 ReplicationController 来方便管理应用。典型的应用场景包括： 定义 Deployment 来创建 Pod 和 ReplicaSet 滚动升级和回滚应用 扩容和缩容 暂停和继续 Deployment 1、部署一个简单的 Nginx 应用 apiVersion: extensions/v1beta1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 3 template: metadate: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 kubectl apply -f https://kubernetes.io/docs/user-guide/nginx-deployment.yaml --record # --record 可以记录当前命令到 deployment 到历史记录中 2、扩容 # 修改副本数量为 10，不会影响 deployment 已经创建的 rs kubectl scale deployment nginx-deployment --replicas 10 如果集群支持 horizontal pod autoscaling 的话，还可以为 Deployment 设置自动扩展 kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80 3、更新镜像 kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 4、回滚 kubectl rollout undo deployment/nginx-deployment 假如当前有4个版本 v1、v2、v3、v4，目前的版本为 v4，使用上述命令回滚之后回滚到 v3 版本，再次使用上述命令，此时回重新回滚到 v4 版本，因为当前的上一个版本为 v4，如果想指定版本可以使用下述命令： # 查看历史版本记录，如果使用了 --replicas 会显示当时的命令 kubectl rollout history deployment/nginx-deployment # 回滚到指定版本 kubectl rollout undo deployment/nginx-deployment --to-revision=2 # 暂停 deployment 的更新 kubectl rollout pause deployment/nginx-deployment # 可以使用 kubectl rollout status 查看回滚是否完成，同时命令返回 code 为 0，可以使用脚本来判断 kubectl rollout status depoyment/nginx-deployment 限制版本数量 可以设置.spec.revisionHistoryLimit来设置保留的版本数量，这个数量也就是 deployment 管理的历史 rs 数量 多个 rollout 并行 假设当前有 10 个 Pod 正在从 v1 版本升级至 v2 版本，此时 v1 : 5、v2 : 5。 这时我们再升级至 v3 版本，此时升级的 5 个 v2 版本的 Pod 会直接被杀死，然后直接创建 v3 版本的 Pod。 常用回滚策略 一般在企业中不会使用 revision 这种回滚方式，而是会复制最近版本的配置文件，修改名称后直接进行 apply 操作，比如nginx-deployment-2022-06-06 12:00:00.yaml。这样的话出现问题可以直接 apply 至上一个配置文件即可。 5、更新策略 Deployment 可以保证在升级时只有一定数量的 Pod 是 down 的。默认它会确保至少有比期望的副本数量少一个为 up 状态，也就是最多一个不可用 同时也可以确保只创建出超过期望一定数量的 Pod，默认会比期望的副本数量多一个是 up 状态 未来的 kuberentes 版本中，将从 1-1 变成 25%-25% 当然，也支持自定义更新策略 kubectl explain deploy.spec.strategy.type Recreate：重新创建 rollingUpdate：滚动更新（推荐） maxSurge：指定超出副本数有几个，两种方式：1、指定数量 2、百分比 maxUnavailable：指定副本数量最多有几个不可用 # 查询当前更新策略 kubectl describe deployments {控制器名称} # 找到 RollingUpdateStrategy # 修改当前更新策略 kubectl edit deployment {控制器名称} # 找到 rollingUpdate # 或者使用 patch 打补丁 kubectl patch deployment nginx-deployment -p '{\"spec\": {\"strategy\": {\"rollingUpdate\": {\"maxSurge\":1, \"maxUnavailable\": 0}}}}' 6、金丝雀部署 # 需要设置当前更新策略为 maxSurge:1 maxUnavailable:0 kubectl patch deployment nginx-deployment -p '{\"spec\": {\"strategy\": {\"rollingUpdate\": {\"maxSurge\":1, \"maxUnavailable\": 0}}}}' # 开始更新后直接暂停，此时只会新建一个新版本的 Pod，旧版本的 Pod 不会进行删除 # 此时 svc 网络会将流量负载均衡至当前全部 Pod，就可以测试新版本了 kubectl set image deployment nginx-deployment nginx=nginx:1.9.1 \\ \u0026\u0026 kubectl rollout pause deployment nginx-deployment # 等待测试结束后，继续更新 kubectl rollout resume deployment nginx-deployment ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:3","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"DaemonSet DaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 假如集群时，也会为他们新增一个 Pod。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod 使用 DaemonSet 的一些典型用法： 运行集群存储 daemon，例如在每个 Node 上运行glusterd、ceph 在每个 Node 上运行日志收集 daemon，例如fluentd、logstash 在每个 Node 上运行监控 darmon，例如Promentheus Node Exproter、collectd、Datadog代理、New Relic 代理或者Ganglia gmond apiVersion: apps/v1 kind: DaemonSet metadata: name: daemonset-example labels: app: daemonset spec: selector: matchLabels: name: daemonset-example template: metadata: labels: name: daemonset-example spec: containers: - name: daemonset-example image: nginx ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:4","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Job Job 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束 特殊说明 .spec.template格式同 Pod RestartPolicy 仅支持 Never 或者 OnFailure 当个 Pod 时，默认 Pod 运行成功后 Job 即结束 .spec.completions标志 Job 结束需要成功运行的 Pod 个数，默认为 1 .spec.parallelism标志并行运行的 Pod 个数，默认为 1 spec.activeDeadlineSecods标志失败 Pod 的重试最大时间，超过这个时间不会继续重试 apiVersion: batch/v1 kind: Job metadata: name: job spec: template: metadata: name: job spec: containers: - name: job image: busybox command: ['echo', 'this is a job container'] restartPolicy: Never ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:5","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"CronJob CronJob 基于时间管理的 Job，即： 在给定的时间点只运行一次 周期性的在给定时间点运行 使用条件：当前使用 k8s 集群，版本 \u003e= 1.8 典型用法： 在给定的时间点调度 Job 运行 创建周期性运行的 Job，例如：数据库备份、发送邮件 Spec .spec.schedule：调度，必须字段，指定任务运行周期，格式同 Cron .spec.jobTemplate：Job 模板，必须字段，指定需要运行的任务，格式同 Job .spec.startingDeadlineSeconds：启动 Job 的时间（秒），选填，超出该时间未启动认定为失败，默认没有期限 .spce.concurrencyPolicy：并发策略，选填，指定 Job 的并发执行，只允许以下策略： Allow （默认）：允许并发运行 Forbid： 禁止并发运行，如果前一个还没有完成，则跳过 Replace：取消当前正在运行的 Job，用一个新的替换 以上策略只能应用于同一个 CronJob 创建的 Job，如果存在多个 CronJob，它们之间总是互不干涉的 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:6:6","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"7、Service Kubernetes Service 定义了这样一种抽象： 一个 Pod 的逻辑分组，一种可以访问它们的策略，通常称为 微服务 这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"核心迭代 在 Kubernetes 集群中，每一个 Node 运行一个 kube-proxy进程。kube-proxy 负责为 Service实现一种 VIP（虚拟IP）的形式，而不是ExternalName的形式。在 Kubernetes v1.0 版本，代理完全在 userspace。在 Kubernetes v1.1 版本，增加了 iptables 代理，但并不是默认的运行模式。从 Kubernetes v1.2 起，默认就是 iptables 代理。在 Kubernetes v1.8.0-beta.0 中，添加了 ipvs 代理。在 Kubernetes v1.14 版本开始默认使用 ipvs 代理。 在 Kubernetes v1.0 版本，Service 是 4层（TCP/UDP over IP）概念。在 Kubernetes v1.1 版本，新增了 Ingress API（beta 版），用来表示 7层（HTTP）服务。 1、userspace 代理模式 2、iptables 代理模式 3、ipvs 代理模式 注意：ipvs 模式假定运行 kube-proxy 之前在节点上都已经安装了 IPVS 内核模块。当 kube-proxy以 ipvs 代理模式启动时，kube-proxy 将验证节点是否安装 IPVS 模块，如果未安装，则回退到 iptables 代理模式 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"限制 Service 能够提供负载均衡的能力，但是在使用上有以下限制： 只提供 4 层负载均衡能力，没有 7 层的功能，但有时我们需要更多的匹配规则来转发请求，这点 4 层负载均衡是不支持的 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"类型 ClusterIP：默认类型，自动分配一个仅 Cluster 内部可以访问的虚拟 IP NodePort：在 Cluster Ip 基础上为 Service 在每台机器上绑定一个端口，这样就可以通过 : 来访问服务 LoadBalancer：在 NodePort 的基础上，结束 cloud provider 创建一个外部负载均衡器，并将请求转发到 : ExternalName：把集群外部的服务引入到集群内部来，在集群内部直接使用。没有任何类型代理被创建，这自由 Kubernetes 1.7 或更高版本的 kube-dns 才支持 1、ClusterIP apiVersion: v1 kind: Service metadata: name: myapp namespace: default spec: type: ClusterIP selector: app: myapp relese: stable ports: - name: http port: 80 targetPort: 80 Headless Service apiVersion: v1 kind: Service metadata: name: myapp-headless namespace: default spec: selector: app: myapp clusterIP: \"None\" ports: - port: 80 targetPort: 80 2、NodePort apiVersion: v1 kind: Service metadata: name: myapp-nodeport namespace: default spec: type: NodePort selector: app: myapp relese: stable ports: - name: http port: 80 targetPort: 80 nodePort: 30000 # 可指定 3、LoadBalancer loadBalacer 和 nodePort 其实是同一种方式，区别在于 loadBalancer 比 nodePort 多了一步，就是可以调用 cloud provider 去创建 LB 来向节点导流 4、ExternalName 可以将服务映射到 ExternalName 字段的内容（例如：myapp.otherNS）。ExternalName Service 是 Service 的特例，它没有 selector，也没有定义任何的端口和 Endpoint。相反的、对于运行在集群外部的服务，它通过返回外部服务的别名这种方式来提供服务 kind: Service apiVersion: v1 metadata: name: my-service namespace: default spec: type: ExternalName externalName: myapp.otherNS 但查询主机my-service.default.svc.cluster.local（SVC NAME.NAMESPACE.svc.cluster.local）时，集群的 coreDNS 服务将返回一个值 my.database.example.com 的 CANEM 记录。访问这个服务的工作方式和其他的相同，唯一不同的事重定向发生在 DNS 层，而且不会进行代理和转发 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:7:3","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"8、Ingress Ingress 的功能与 service 大致相似，不同的是 ingerss 提供了7层的代理，而 service 只提供了 4 层代理，如果希望实现 https 的访问则可以使用 Ingress ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:8:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"实现原理 在 k8s 环境下创建一个 nginx pod，在内编写配置文件去反向代理 svc，同时提供 https 服务。其中的 nginx 在修改配置文件的状态下可能会造成服务的不稳定，所以 ingress 的 nginx 版本是不同的，具体逻辑见下图： ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:8:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"示例 http代理 apiVersion: extensions/v1beta1 kind: Deployment metadata: name: myapp spec: replicas: 2 template: metadata: labels: name: app spec: containers: - name: nginx image: myapp:v1 imagePullPolicy: IfNotPresent ports: - containerPort: 80 --- apiVersion: v1 kind: Service metadata: name: app-svc spec: ports: - port: 80 targetPort: 80 protocol: TCP selector: name: app --- apiVersion: extensions/v1beta1 kind: Ingress metadata: name: app-ingress spec: rules: - host: test.localhost http: paths: - path: / backend: serviceName: app-svc servicePort: 80 可以发现 Ingress 依赖与 svc，避免依赖动态的服务副本数量频繁重启 Ingress https代理 创建 https 证书，以及创建 secret 对象进行存储 # 创建证书 openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj \"/CN=nginxsvc /O=nginxsvc\" kubectl create secret tls tls-secret --key tls.key --cert tls.crt 配置文件 apiVersion: extensions/v1beta1 kind: Ingress metadata: name: app-ingress spec: tls: - hosts: - test.localhost secretName: tls-secret rules: - host: test.localhost http: paths: - path: / backend: serviceName: app-svc servicePort: 80 BasicAuth 创建密钥对 yum -y install httpd-tools htpasswd -c auth foo kubectl create secret generic basic-auth --form-file=auth 配置文件 apiVersion: extensions/v1beta1 kind: Ingress metadata: name: ingress-with-auth anntations: nginx.ingress.kubernetes.io/auth-type: basic nginx.ingress.kubernetes.io/auth-secret: basic-auth nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required - foo' spec: rules: - host: test.localhost http: paths: - path: / backend: serviceName: app-svc servicePort: 80 Nginx 进行重写 名称 描述 值 nginx.ingress.kubernetes.io/rewrite-target 必须重定向流量的目标 URL 字符串 nginx.ingress.kubernetes.io/ssl-redirect 指示位置部分是否仅可访问SSL（当 Ingress 包含证书时默认为 true） 布尔 nginx.ingress.kubernetes.io/force-ssl-redirect 即使 Ingress 未启用 TLS，也强制重定向到 HTTPS 布尔 nginx.ingress.kubernetes.io/app-root 定义 Controller 必须重定向到应用程序根，如果它在 ‘/’ 上下文中 字符串 nginx.ingress.kubernetes.io/use-regex 指示 Ingress 上定义当路径是否使用正则表达式 布尔 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:8:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"9、存储 K8S 集群中存储常用的有以下 4 种 ConfigMap: 一般用于存储配置信息 Secret: 存储一些安全类型的内容，例如存储密钥 Volume: 卷，可以保障 Pod 级别的文件存储 Persistent Volume: 持久卷 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:9:0","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"ConfigMap 描述 ConfigMap 功能在 Kubernetes 1.2 版本中引入，许多应用程序会从配置文件、命令行参数或环境变量中读取配置信息。ConfigMap 可以被用来保存单个属性，也可以用来保存整个配置文件或者 JSON 二进制等对象 创建 使用目录创建 ls /root/game # game.file # ui.file cat /root/game/game.file # version=1.17 # name=dave # age=18 cat /root/game/ui.file # level=2 # color=yellow kubectl create configmap game-config --from-file=/root/game -from-file指定在目录下当所有文件都会被用在 ConfigMap 里面创建一个键值对，键的名称就是文件名，值就是文件的内容 使用文件创建 只要指定为一个文件就可以从单文件中创建 ConfigMap kubectl create configmap game-config-2 --from-file=/root/game/game.file --form-file这个参数可以使用多次、可以使用两次分别指定三个实例中的那两个配置文件，效果和指定整个目录是一样的 使用字面值创建 使用文字创建，利用-from-literal参数传递配置信息，该参数可以使用多次，格式如下 kubectl create configmap literal-config --from-literal=name=dave --from-literal=password=pass kubectl get configmap literal-config -o yaml 使用 使用 ConfigMap 来代替环境变量 创建两个 ConfigMap apiVersion: v1 kind: ConfigMap metadata: name: literal-config namespace: default data: name: dave password: pass apiVersion: v1 kind: ConfigMap metadata: name: env-config namespace: default data: log_level: INFO 在 Pod 中使用 ConfigMap apiVersion: v1 kind: Pod metadata: name: cm-env-test-pod spec: containers: - name: test-container image: myapp:v1 command: [\"/bin/sh\", \"-c\", \"env\"] env: # 单个指定 - name: USERNAME valueFrom: configMapKeyRef: name: literal-config key: name - name: PASSWORD valueForm: configMapKeyRef: name: literal-config key: password envFrom: # 批量注入 - configMapRef: name: env-config restartPolicy: Never 使用 ConfigMap 设置命令行参数 apiVersion: v1 kind: Pod metadata: name: cm-env-test-pod spec: containers: - name: test-container image: myapp:v1 command: [\"/bin/sh\", \"-c\", \"echo $(USERNAME) $(PASSWORD)\"] env: # 单个指定 - name: USERNAME valueFrom: configMapKeyRef: name: literal-config key: name - name: PASSWORD valueForm: configMapKeyRef: name: literal-config key: password restartPolicy: Never 通过数据卷插件使用 ConfigMap 在数据卷里面使用这个 ConfigMap，有不同的选项、最基本的就是将文件填入数据卷，在这个文件中，键就是文件名称，值就是文件内容 apiVersion: v1 kind: Pod metadata: name: cm-volume-test-pod spec: containers: - name: test-container image: myapp:v1 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: literal-config restartPolicy: Never 热更新 在通过数据卷插件的形式使用 ConfigMap 时，可以达到热更新的目的，修改 ConfigMap 之后，在 Pod 中的对应文件内容也将修改成对应修改后的内容 创建初始 ConfigMap \u0026 Pod # 初始内容 apiVersion: v1 kind: ConfigMap metadata: name: log-cofnig namespace: default data: log_level: INFO --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: hot-update spec: replicas: 1 template: metadata: labels: run: my-nginx spec: containers: - name: my-nginx image: myapp:v1 ports: - containerPort: 80 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: log-config 查看内容 kubectl exec pod-xxx cat /etc/config/log_level # INFO 修改 ConfigMap kubectl edit cm log-config # log_level=ERROR 再次查看内容，需要一定时间 kubectl exec pod-xxx cat /etc/config/log_level # ERROR **注意：**如果 configMap 以 ENV 的方式挂载，修改并不会实现热更新 滚动更新Pod 在更新 ConfigMap 之后并不会触发 Pod 的滚动更新，可以通过修改 Pod annotations 的方式来强制出发滚动更新 kubectl patch deploy my-nginx --patch '{\"spec\": {\"template\": {\"metadata\": {\"anntations\": {\"version/config\": \"20190411\"}}}}}' 这个例子里我们在.spec.template.metadata.annotations中添加version/config，每次通过修改version/config来触发滚动更新 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:9:1","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Secret 解决了密码、token、密钥等敏感数据等配置问题，而不需要把这些敏感数据暴露到镜像或者 Pod Spec 中。Secret 可以以 Volume 或者环境变量方式使用 Secret有三种类型： Service Account：用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount目录中 Opaque：base64 编码格式的 Secret，用来存储密码、密钥等 kubernetes.io/dockerconfigjson：用来存放私有 docker 仓库等认证信息 Service Account 用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount目录中 kubectl exec pod-xxx -- ls /run/secrets/kubernetes.io/serviceaccount # ca.crt # namespace # token Opaque Secret Opaque 类型的数据是一个 map 类型，要求 value 是 base64 编码格式 创建 $ echo -n \"admin\" | base64 YWRtaW4= $ echo -n \"123456\" | base64 MTIzNDU2 secrets.yaml apiVersion: v1 kind: Secret metadata: name: mysecret type: Opaque data: username: YWRtaW4= password: MTIzNDU2 secret 在挂载后会自动解密 使用 1、将 Secret 挂载到 Volume 中 apiVersion: v1 kind: Pod metadata: labels: name: secret-test name: secret-test spec: volumes: - name: volumes12 secret: secretName: mysecret containers: - image: myapp:v1 name: db volumeMounts: - name: volumes12 mountPath: \"/data\" 2、将 Secret 导出到环境变量中 apiVersion: extensions/v1beta1 kind: Deployment metadata: labels: name: pod-deployment spec: replicas: 2 template: metadata: labels: app: pod-deployment spec: containers: - name: pod-1 image: myapp:v1 ports: - containerPort: 80 env: - name: TEST_USER valueFrom: secretKeyRef: name: mysecret key: username - name: TEST_PASSWORD valueFrom: secretKeyRef: name: mysecret key: password kubernetes.io/dockerconfigjson 使用 kubectl 创建 docker 仓库认证的 secret $ kubectl create secret docker-registry myregistrykey \\ --docker-server=DOCKER_REGISTRY_SERVER \\ --docker-username=DOCKER_USER \\ --docker-password=DOCKER_PASSWOED \\ --docker-email=DOCKER_EMAIL secret \"myregistrykey\" created。 在创建 Pod 的时候，通过 imagePullSecrets来引用刚创建的myregistrykey apiVersion: v1 kind: Pod metadata: name: foo spec: containers: - name: foo image: hub.xxx.com/xxx/xxxx imagePullSecrets: - name: myregistrykey ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:9:2","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Volume「卷」 容器磁盘上的文件等生命周期是短暂的，这就使得在容器中运行重要应用时会出现一些问题。首先，当容器崩溃时，kubelet 会重启它，但是容器中的文件将丢失，容器将以干净的状态（镜像最初的状态）重新启动。其次，在Pod中同时运行多个容器时，这些容器之间通常需要共享文件。Kubernetes 中的 Volume 抽象就很好的解决了这些问题。 Kubernetes 中的卷有明确的寿命（与封装它的 Pod 相同）。所以，卷的生命比 Pod 中的所有容器都长，当这个容器重启时数据仍然得以保存。当然，当 Pod 不再存在时，卷也将不复存在。也许更重要的是，Kubernetes 支持多种类型的卷，Pod 可以同时使用任意数量的卷 类型 kubernetes 支持以下类型的卷： csi 通用存储接口 hostPath 主机路径（不能限制使用量） emptyDir 空目录 awsElasticBlockStore azureDisk azureFile cephfs downwardAPI fc flocker gcePersistentDisk gitRepo glusterfs hostPath iscsi local nfs persistentVolumeClaim projected portworxVolume quobyte rbd scaleIO secret storageos vsphereVolume emptyDir 当 Pod 被分配给节点时，首先创建 emptyDir 卷，并且只要该 Pod 在该节点上运行，该卷就会存在。正如卷名字所述，它最初时空的。Pod 中的容器可以读取喝写入 emptyDir 卷中的相同文件，尽管该卷可以挂载到每个容器中的相同或不同路径上。当出于任何原因从节点中删除 Pod 时，empryDir 中的数据将被永久删除 ⚠️注意： 容器崩溃不会从节点中移除 Pod，因此 emptyDir 卷中的数据在容器崩溃时是安全的 用法： 暂存空间，例如用于基于磁盘的合并排序、用作长时间计算崩溃恢复时的检查点 Web 服务器容器提供数据时，保存内容管理器提取的文件 apiVersion: batch/v1 kind: Job metadata: name: jobs-empty spec: template: spce: restartPolicy: Never initContainers: - name: job-1 image: busybox:1.34.1 command: - \"sh\" - \"-c\" - \u003e for i in 1 2 3; do echo \"job-1 `date`\"; sleep 1s; done; echo job-1 GG \u003e /src/input/code volumeMounts: # 挂载一个卷 - name: input mountPath: /src/input/ - name: job-2 image: busybox:1.34.1 command: - \"sh\" - \"-c\" - \u003e for i in 1 2 3; do echo \"job-2 `date`\"; sleep 1s; done; cat /src/input/code \u0026\u0026 echo job-2 GG \u003e /sec/input/output/file volumeMounts: # 挂载两个卷 - name: input mountPath: /src/input/ - name: output mountPath: /src/input/output/ containers: - name: job-3 image: busybox:1.34.1 command: - \"sh\" - \"-c\" - \u003e echo \"job-1 and job-2 completed\"; sleep 3s; cat /src/output/file volumeMounts: - name: output mountPath: /src/output/ volumes: - name: input emptyDir: {} - name: output emptyDir: {} hostPath hostPath 卷将主机节点的文件系统中的文件或目录挂载到集群中 用途如下： 运行需要访问 Docker 内部的容器；使用 /var/lib/docker 的 hostPath 在容器中运行 cAdvisor; 使用 /dev/cgroups 的 hostPath 允许 Pod 指定给定的 hostPath 是否应该在 Pod 运行之前存在，是否应该创建，以及它应该以什么形式存在 除了所需的 path 属性之外，用户还可以为 hostPath 卷指定 type 值 行为 空字符串（默认）用于向后兼容，这意味着在挂载 hostPath 卷之前不会执行任何检查 DirectoryOrCreate 如果在给定的路径没有任何东西存在，那么将根据需要在那里创建一个空目录，权限设置为 0755，与 kubelet 具有相同的组喝所有权 Directory 给定的路径下必须存在目录 FileOrCreate 如果在给定的路径没有任何东西存在，那么将根据需要在那里创建一个空文件，权限设置为 0655，与 kubelet 具有相同的组喝所有权 File 给定的路径下必须存在文件 Socket 给定的路径下必须存在 UNIX 套接字 CharDevice 给定的路径下必须存在字符设备 BlockDevice 给定的路径下必须存在块设备 使用这种卷类型时请注意，因为： 由于每个节点上的文件都不同，具有相同配置（例如从 PodTemplate 创建的）的 Pod 在不同节点上的行为会有所不同 当 Kubernetes 按照计划添加资源感知调度时，将无法考虑 hostPath 使用的资源 在底层主机上创建的文件或目录只能由 root 写入，您需要在特权容器中以 root 身份运行进程，或修改主机上的文件权限以便写入 hostPath 卷 apiVersion: v1 kind: Pod metadata: name: test-pd spec: containers: - image: myapp:v1 name: test-container volumeMounts: - name: test-volume mountPath: /test-pd volumes: - name: test-volume hostPath: path: /data type: Dirctory ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:9:3","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":"Persistent Volume「持久卷」 概念 PersistentVolume（PV） 是由管理员设置的存储，它是集群的一部分，就像节点是集群中的资源一样，PV 也是集群中的资源。PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期。此 API 对象包含存储实现的细节，即 NFS、ISCSI 或特定于云供应商的存储系统 PersistentVolumeClaim（PVC） 是用户存储的请求，它与 Pod 相似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和 内存）。声明可以请求特定的大小和访问模式（例如：可以以读/写一次或只读多次模式挂载） 静态PV 集群管理员创建一些 PV。它们带有可供集群用户使用的实际存储的细节。它们存在于 Kuberneters API 中，可用于消费。 动态PV 当管理员创建的静态 PV 都不匹配用户的 PVC 时，集群可能会尝试动态的为 PVC 创建卷。此配置基于 StorageClasses： PVC 必须请求 「存储类」，并且管理员必须创建并配置该类才能进行动态创建。声明该类为 \"\" 可以有效的禁用其动态配置 要启用基于存储级别的动态存储配置，集群管理员需要启用 API server 上的 DefaultStorageClass「准入控制器」。例如，通过确保 DefaultStorageClass 位于 API server 组件的 --admission-control 标志，使用逗号分隔的有序值列表中，可以完成此操作 绑定 master 中的控制环路监听新的 PVC，寻找匹配的 PV（如果可能），并将它们绑定在一起。如果为新的 PVC 动态掉配 PV，则该环路将始终将 PV 绑定到 PVC，否则用户总会得到他们所请求的存储，但是容量可能超出要求的数量。一旦 PV 和 PVC 绑定后，PersistentVolumeClaim 绑定是排他性的，不管它们是如何绑定的。PVC 跟 PV 绑定是一对一的映射 保护 PVC 保护的目的是确保由 Pod 正在使用的 PVC 不会从系统中移除，因为如果被移除的话可能会导致数据丢失 ⚠️**注意：**当 Pod 状态为 Pending 并且 Pod 已经分配给节点或 Pod 为 Running 状态时，PVC处于活跃状态 当启用 PVC 保护 alpha 功能时，如果用户删除了一个 Pod 正在使用的 PVC，则该 PVC 不会被立即删除。PVC 的删除将被推迟，直到 PVC 不再被任何 Pod 使用 分类 PersistentVolume 类型以插件形式出现。Kubernetes 目前支持以下插件类型： HostPath GCEPersistentDisk AWSElasticBlockStore AzureFile AzureDisk FC(Fibre Channel) FlexVolume Flocker NFS iSCSI RBD CephFS Cinder(OpenStack block storage) Glusterfs VsphereVolume Quobyte Volumes Vmware Photon Portworx Voumes ScaleIO Volumes StorageOS 持久卷示例代码 apiVersion: v1 kind: PersistentVolume metadata: name: pv0001 spec: capacity: # 容量 storage: 5Gi volumeMode: Filesystem # 卷模式 accessModes: # 访问策略 - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle # 回收策略 storageClassName: slow # 存储类名称 默认为 StorageClass mountOptions: - hard - nfsvers=4.1 nfs: path: /tmp server: 172.17.0.2 访问模式 PV 可以以资源提供者支持的任何形式挂载到主机上。如下表所示，供应商具有不同的功能，每个 PV 的访问模式都将被设置为该卷支持的特定模式。例如，NFS 可以支持多个读/写客户端，但特定的 NFS PV 可能以只读方式导出到服务器上。每个 PV 都有一套自己的用来描述特定功能的访问模式 ReadWriteOnce 该卷可以被单个节点以读/写模式挂载 ReadOnlyMany 该卷可以被多个节点以只读模式挂载 ReadWriteMany 该卷可以被多个节点以读/写模式挂载 在命令行中，访问模式缩写为： RWO - ReadWriteOnce ROX - ReadOnlyMany ReadWriteMany - RWX ⚠️**注意：**一个卷一次只能使用一种访问模式挂载，即使它支持很多访问模式。例如，GCRPersistentDisk 可以由单个节点作为 ReadWriteOnce 模式挂载，或由多个节点以 ReadOnlyMany 模式挂载，但不能同时挂载 回收策略 Retain（保留）：手动回收 Recycle（回收）：基本擦除（rm -rf /thevolume/*） Delete（删除）：关联的存储资产（例如 AWS EBS…）将被删除 当前，只有 HostPath 支持回收策略，AWS EBS、GCE PD、Azure Disk 和 Cinder 卷支持删除策略 状态 卷可以处于一下的某种状态： Available（可用）：一块空闲资源还没有被任何声明绑定 Bound（已绑定）：卷已经被声明绑定 Released（已释放）：声明被删除，但是资源还未被集群重新声明 Failed（失败）：该卷的自动回收失败 命令行会显示绑定到 PV 的 PVC 的名称 ","date":"2022-06-07","objectID":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/:9:4","tags":["k8s"],"title":"K8S学习笔记","uri":"/k8s%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"categories":null,"content":" 此文章为转载，原文章链接动态字段存储方案对比 - 修行编程，沉淀技术，记录生活 - JinTang’s Zone ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:0:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"一、前言 最近在考虑PAAS移动平台的”动态字段存储”问题，简单来说就是前段某页面中的表单动态增加一个编辑框，以某一个新字段的形式提交到后端，后端接口能够在不增加新的表字段且基本不需要修改代码的方式存储起来。 我们都知道，关系型数据库MySQL的数据表在修改表字段时，代价比较大，甚至出现锁表导致服务奔溃。有什么好的办法呢？下面我仍然基于MySQL，对比了两种可行的方法，希望对你有帮助。 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:1:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"二、动态结构 关系数据库非常适合具有大量关系的结构化数据，它所存储的数据都是预先能够定义出清晰的结构，并且短期或更长的时间内结构不会发生变化。但是业务总是不断在变化的，业务在扩展，存储的信息必然更多更广，表结构发生变化几乎是不可避免。 为了解决”动态结构”的问题也有不少轻易能够想到的方法： 列模型：就是常说的”宽表”，为了应对表结构的改变，我们可以在设计表结构的时候，预留多一些空白字段，简单好理解，但是容易造成数据的”稀疏性”，同时长远看来宽表太宽存储性能很差，太窄会满足不了业务变化。 行模型：就是以key-value结构作为一行存储到表中，每增加一个字段就新增一行数据，兼顾灵活性，问题在于value定义类型只能是varchar，大小也需要做限制。 NoSQL：利用NoSQL基于document类型的特性，可以很方便地存储动态结构并且查询效率高，但问题在于业务改造成本大，同时需要ACID事务的场景支持度不够。 还有一种模型，目前在诸如医疗数据库、犯罪数据库和大型电商类数据等有着广泛应用的成熟模型：EAV模型，也即是以”实体-属性-值”来组织数据。 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:2:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"EAV模型 在开源和php社区，最著名的EAV实现是Magento，一个电子商务平台。EAV模型，就是把实体-属性-值（Entity-Attribute-Value）分开表进行存储。实体表存储对象的ID和主要属性，属性表存储需要扩展的属性，值表由不同类型的表组成一个集合，一个值需要由实体ID+属性ID来确定。 为了方便查找某一个实体具备哪些属性，可以增加实体类型（type_id），基于实体的类型，可以通过查找eav_attribute来找到要设置产品的那一属性。当需要操作某一个实体的属性时，就可以先把实体拥有的属性先查出来，再对属性进行操作，设置属性值时，先判断属性的类型是什么，再找到对应类型的值表，然后更新改属性的值。 虽然EAV模型能够解决以上三种模型的缺点，有着灵活性强，完美解决数据稀疏性，但是它也因为太过于复杂，有着明显的学习曲线，查询性能也相对低下，必须为其提升性能做大量的辅助工作。 我的目标是寻找一种动态结构的数据的模型性能可与文档数据库相媲美，结构更简单比EAV更具可读性。那就是MySQL5.7以后支持的JSON类型，也就表字段类型为JSON，用于存储动态扩展字段。 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:2:1","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"JSON模型 JSON模型，比较MySQL5.7以前使用text类型来存文本JSON的方式，JSON模型兼顾了性能及易用性，在操作和性能上都得到很大的提升。JSON类型是以二进制方式存储的，要比字符串更加高效，再也不用json序列化近文本字段，查询之后还要解析，同时还要兼顾json的合法性。 在MySQL 5.7.8中，MySQL支持由RFC 7159定义的本地JSON数据类型，它支持对JSON(JavaScript对象标记)文档中的数据进行有效访问. 有如下几个特性： MySQL会对DML JSON数据自动验证。无效的DML JSON数据操作会产生错误. 优化的存储格式。存储在JSON列中的JSON文档转换为一种内部格式，允许对Json元素进行快速读取访问. MySQL Json类型支持建立索引增加查询性能提升. 另外有还有一种我认为收益比较大的是：虚拟列 Virtual Column 在MySQL 5.7中，支持两种Generated Column，即Virtual Generated Column和Stored Generated Column，前者只将Generated Column保存在数据字典中（表的元数据），并不会将这一列数据持久化到磁盘上；后者会将Generated Column持久化到磁盘上，而不是每次读取的时候计算所得。很明显，后者存放了可以通过已有数据计算而得的数据，需要更多的磁盘空间，与Virtual Column相比并没有优势，因此，MySQL 5.7中，不指定Generated Column的类型，默认是Virtual Column。 有了虚拟列，在select子句和where子句中，查询虚拟列与普通的列没有不同，查询用法上可以基本不需要变化。同时由于虚拟列的特性，只是与json中的属性key的一种映射关系，所以虚拟列的增删性能是非常好的。 另外，在建立了虚拟列之后，可以继续对虚拟列建立索引，可以提升查询性能，有了索引，性能几乎跟普通没有区别。 下面的第五节的模型操作对比中会给出一些JSON操作的实例，更多参考官方文档：https://dev.mysql.com/doc/refman/5.7/en/json.html 下面给出列模型、行模型、EAV模型和JSON模型的优缺点及表结构对比： 由于列模型、行模型和NoSQL都是比较容易理解和常见，所以下文重点只对EAV模型和JSON模型进行分析和对比 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:2:2","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"三、性能测试结果对比 下面是两种模型参与性能测试的SQL，包括查询，更新和插入数据，可以对比观察一下不同模型SQL的复杂度： 下面为SQL在不同量级的数据量时，从查询、更新、插入、建立字段和索引等操作维度，对比了EAV模型、MySQL5.7的JSON模型 和 MySQL8.0的JSON模型 的性能，另外对比了磁盘空间占用和数据导入性能 图表展示，方便查看趋势 结论： 两种模型从操作的复杂度比较，EAV模型要复杂得多，查询不宜联查这么多的表，所以每次都必须分步骤，查询有哪些属性并拿到属性ID（当然可以利用缓存来优化），JSON模型只要有虚拟列，查询时与普通的方式没有却别，插入或更新时需要利用函数； 从查询性能来看，JSON模型明显优于EAV模型。不过虽然这样，EAV只要做好适当的缓存优化，其实是可以满足一定的场景并被接受； 无论在那个数量级下，JSON模型操作虚拟列时的消耗都是极快，而对于给虚拟列添加索引，性能会随着数据量级的增大而增加，毕竟需要建立索引树，也是正常操作了，与普通列的索引差不多； MySQL8.0对JSON类型也做了增强，对比MySQL5.7，在添加/删除索引的性能上，性能提升了接近一倍，虚拟列的操作性能在不同数据量级下，更加稳定； 由于测试用例还是比较粗略，所以不一定100%精准，发现哪里有问题，欢迎指正。 对EAV模型和JSON模型的表结构和增删改查等操作感兴趣的，请看第五节”动态存储模型实际案例” ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:3:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"四、总结 本篇为你介绍了动态结构的场景，并且列举了几个可行的存储模型：列模型（宽表），行模型，EAV模型和JSON模型，并且分析了各种模型的优缺点，通过实际的案例来对比分析了EAV模型和JSON模型，了解了这两种模型的实际操作的SQL语句，展示了不同的数据量级下的查询、插入和更新性能。 经过一番对比，相信你已经面对”动态结构”的场景时候，已经有据可依了，希望对你有帮助。 肝文章不易，点个赞再走。感谢！！ ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:4:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"五、附加：动态存储模型实际案例 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:5:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"1. EAV模型（Entity-Attribute-Value Model） 表结构 属性表 create table `eav_attribute` ( `id` int unsigned not null auto_increment comment '属性ID', `entity_type_id` int unsigned not null default 0 comment '实体类型ID', `attribute_code` varchar(128) not null default '' comment '属性Code', `attribute_name` varchar(128) not null default '' comment '属性名称', `attribute_type` enum ('int', 'varchar', 'text', 'decimal', 'datetime') not null comment '属性类型', primary key (`id`), index `IDX_ENTITY_TYPE_ID` (`entity_type_id`), index `IDX_TYPE` (`attribute_type`) ) engine = innodb charset = utf8mb4 comment 'eav属性表'; 用户实体表 create table `user_entity` ( id int auto_increment primary key comment '用户实体ID', type_id int unsigned not null default 0 comment '实体类型ID', username varchar(32) default '' not null comment '用户名' ) engine = innodb charset = utf8mb4 comment '用户实体表'; 用户整型值表 create table `user_int` ( `entity_id` int unsigned not null comment '实体ID', `attribute_id` int unsigned not null comment '属性ID', `value` int not null default 0 comment '整型值', primary key (`entity_id`, `attribute_id`), index `IDX_VALUE` (`value`) ) engine = innodb charset = utf8mb4 comment 'user整型值表'; 用户字符串值表 create table `user_varchar` ( `entity_id` int unsigned not null comment '实体ID', `attribute_id` int unsigned not null comment '属性ID', `value` varchar(255) not null default '' comment '字符值', primary key (`entity_id`, `attribute_id`), index `IDX_VALUE` (`value`) ) engine = innodb charset = utf8mb4 comment 'user字符值表'; 用户文本值表 create table `user_text` ( `entity_id` int unsigned not null comment '实体ID', `attribute_id` int unsigned not null comment '属性ID', `value` text comment '文本值', primary key (`entity_id`, `attribute_id`) ) engine = innodb charset = utf8mb4 comment 'user文本值表'; 用户浮点型值表 create table `user_decimal` ( `entity_id` int unsigned not null comment '实体ID', `attribute_id` int unsigned not null comment '属性ID', `value` decimal(9, 2) unsigned not null comment '浮点值', primary key (`entity_id`, `attribute_id`), index `IDX_VALUE` (`value`) ) engine = innodb charset = utf8mb4 comment 'user浮点值表'; 用户日期型值表 create table `user_datetime` ( `entity_id` int unsigned not null comment '实体ID', `attribute_id` int unsigned not null comment '属性ID', `value` datetime not null comment '日期值', primary key (`entity_id`, `attribute_id`), index `IDX_VALUE` (`value`) ) engine = innodb charset = utf8mb4 comment 'user日期值表'; 插入属性数据 INSERT INTO `eav_attribute` (id, entity_type_id, attribute_code, attribute_name, attribute_type) VALUES (1, 1, 'name', '姓名', 'varchar'), (2, 1, 'age', '年龄', 'int'), (3, 1, 'gender', '性别', 'varchar'), (4, 1, 'phone', '电话', 'varchar'), (5, 1, 'mobile', '移动电话', 'varchar'), (6, 1, 'address', '家庭住址', 'varchar'), (7, 1, 'height', '身高(cm)', 'decimal'), (8, 1, 'weight', '体重(kg)', 'decimal'), (9, 1, 'profile', '简介', 'text'), (10, 1, 'birthday', '出生年月', 'datetime'); ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:5:1","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"2. JSON模型 表结构 用户表 create table `user` ( `id` int unsigned not null auto_increment comment '用户ID', `username` varchar(32) not null default '' comment '账号', primary key(`id`) ) engine = innodb charset = utf8mb4 comment '用户主表'; 用户源数据表 create table `user_metadata` ( `id` int unsigned not null auto_increment comment '用户元数据', `field_code` varchar(32) not null default '' comment '字段code', `field_name` varchar(32) not null default '' comment '字段名', `field_type` varchar(32) not null default '' comment '字段类型', primary key(`id`), index `IDX_FIELD` (`field_name`, `field_type`) ) engine = innodb charset = utf8mb4 comment '用户元数据表'; 用户扩展字段表 create table `user_extra_field` ( `id` int unsigned not null auto_increment comment '字段id', `user_id` int unsigned not null default 0 comment '用户ID', `properties` json default null comment '扩展字段', primary key(`id`), index `IDX_USER_ID` (`user_id`) ) engine = innodb charset = utf8mb4 comment '用户扩展字段表'; 元数据 insert into `user_metadata` (id, field_code, field_name, field_type) VALUES (1, 'name', '姓名', 'varchar'), (2, 'age', '年龄', 'int'), (3, 'gender', '性别', 'varchar'), (4, 'phone', '电话', 'varchar'), (5, 'mobile', '移动电话', 'varchar'), (6, 'address', '家庭住址', 'varchar'), (7, 'height', '身高(cm)', 'decimal'), (8, 'weight', '体重(kg)', 'decimal'), (9, 'profile', '简介', 'text'), (10,'birthday', '出生年月', 'datetime'); 说明：由于json类型里的数据类型也是只有字符串、数字、对象（JSON 对象）、数组、布尔和Null，所以使用元数据表把属性的具体类型存储起来，可以在必要时可以在代码层做类型转换逻辑。 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:5:2","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"模型操作对比 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:6:0","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"1. 字段操作 增加一个”edu”学历字段 EAV模型 只需要在属性表eav_attribute中增加一行即可 insert into eav_attribute (entity_type_id, attribute_code, attribute_name, attribute_type) values (1, 'edu', '学历', 'varchar'); JSON 需要在元数据表user_metadata增加一行，并且增加虚拟列edu以及其索引 alter table user_extra_field add column `edu` varchar(32) GENERATED ALWAYS AS (json_extract(`properties`,'$.edu')) VIRTUAL; alter table user_extra_field add index `IDX_EDU` (`edu`); 删除mobile字段 EAV模型 需要三步： 查询mobile属性 删除属性记录 删除属性值 -- step1: 查询属性信息 select * from eav_attribute where entity_type_id = 1; -- step2: 删除字段 delete from eav_attribute where id = 5; -- step3: 删除值 delete from user_varchar where attribute_id = 5; JSON模型 利用json_remove()方法，可以直接删除json字段对应的属性 -- step1: 删除字段 delete from user_metadata where field_code = 'mobile'; -- step2: 删除值 update user_extra_field set properties = json_remove(properties, '$.mobile'); -- step3: 删除虚拟列 alter table user_extra_field drop column `mobile`; 注意，第2、3步可以根据业务自身考虑是否有必要，为了节省空间，那些确定不再使用的属性字段可以考虑删除，缩小json体积。 ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:6:1","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"2. 查询操作 查询身高高于170cm，年满18岁的男性用户 EAV模型 需要分三步进行查询，每一步的结果传递需要代码逻辑层实现，此处直接贴出所有的查询SQL -- step1: 查询所有属性 select * from eav_attribute where entity_type_id = 1; -- step2: 根据条件过滤出用户ID select i.entity_id from user_int as i join user_varchar as v on i.entity_id = v.entity_id and v.value = '男' and v.attribute_id = 3 join user_decimal as d on v.entity_id = d.entity_id and d.value \u003e 170 and d.attribute_id = 7 where i.attribute_id = 2 and i.value \u003e 18; -- step3: 根据用户ID与属性，查询满足条件的实体信息 select entity_id as id, `value`, a.attribute_code from ( select entity_id, `value`, attribute_id from user_int where attribute_id = 2 and entity_id in (1,3,4,6,10,13,17,18) union all select entity_id, `value`, attribute_id from user_varchar where attribute_id in (1, 3) and entity_id in (1,3,4,6,10,13,17,18) union all select entity_id, `value`, attribute_id from user_datetime where attribute_id = 10 and entity_id in (1,3,4,6,10,13,17,18) union all select entity_id, `value`, attribute_id from user_decimal where attribute_id = 7 and entity_id in (1,3,4,6,10,13,17,18) ) as s join eav_attribute as a on s.attribute_id = a.id; 注意：查出来的结果，还需要进行key-value的转换 JSON模型 select u.id, json_unquote(f.properties -\u003e '$.name') as name, json_unquote(f.properties -\u003e '$.gender') as gender, f.properties -\u003e '$.height' as height, json_unquote(f.properties -\u003e '$.birthday') as birthday from user as u join user_extra_field as f on u.id = f.user_id and f.properties -\u003e '$.age' \u003e 18 and f.properties -\u003e '$.height' \u003e 170 and f.properties -\u003e '$.gender' = '男' 在建立了虚拟列的前提下，查询与传统的方式没有区别 select u.id,f.name,f.gender,f.height, f.birthday from user as u join user_extra_field as f on u.id = f.user_id and f.age \u003e 18 and f.height \u003e 170 and f.gender = '男' 查询用户详情：查询用户ID为3的用户信息 EAV模型 需要分两步：1. 查询所有的属性，2.根据属性ID和用户ID，查询属性值 -- step1: 查询所有属性 select * from eav_attribute where entity_type_id = 1; -- step2: 根据属性及id，查询id为3的用户信息 select entity_id as id, `value`, a.attribute_code from ( select entity_id, `value`, attribute_id from user_int where attribute_id = 2 and entity_id = 3 union all select entity_id, `value`, attribute_id from user_varchar where attribute_id in (1,3,4,5,6) and entity_id = 3 union all select entity_id, `value`, attribute_id from user_decimal where attribute_id in (7, 8) and entity_id = 3 union all select entity_id, `value`, attribute_id from user_text where attribute_id = 9 and entity_id = 3 union all select entity_id, `value`, attribute_id from user_datetime where attribute_id = 10 and entity_id = 3 ) as s join eav_attribute as a on s.attribute_id = a.id JSON模型 select u.id, u.username, f.properties from user as u join user_extra_field as f on u.id = f.user_id where u.id = 3; ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:6:2","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"3. 插入数据 新增一条数据 insert into user (id, username, name, age, gender, phone, address, profile, birthday) values (20, 'jayzone', '张三', 22, '男', '13722211133', '广东省深圳市宝安区西乡街道华泰大厦101', '我很好，你呢？', '1994-01-11'); EAV模型 分两步操作: 1.查询所有属性，2.根据属性ID和值，插入到对应的表中 -- step1: 查询所有属性 select * from eav_attribute where entity_type_id = 1; -- step2: 把值插入到对应的表 insert into user_entity (id, username, type_id) values (20, 'jayzone', 1); insert into user_int (entity_id, attribute_id, value) values (20, 2, 22); insert into user_varchar (entity_id, attribute_id, value) values (20, 1, '张三'), (20, 3, '男'), (20, 4, '13722211133'), (20, 6, '广东省深圳市宝安区西乡街道华泰大厦101'); insert into user_text (entity_id, attribute_id, value) values (20, 9, '我很好，你呢？'); insert into user_datetime (entity_id, attribute_id, value) values (20, 10, '1994-01-11 00:00:00'); JSON模型 需要使用**json_object()**方法构建json对象，在存入JSON字段中 insert into user (id, username) values (20, 'jayzone'); insert into user_extra_field (user_id, properties) values (20, json_object('name', '张三', 'age', 22, 'gender', '男', 'phone', '13722211133', 'address', '广东省深圳市宝安区西乡街道华泰大厦101', 'profile', '我很好,你呢？', 'birthday', '1994-01-11')); ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:6:3","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"4. 更新数据 新增一个字段, 并且更新用户ID=3的用户学历为本科 EAV模型 需要在eav_attribute表中增加一行记录，然后更新对应的值 -- step1: 查询属性 select * from eav_attribute where entity_type_id = 1; -- step2: 更新对应属性的值 update user_varchar set value = '本科' where entity_id = 3 and attribute_id = 11; JSON模型 利用json_insert/json_set方法更新对应字段的值 update user_extra_field set properties = json_set(properties, '$.phone', '15016716555') where id = 3; ","date":"2022-05-17","objectID":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/:6:4","tags":["MySQL","JSON"],"title":"MySQL动态存储方案对比「转」","uri":"/%E5%8A%A8%E6%80%81%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94%E8%BD%AC%E8%BD%BD/"},{"categories":null,"content":"1、卸载旧版本 sudo apt remove docker docker-engine docker.io containerd runc ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:1","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"2、安装相关依赖包 sudo apt update \u0026\u0026 sudo apt install -y apt-transport-https ca-certificates curl gnupg lsb-release ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:2","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"3、添加证书\u0026镜像 官方镜像 # 官方镜像 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # 如果你使用的是 Ubuntu 22.04 请使用 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/aliyun-docker-archive-keyring.gpg sudo add-apt-repository \"deb [arch=arm64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" 阿里云镜像 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - # 如果你使用的是 Ubuntu 22.04 请使用 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg ｜ sudo gpg --dearmor -o /usr/share/keyrings/aliyun-docker-archive-keyring.gpg sudo add-apt-repository \"deb [arch=arm64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\" 如果卡住不动的话，可以先 wget 下载文件，直接导入 wget http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg sudo apt-key add ./gpg ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:3","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"4、安装 sudo apt update \u0026\u0026 sudo apt install -y containerd ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:4","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"5、生成配置文件 mkdir -p /etc/containerd \u0026\u0026 containerd config default | sudo tee /etc/containerd/config.toml # 修改配置文件 # 老版本需要手动添加 `SystemdCgroup = true` sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml \u0026\u0026 grep 'SystemdCgroup' -B 11 /etc/containerd/config.toml ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:5","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"6、配置镜像加速官方链接 # 这里需要替换为自己阿里云的镜像加速器地址 sudo sed -i 's#endpoint = \"\"#endpoint = \"https://xxxxxx.mirror.aliyuncs.com\"#g' /etc/containerd/config.toml \u0026\u0026 grep 'endpoin' -B 5 /etc/containerd/config.toml sed -i 's#sandbox_image = \"k8s.gcr.io/pause#sandbox_image = \"registry.aliyuncs.com/google_containers/pause#g' /etc/containerd/config.toml \u0026\u0026 grep 'sandbox_image' /etc/containerd/config.toml ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:6","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"7、重载服务器配置 systemctl daemon-reload \u0026\u0026 systemctl restart containerd.service ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:7","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"8、检查运行情况 systemctl status containerd ","date":"2022-05-14","objectID":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/:0:8","tags":["k8s","containerd"],"title":"K8Sv1.24.0 containerd 安装教程","uri":"/k8sv1.24.0-containerd%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"},{"categories":null,"content":"1、卸载可能存在的旧版本 sudo apt remove docker docker-engine docker-ce docker.io ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:1","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"2、安装依赖使 apt 可通过 HTTPS 下载包 sudo apt update \u0026\u0026 apt install -y apt-transport-https ca-certificates curl software-properties-common ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:2","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"3、添加 docker 密钥 3.1、阿里云 docker 源 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 3.2、官方 docker 源 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:3","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"4、添加对应的 docker 源「需要和第三部一致」 4.1、阿里云 「官方文档」 sudo add-apt-repository \"deb [arch=arm64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\" 4.2、官方源 sudo add-apt-repository \"deb [arch=arm64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" $(lsb_release -cs)是获取当前 Ubuntu 代号 如果没有科学上网手段，推荐使用阿里云源 ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:4","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"5、安装 docker sudo apt update \u0026\u0026 apt install -y docker-ce ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:5","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"6、配置镜像仓库 mkdir /etc/docker cat \u003e /etc/docker/daemon.json \u003c\u003c EOF { \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"100m\" }, \"registry-mirrors\": [\"https://xxx.mirror.aliyuncs.com\"] } EOF # 设置完成后重启 sudo systemctl daemon-reload sudo systemctl restart docker ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:6","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"7、验证安装 systemstl status docker 正常运行则会显示 ","date":"2022-05-13","objectID":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/:0:7","tags":["Ubuntu","ARM","Docker"],"title":"Ubuntu ARM Docker 安装","uri":"/ubuntu-arm-docker-%E5%AE%89%E8%A3%85/"},{"categories":null,"content":"在 Hugo 的配置文件中添加一行 hasCJKLanguage = true # 字数统计添加中文支持 重新编译即可 ","date":"2022-05-11","objectID":"/%E8%A7%A3%E5%86%B3hugo%E5%AD%97%E6%95%B0%E7%BB%9F%E8%AE%A1%E4%B8%8D%E6%AD%A3%E7%A1%AE/:0:0","tags":["Hugo"],"title":"解决Hugo字数统计不正确","uri":"/%E8%A7%A3%E5%86%B3hugo%E5%AD%97%E6%95%B0%E7%BB%9F%E8%AE%A1%E4%B8%8D%E6%AD%A3%E7%A1%AE/"},{"categories":null,"content":"问题 Typora 可以方便的将文件保存在本地，但是不合理的设置将无法适应各种静态博客生成工具（比如：hugo）的图片存储方式，所以要对 Typora 进行设置。 ","date":"2022-05-11","objectID":"/%E5%A6%82%E4%BD%95%E5%9C%A8hugo%E5%92%8Ctypora%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87/:0:1","tags":["Typora","image"],"title":"如何在Hugo和Typora中显示图片","uri":"/%E5%A6%82%E4%BD%95%E5%9C%A8hugo%E5%92%8Ctypora%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87/"},{"categories":null,"content":"目标 hugo 的默认图片路径为 ${site}/static/images目录，所以我们需要配置 Typora 的图片默认复制到整个目录。并且达到在网站和 Typora 中同时可查看。 ","date":"2022-05-11","objectID":"/%E5%A6%82%E4%BD%95%E5%9C%A8hugo%E5%92%8Ctypora%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87/:0:2","tags":["Typora","image"],"title":"如何在Hugo和Typora中显示图片","uri":"/%E5%A6%82%E4%BD%95%E5%9C%A8hugo%E5%92%8Ctypora%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87/"},{"categories":null,"content":"解决 对于 Typora 图片的默认复制路径可以直接进行配置，如下图所示： 也可以再加上 static/images/${filename}/，这样可以更加方便的管理图片。 但是这样配置完会发现，Hugo 读取图片的条件满足了，Typora 预览没法满足，在设置里我们也找到调整的位置。 其实 Typora 有一个隐藏的配置，格式( Format ) -\u003e 图像( Image ) -\u003e 设置图片根目录( Use Image Root Path )，具体可以依据下图。 配置是在当个 md 文件中生效的，在设置后在文件的开头会添加上typora-root-url: ../../../static/，也就是具体的原理了。 ","date":"2022-05-11","objectID":"/%E5%A6%82%E4%BD%95%E5%9C%A8hugo%E5%92%8Ctypora%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87/:0:3","tags":["Typora","image"],"title":"如何在Hugo和Typora中显示图片","uri":"/%E5%A6%82%E4%BD%95%E5%9C%A8hugo%E5%92%8Ctypora%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87/"},{"categories":null,"content":"常用命令 rustc rustc xxx.rs // 编译Rust程序 cargo cargo build // 编译Rust项目，如block在更新lock文件，可执行 rm -rf ~/.cargo/.package-cache cargo run // 立刻运行Rust项目 cargo doc –open // 生成并打开项目文档 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:1:0","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"常见概念 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:0","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"变量和可变性 使用let xxx 声明一个变量，此时这个变量是不可变的，但是可以被隐藏 使用let mut xxx 声明一个可变变量，此时变量可以被重新赋值 使用const XXX声明一个常量，常量不可被重新赋值 隐藏 ​ 重复使用let定义一个与之前变量同名的变量，我们称第一个变量被第二个变量隐藏了，此时使用该名称的变量会使用第二个变量，我们可以重复使用let来多次隐藏。 fn main() { let x = 5; let x = x + 1; { let x = x * 2; println!(\"block inner x:{}\", x); } println!(\"block outer x:{}\", x); } 上面例子会输出： block inner x:12 block outer x:6 ​ 这个程序首先将 x 绑定到值 5 上。接着通过 let x = 隐藏 x，获取初始值并加 1，这样 x 的值就变成 6 了。然后，在内部作用域内，第三个 let 语句也隐藏了 x，将之前的值乘以 2，x 得到的值是 12。当该作用域结束时，内部 shadowing 的作用域也结束了，x 又返回到 6。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:1","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"数据类型 标量类型 整型 长度 有符号 无符号 8-bit i8 u8 16-bit i16 u16 32-bit i32 u32 64-bit i64 u64 128-bit i128 u128 arch isize usize 浮点型 ​ Rust 的浮点数类型是 f32 和 f64，分别占 32 位和 64 位。默认类型是 f64 布尔型 ​ Rust 中的布尔类型有两个可能的值：true 和 false。Rust 中的布尔类型使用 bool 表示。 字符型 ​ Rust 的 char 类型的大小为四个字节(four bytes)，并代表了一个 Unicode 标量值（意味着你可以使用emoji）。 复合类型 元组类型 相当于把一个或者多个类型的值组合成一个类型。元组的长度是固定的：一旦声明。其长度不会改变。 我们可以使用圆括号中逗号分割的值列表来创建一个元组。 fn main() { let one: (i32, f64, u8) = (500, 6.4 ,1); let one = (500, 6.4 ,1); } 同时可以对元组进行解构，或者只用点号（.）跟着值的索引（从0开始）直接访问 fn main() { let one = (500, 6.4 ,1); let (x, y, z) = one; println(\"x:{} y:{} z:{}\",x, y, z); println(\"x:{} y:{} z:{}\",one.0, one.1, one.2); } 数组类型 另一个包含多个值的方式是 数组（array）。与元组不同，数组中的每个元素的类型必须相同。Rust 中的数组与一些其他语言中的数组不同，因为 Rust 中的数组是固定长度的：一旦声明，它们的长度不能增长或缩小。 可以使用以下两种方式来声明数组： fn main() { let a = [1, 2, 3, 4, 5]; // 当你想定义类型或者长度时可使用下面这种方式 // 在方括号中包含每个元素的类型，后跟分号，再后跟数组元素的数量 let a: [i64; 5] = [1, 2, 3, 4, 5]; } ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:2","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"函数 Rust 中的函数定义以 fn 开始并在函数名后跟一对圆括号。大括号告诉编译器哪里是函数体的开始和结尾。 在函数签名中，必须 声明每个参数的类型。这是 Rust 设计中一个经过慎重考虑的决定：要求在函数定义中提供类型注解，意味着编译器不需要你在代码的其他地方注明类型来指出你的意图。在有多个参数时，使用,来分割多个参数。 函数可以向调用它的代码返回值。使用（-\u003e）后声明它的类型。在 Rust 中，函数的返回值等同于函数体最后一个表达式的值。使用 return 关键字和指定值，可从函数中提前返回；但大部分函数隐式的返回最后的表达式。 fn five() -\u003e i32 { 5 } fn four() -\u003e i32 { let a = 4; return a; } fn main() { let x = five(); println!(\"The value of x is: {}\", x); } 语句和表达式 Rust是一门基于表达式（expression-based）的语言。 使用let关键字创建变量并绑定一个值是一个语句（let y = 6;）。 语句不返回值。不能把let语句赋值给另外一个变量（let x = (let y = 6)）。 表达式可以计算出一个值，考虑一个数学运算，比如5+6，这是一个表达式并计算出值11。表达式可以是语句的一部分。函数调用是一个表达式。宏调用是一个表达式。我们用来创建新作用于的大括号（代码块），{}，也是一个表达式。 fn main() { let x = 5; let y = { let x = 3; x + 1 } println!(\"x:{} y:{}\") } 这个表达式： { let x = 3; x + 1 } 是一个代码块，它的值是 4。这个值作为 let 语句的一部分被绑定到 y 上。注意结尾没有分号的那一行 x+1，与你见过的大部分代码行不同。表达式的结尾没有分号。如果在表达式的结尾加上分号，它就变成了语句，而语句不会返回值。在接下来探索具有返回值的函数和表达式时要谨记这一点。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:3","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"控制流 if表达式 if 表达式允许根据条件执行不同的代码分支。你提供一个条件并表示 “如果条件满足，运行这段代码；如果条件不满足，不运行这段代码。” fn main() { let number = 3; if number \u003c 5 { // xxx } else { // yyy } } 代码中的条件必须是bool值。如果不是bool值，我们会得到一个错误。 因为if是一个表达式，所以我们可以在let语句的右侧使用它。注意，if和else分支的结果都必须是相同类型 fn main() { let conditioin = true; let number = if condition { 5 } else { 6 }; println!(\"number:{}\", number); } ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:4","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"循环 Rust 中有三种循环：loop、while和for。 loop表达式 loop就是一个无限循环，需要显式的调用break来退出这个循环。 如果存在嵌套循环，此时单独只用break 和 continue只应用于此时语句最内层的循环。可以在循环上指定一个循环标签，然后将标签与break 和 continue一起使用，此时这些关键字生效的则是已标记的循环。 fn main() { let mut count = 0; 'counting_up: loop { let mut remaining = 10; loop { println!(\"remaining = {}\", remaining); if remaining == 9 { break; } if count == 2 { break 'counting_up; } remaining -= 1; } count += 1; } println!(\"End count = {}\", count); } loop的另外一个用法是重试可能会失败的操作，比如检查线程是否完成了任务。如果将返回值加入你用来停止循环的break表达式，它会被停止的循环返回。 fn main() { let mut counter = 0; let result = loop { counter += 1; if counter == 10 { break counter * 2; } }; println!(\"The result is {}\", result); } while条件循环 当条件为真，执行循环。当条件不再为真，则停止循环。这个循环类型可以通过组合 loop、if、else 和 break 来实现。或者直接使用while。 fn main() { let mut number = 3; while number != 0 { println!(\"{}!\", number); number = number - 1; } println!(\"LIFTOFF!!!\"); } for遍历集合 可以使用 for 循环来对一个集合的每个元素执行一些代码。 fn main() { let a = [10, 20, 30, 40, 50]; for element in a.iter() { println!(\"the value is: {}\", element); } } Rust的循环不像“C风格”的循环 for (x = 0; x \u003c 10; x++) { printf(\"%d\\n\", x); } 相反，Rust是这样的 for x in 0..10 { println!(\"{}\", x); } // 当你需要 x \u003c= 10 这种类型的时候 for x in 0..=10 { println!(\"{}\", x); } 当你需要知道当前已经循环多少次时，可以使用.enumerate()函数 for (i,j) in (5..10).enumerate() { println!(\"i = {} and j = {}\", i, j); } 输出： i = 0 and j = 5 i = 1 and j = 6 i = 2 and j = 7 i = 3 and j = 8 i = 4 and j = 9 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:5","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"所有权 首先，让我们看一下所有权的规则。当我们通过举例说明时，请谨记这些规则： Rust 中的每一个值都有一个被称为其 所有者（owner）的变量。 值在任一时刻有且只有一个所有者。 当所有者（变量）离开作用域，这个值将被丢弃。 变量作用域 变量 s 绑定到了一个字符串字面值，这个字符串值是硬编码进程序代码中的。这个变量从声明的点开始直到当前 作用域 结束时都是有效的。示例 4-1 的注释标明了变量 s 在何处是有效的。 { // s 在这里无效, 它尚未声明 let s = \"hello\"; // 从此处起，s 是有效的 // 使用 s } // 此作用域已结束，s 不再有效 内存与分配 首先我们要知道变量的两种内存分配位置：堆和栈。这个概念再此不做赘述。 当我们声明一个变量的类型，它的内存分配在堆上，我这习惯将其成为引用类型，如果它的内存分配在栈上，则称为值类型。 值类型，如i32、f64。引用类型，如string： fn main() { let x = 1;// i32 值类型 let str = String::from(\"hello world!\");// string 引用类型 } 值类型的传递方式都是copy fn main() { let x = 1; let y = x; } 此时 x、y都在栈上拥有属于自己的内存空间。 而引用类型的传递方式则不一样。 fn main() { let x = String::from(\"hello world!\");// x 获得 string 的所有权 let y = x;// string 的所有权交给了 y // 此时 x 与 y 的地址共同指向堆的同一个地方 // 我们只拷贝了其长度和容量信息，其在堆上的指针是相同的 // 如果想拷贝其在堆上的数据 let z = y.clone();// z clone 了一个 y，没有获得 string 的所有权 // 此时则是 z 与 y 是地址完全不同的两个变量 // 如果我们在这使用 let z = x.clone() 则对得到一个错误，因为Rust禁止你使用无效的引用 } 那如果是在函数里呢？ fn main() { let str = String::from(\"hello world!\");// str 进入作用域 test_one(str);// str 所有权移动到函数内 // str再此不在有效 let x = 12;// x 进入作用域 test_two(x);// x copy 进入函数内 // x 是copy的,所以 x 在此依然有效 }// x移除作用域。 str 所有权已经移交，不做操作 fn test_one(some_string: String) {// some_string 进入作用域 println!(\"{}\", some_string); }// some_string 离开作用域，调用 `drop` 方法释放内存 fn test_two(some_integer: i32) {// some_integer 进入作用域 println!(\"{}\", some_integer); }// some_integer 离开作用域，不会有特殊操作 函数的返回值也可以转移所有权。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:6","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"引用与借用 规则 在任意给定时间，要么 只能有一个可变引用，要么 只能有多个不可变引用。 引用必须总是有效的。 如果我们只是想使用一个变量，而不是获取这个变量的所有权。我们则需要使用引用这个操作。 fn main() { let s1 = String::from(\"hello\"); let len = calculate_length(\u0026s1); println!(\"The length of '{}' is {}.\", s1, len); } fn calculate_length(s: \u0026String) -\u003e usize { s.len() } 我们在这里获得的是s1的引用，并没有获取s1的所有权。所以上述代码可以正常的运行。 使用的\u0026符号就是引用，它允许你使用值但不获取其所有权。就像其他语言类似，获取一个变量的地址，也就是指针。 因为没有获取到所有权，所以当引用离开作用域时，不会将内存释放。但是这里的引用只能使用被引用的变量，当我们想修改这个变量时，则会发现会抛出一个错误。正如变量默认不可变一样，引用默认也是不可改变的。 fn main() { let s = String::from(\"hello\"); change(\u0026s); } fn change(some_string: \u0026String) { some_string.push_str(\", world\"); } error[E0596]: cannot borrow immutable borrowed content `*some_string` as mutable --\u003e error.rs:8:5 | 7 | fn change(some_string: \u0026String) { | ------- use `\u0026mut String` here to make mutable 8 | some_string.push_str(\", world\"); | ^^^^^^^^^^^ cannot borrow as mutable 如果我们想修改一个引用的值，我们只需做一个小调整： fn main() { let mut s = String::from(\"hello\"); change(\u0026mut s); } fn change(some_string: \u0026mut String) { some_string.push_str(\", world\"); } 这里使用\u0026mut获取到的是 s的可变引用，这就清除的表明，我需要修改这个引用的值。不过可变引用有一个很大的限制。 在同一时间只能有一个对某一特定数据的可变引用 这个限制的好处是 Rust 可以在编译时就避免数据竞争。 不可变引用可以存在多个，但不能同时与可变引用存在。原因也很明显，谁也不想自己引用的变量在某一时间被修改。 这种概念和读写锁类似。可以拥有多个读锁（不可变引用），只能存在一个写锁并与读锁互斥（可变引用）。当了解这个概念之后就很好理解了。 注意一个引用的作用域从声明的地方开始一直持续到最后一次使用为止。例如以下代码是可以编译的： let mut s = String::from(\"hello\"); let r1 = \u0026s; // 没问题 let r2 = \u0026s; // 没问题 println!(\"{} and {}\", r1, r2); // 此位置之后 r1 和 r2 不再使用，作用域也再此结束 let r3 = \u0026mut s; // 没问题 r1，r2的作用域已经结束 println!(\"{}\", r3); 不可变引用 r1 和 r2 的作用域在 println! 最后一次使用之后结束，这也是创建可变引用 r3 的地方。它们的作用域没有重叠，所以代码是可以编译的。编译器在作用域结束之前判断不再使用的引用的能力被称为非词法作用域生命周期（Non-Lexical Lifetimes，简称NLL）。你可以在 The Edition Guide 中阅读更多关于它的信息。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:7","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"结构体 定义结构体，需要使用 struct 关键字并为整个结构体提供一个名字。结构体的名字需要描述它所组合的数据的意义。接着，在大括号中，定义每一部分数据的名字和类型，我们称为 字段（field）。例如，示例 5-1 展示了一个存储用户账号信息的结构体： struct User { username: String, email: String, sign_in_count: u64, active: bool, } 当变量名与字段名相同时，可以简写 fn build_user(email: String, username: String) -\u003e User { User { email, username, active: true, sign_in_count: 1, } } 我们还可以使用结构体更新语法 let user2 = User { email: String::from(\"another@example.com\"), ..user1 }; 在这里..user1必须放在最后，其他字段实际是使用=的赋值，所以要注意所有权的移动。 我们还可以创建没有字段的元组结构体，使用.接上索引来访问单独的值。 struct Color(i32, i32, i32); struct Point(i32, i32, i32); let black = Color(0, 0, 0); let origin = Point(0, 0, 0); 或者创建一个没有任何字段的结构体（类单元结构体） 单元结构体常常在你想要在某个类型上实现 trait 但不需要在类型中存储数据的时候发挥作用。 struct AlwaysEqual; let subject = AlwaysEqual; todo 字段的生命周期 打印结构体 #[derive(Debug)] struct Rectangle { width: u32, height: u32, } fn main() { let rect1 = Rectangle { width: 30, height: 50 }; println!(\"{:#?}\", rect1); println!(\"{:#?}\", rect1); dbg!(\u0026rect1); } 分别输出： Rectangle { width: 30, height: 30, } Rectangle { width: 30, height: 30, } [src/main.rs:15] \u0026rect1 = Rectangle { width: 30, height: 30, } 给struct绑定方法 定义方法 #[derive(Debug)] struct Rectangle { width: u32, height: u32, } impl Rectangle { fn area(\u0026self) -\u003e u32 { self.width * self.height } } fn main() { let rect1 = Rectangle { width: 30, height: 30, }; println!(\"这个长方体的面积是：{}\", rect1.area()); } 为了使函数定义在Rectangle的上下文中，我们定义了一个impl块。在这个块中的所有内容都与Rectangle相关联。 在area的函数前面上，使用\u0026self来代替rectangle: \u0026Rectangle，\u0026self其实是self: \u0026Self的缩写。在一个impl块中，方法的第一个参数必须有一个名为self的Self类型的参数，所以Rust在这里提供了self这个名字来缩写，在这里我们使用\u0026来表示只是借用这个示例，并没有获取所有权。同时，我们也一样可以获取所有权，或者可变借用。 那我们的\u0026运算符去哪里了呢？ area()函数的参数是\u0026self，但是我们调用的地方并没有借用rect1；那是Rust有一个叫做自动引用和解引用的功能。方法调用是Rust中少数几个拥有这种行为的地方。 这样我们的代码实际是这样工作的： rect1.area(); (\u0026rect1).area(); 这样看起来第一种方式简洁的多。 关联函数 所有在impl块中定义的函数被称为关联函数。我们可以定义一个不以self为第一参数的关联函数（它不是方法），我们已经使用过这样的函数了，String::from()。通常这样的函数被我们用作为返回一个结构体新实例的构造函数。 impl Rectangle { fn square(size: u32) -\u003e Rectangle { Rectangle { width: size, height: size } } } fn main() { let sq = Rectangle::square(3); } ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:8","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"枚举 在 Rust 中我们使用enum来定义一个枚举类型。 enum IpAddrKind { V4, V6, } 在上述代码中定义了一个IpAddrKind枚举来列出可能的 IP 地址类型，V4和V6。这两种类型被称为枚举的成员。 我们可以像这样创建IpAddrKind两个不同成员的实例。 let four = IpAddrKind::V4; let six = IpAddrKind::V6; fn route(ip_type: IpAddrKind) {} route(four); route(six); 可以看到我们可以使用任意成员来调用route函数。 枚举的成员也可以关联一个值。 enum IpAddr { V4(String), V6(String), } let home = IpAddr::V4(String::from(\"127.0.0.1\")); let loopback = IpAddr::V4(String::from(\"::1\")); 或者关联上一个元组。 enum IpAddr { V4(u8, u8, u8, u8), V6(String), } let home = IpAddr::V4(127, 0, 0, 1); let loopback = IpAddr::V4(String::from(\"::1\")); 我们还可以对枚举类型关联上方法。 impl IpAddr { fn call(\u0026self) { dbg!(self) } } 我们就可以直接使用home.call()来调用这个方法。 todo option ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:9","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"相关控制流运算符 match运算符 如果有其他语言基础的话，看到match这个关键字，应该能联想到switch。它的用法和switch是差不多的，只是有一些细节不同。这里我们用上面的IpAddr绑定的方法call举例： fn call(\u0026self) { match self { IpAddr::V4(a, b, c, d) =\u003e println!(\"{}:{}:{}:{}\", a, b, c, d), IpAddr::V6(str) =\u003e println!(\"{}\", str), } } 可以看到，我们使用了match匹配了self这个变量，在 case 里我们用上了IpAddr::V4(a, b, c, d)，使用了a b c d四个变量来分别匹配绑定上的V4(u8, u8, u8, u8)4个值。而在IpAddr::V6(str)使用了str来接收绑定的String这样我们就可以根据不同的类型在做出不同的操作了。 但是注意 Rust 默认需要我们处理match后变量的所有可能情况，也就是说，下述代码是不正确的： fn call(\u0026self) { match self { IpAddr::V4(a, b, c, d) =\u003e println!(\"{}:{}:{}:{}\", a, b, c, d), } } Rust 会提示我们少了IpAddr::V6的case。 上述例子只有2种情况，那如果是10种？20种呢？如果真的全部都要列出来的话，那未免太蠢了。所以 Rust 和其他语言一样，提供了类似default的功能，使用的关键字是_，我们来看看例子。 fn call(\u0026self) { match self { IpAddr::V4(a, b, c, d) =\u003e println!(\"{}:{}:{}:{}\", a, b, c, d), _ =\u003e (), } } 注意必须要显式调用_ =\u003e () Rust不会默认给你加上。这样的话就可以忽略掉V6的匹配了。 if let简单控制流 想上面的例子，只有2种情况，我们还需要显式的用_去忽略匹配，实在是过于冗长，所以 Rust给了我们另外一种方式来处理这种情况。 fn call(\u0026self) { if let IpAddr::V4(a, b, c, d) = self { println!(\"{}:{}:{}:{}\", a, b, c, d); } } 这样我们就不用再用那么冗长的方式来编写了。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:10","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"package / crate / module cargo new会生成项目的雏形，提供了 src/main.rshe src/lib.rs文件，随着项目复杂度的增长，代码量也会随之增长，如果靠一个文件来维护一大堆代码，肯定是不合适的。一般都会使用模块来拆分文件。 在这里学习一下rust中代码的组织方式，主要涉及到一下几个名词： package：Cargo中的概念，用于管理crate crate：模块的集合，编译单位，有bin和lib两种，分别是可执行文件，和供他人调用 module：用户在crate内组织代码 workspace：项目复杂时，管理多个package package 使用cargo new命令会创建一个新项目，也就是一个package，里面带有一个Cargo.toml文件，用于定义package、所需外部依赖，以及如何编译crate等 crate Rust里有两种crate，lib类型和bin类型，并且默认以文件名为标准处理crate: src/main.rs：表示该crate时一个bin类型大crate src/lib.rs：表示该crate时一个lib类型的crate 并且，一个package中的crate还有如下与约束： 可以有多个bin类型的crate 只能有0个或者1个lib类型的crate 以上两条约束并不互斥，也就是说一个项目下可以有一个lib和多个bin类型的crate，也就是可以编译出多个可执行文件 只是如果有多个bin类型的crate，一个src/main.rs就不够了，需要放到src/bin下，每个crate一个文件 mod 当项目逐渐膨胀后，可以对代码以mod「文件/文件夹」为单位进行拆分，而不是把所有代码都写在src/main.rs或者src/lib.rs里 以lib类型的crate为例，该类型的crate入口在src/lib.rs，也就是crate的根。定义一个模块也很简单 // src/lib.rs mod testMod { fn test() { println!(\"test\") } } 而在实际项目中，我们不会只有一个lib.rs文件，而是会将代码按功能进行拆分成多个模块 模块拆分 一般来说，一个文件都会被看作为一个mod，并且mod可以嵌套定义。嵌套定义的mod可以卸载一个文件里，也可以通过文件夹的形式来实现。具体的我们来看几个例子。 假设当前项目文件结构如下: src ├── lib.rs ├── mod_a │ ├── mod.rs │ └── mod_b.rs └── mod_c.rs 在这里定义了3个mod：mod_a、mod_b 和 mod_c，其中mod_a为文件夹形式，而mod_b和mod_c都有对应的文件。其中mod_b是mod_a的子模块。 我们来看下各个模块之间如何声明和引用。 首先我们先来看看crate的根，也就是lib.rs pub mod mod_a; mod mod_c; 在这里声明了两个mod，如果需要在crate外部访问，需要在mod前面加上pub关键字。注意这里不需要声明mod_a的子模块mod_b,这个需要mod_a来声明。 再来看一下这两个mod。先看mod_a，这是一个文件夹形式存在的mod，按cargo规定，这时候需要在该文件夹下有一个名为mod.rs的文件定义该mod下的内容。该文件内容如下： // src/mod_a/mod.rs pub mod mod_b; 可以看到，这个文件和lib.rs类似，都可以声明mod。但该文件声明的mod可以保存到mod.rs： // src/mod_a/mod_b.rs use super::super::mod_c; pub fn test() { println!(\"i'm mod_b\") } fn call_mod_c() { mod_c::test(); } 我们再来看看mod_c.rs的代码： // src/mod_c.rs use crate::mod_a::mod_b; pub fn test() { mod_b::test(); println!(\"i'm mod_c\"); } 除了如何定义mod，我们还需要的是如何引用其他mod的定义。在mod_c中，要想使用mod_b，可以使用： 绝对路径use crate::mod_a::mod_b 而在mod_b中使用mod_c的时候，使用了use super::super::mod_c这种相对路径的形式。 添加main.rs 最后在上面代码的基础上添加main.rs，看看作为外部crate如何使用上面的mod_a // src/main.rs use testlib::mod_a::mod_b; fn main() { println!(\"main\") mod_b::test(); } 在这里需要注意的是，引用自己lib的方法不能使用上面说的绝对路径或者相对路径这两种引用方式，必须使用该crate的名称「也就是Cargo.toml里的名称」来应用。因为main和lib属于不同的crate pub 修饰符 要想访问其他mod中的结构体、方法、枚举等，需要对方声明为pub。如果是想操作结构体中的字段，可以有一下两种方法 提供对应的pub方法 直接修改字段为pub use 语句 讲了这么做如何定义mod，我们来看下如何使用 在crate和模块中我们可能定义了函数、结构体等，要想在其他模块或者crate中使用，需要将其引入到当前文件中，类似php的use，或者java中的import，在Rust中我们需要使用use 如何表示要被引用的对象，Rust里称之为path，我们可以理解为操作系统中的文件目录 path有两种形式，也和文件系统一样，有绝对路径和相对路径： 绝对路径始于crate的根（src/main.rs or src/lib.rs），可以使用crate名或者crate这个字面值表示 相对路径可以使用当前模块名，当前模块中可以使用的对象，super和self等 path中的层级使用两个冒号::，类似文件系统中的斜线. 假设有一下代码（来自官方文档）： mod front_of_house { pub mod hosting { pub fn add_to_waitlist() {} } } pub fn eat_at_restautant() { // 绝对路径 crate::front_of_house::hosting::add_to_waitlist(); // 相对路径 front_of_house::hosting::add_to_waitlist(); } 有一些限制也需要知道： 在夫模块中不能使用子模块中的私有项目 子模块可以使用父模块中的所有项目 同一模块内可以直接互相使用 下面是一个使用了super的例子： fn server_order() {} mod back_of_house() { fn fix_incorrect_order() { cook_order(); super::server_order(); } fn cook_order() {} } fix_incorrect_order方法和cook_order同属于一个模块，可以直接调用。server_order方法和back_of_house同级，因此需要使用super访问到同级的server_order方法 如果use后面的路径具有共同的父路径，可以使用简化的模式。比如： use std::io; use std::cmp::Ordering; 可以简化为： use std::{cmp::Ordering, io}; 如果use的mod直接有父子关系，也可以像上面那样简化，使用self代表父mod。比如： use std::io; use std::io::Write; 可以简化为： use std::io::{self, Write}; 如果想将某一路径下的所有pub的item都引入到当前文件中，可以使用* use std::collections::*; 一般会在单元测试中常用，不推荐在业务代码中使用 #[cfg(test)] mod tests{ use super::*; #[test] fn it_works() {} } 引用层级 对比一下两种引用方式: // case 1 use crate::front_of_house::hosting; hosting::add_to_waitlist(); // case 2 use crate::front_of_house::hosting::add_to_waitlist; add_to_waitlist(); 这两种方法的结果都是一样的，但是阅读起来给人的感觉不一样。一般来说推荐第一个 case ，这样能明确的知道使用的方法是外部 hosting 模块的方法，后者的话不知道是 use 进来的，还是本模块定义的 重命名 有时候从不同的 crate 或者 mod 引入了同名的 item，这个时候最简单的方式是使用as关键字进行重命名。 use std::fmt; use std::io; fn function1() -\u003e fmt::Result {} fn function2() -\u003e io::Result\u003c()\u003e {} ########################### use std::fmt::Result; use std::io::Result as IoResult; fn function1","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:11","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"常见集合 一般来说在 Rust 常用的集合 vector允许我们一个挨着一个地存储一系列数量可变的值 字符串是字符的集合，String 哈希 map 允许我们将值与一个特定的键相关联 vector 新建vector let v: Vec\u003ci32\u003e = Vec::new(); let v = vec![1, 2, 3]; 更新vector let mut v = Vec::new(); v.push(1); v.push(2); let a = v.pop(); 类似于其他任何的struct，vector 在离开其作用域时会被释放。 访问vector let v = vec![1, 2, 3]; let v1 = \u0026v[1]; // 索引语法 let v2 = v.get(2); // 方法 使用索引语法访问vector会导致程序panic，而使用 get 方法访问时 会返回一个 None 在拿到 vector 中任意一个有效的引用，借用检查器将会窒息所有权和借用规则，来确保 vector 内容的这个引用和任何其他引用保持有效。当我们获取到了 vector 的第一个元素的不可变引用并在 vector 末尾增加一个元素的时候，编译无法通过。 let mut v = vec![1, 2, 3, 4, 5]; let first = \u0026v[0]; v.push(6); // 不通过编译 println!(\"The first element is: {}\", first); 为什么第一元素的引用会关心到末尾的变化？那是因为 vector 和 golang 的 slice 一样，在内部的空间不足时，会进行拷贝扩容，这样第一个元素的引用就指向了被释放的内存。 遍历 vector let mut v = vec![1, 2, 3]; for i in \u0026v { println!(\"{}\", i) } for i in \u0026mut v { *i += 50; } 同时 vector 也可以使用枚举来存储多种类型的值 enum Test { Int(i32), Text(String), } let row = vec![ Test::Int(3), Test::Text(String::from(\"test\")) ]; 字符串 创建一个字符串 let s1 = String::new(); // 创建一个空字符串 // 使用初始数据创建字符串 let s2 = \"test\".to_string(); let s3 = String::from(\"test\"); 更新字符串 let mut s = String::from(\"foo\"); let mut x = String::from(\" bar\"); s.push_str(x); s.push('~'); println!(\"x is {}\", x); let s1 = String::from(\"Hello, \"); let s2 = String::from(\"world!\"); let s3 = s1 + \u0026s2; // 这里 s1 被移动了，不能继续使用 执行上述代码之后，s将会包含x，x还可以继续使用，因为push_str方法使用了字符串 slice，因此我们不需要获取参数的所有权。 然而直接使用+运算符将两个String值合并到一个新String值中，此时s1在相加后失去了所有权。因为+调用了add函数，这个函数看起来像这样 fn add(self, s: \u0026str) -\u003e String{} 这并不是标准库当中实际的签名，标准库中的add使用泛型定义。 那为什么add方法的第二个参数是\u0026str，我们在调用时却是\u0026String，并且可以通过编译。 那是因为 Rust 使用了一个被称为 Deref 强制转换 的技术，可以理解为把\u0026s2变成了\u0026s2[..] 并且在签名中add方法获取self的所有权，这意味着s1的所有权将被移动到add调用中，之后不在生效，这样的好处是不会生成很多拷贝，这个实现比拷贝更加高效。 如果想获取多个字符相加： let s1 = String::from(\"hello\"); let s2 = String::from(\" \"); let s3 = String::from(\"world\"); let s = format!(\"{}{}{}\", s1, s2, s3); 上述代码会将s设置为hello world。format!与println!的工作原理相同，并且它使用索引不会获取任何参数的所有权。 索引字符串 在很多语言中，通过索引来一用字符串中的单独字符是很常见的操作，比如说 golang。然而在 Rust 中，不允许使用索引语法访问String的一部分，会出现错误。 let s = String::from(\"hello\"); let h = s[0]; // error 原因则是在 Rust 中，String是一个Vec\u003cu8\u003e的封装，相当于在底层存储的是字节，和大多数编程语言一样。直接使用索引语法获取String的一部分，相当于获取UTF-8字符的一个字节，这样可能会返回意外的值，Rust 根本不会编译这些代码。 在Golong中可以直接索引访问，那是因为Golang会默认把字符串按照rune来 遍历。 在 Rust 中也有这样的操作，只不过需要显示使用： for c in \"hello world\".chars() { println!(\"{}\", c); } 这样可以获取到每个UTF-8编码的字符，也就相当于 Golang 中的rune。 fn main() { let s = String::from(\"你好世界👋\"); let c = s.chars().nth(10000); match c { Some(tmp) =\u003e println!(\"{}\",tmp), None =\u003e ( println!(\"this index is none\") ), } } 上述代码可以安全的使用索引来获取单个字符。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:12","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"Hash Map 新建 可以使用new来创建一个空的HashMap，并使用insert增加元素。 use std::collections::HashMap; let mut map = HashMap::new(); map.insert(String::from(\"hello\"), String::form(\"world\")); 注意，使用HashMap需要引入 访问 可以 使用get方法传入对应的键，从HashMap中获取值 let name = String::from(\"hello\"); let s = map.get(\u0026name); // s : Option\u003cV\u003e 或者使用与 vector 类似的方式来遍历 for (key, value) in \u0026map { println!(\"{}: {}\", key, value); } 更新 直接使用相同的键重新调用insert方法，这样会直接替换成新值。 当我们需要检查对应键是否存在值时，可以使用entry方法 map.insert(String::from(\"Ronin\")); let s = map.entry(String::from(\"hello\")).or_insert(\"世界\"); *s = farmat!(\"{}\", s, String::from(\"~\")); 并且or_insert方法返回这个值的可变引用\u0026mut V，我们可以直接改变它。 所有权 对于类似i32这样实现了Copy trait 的类型，值可以直接拷贝进HashMap。对于拥有所有权的值，其值将被移动而HashMap会成为这些值的所有者。或者将值的引用传入HashMap，但是需要保证生命周期，后续会了解。 ","date":"2021-11-22","objectID":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/:2:13","tags":["Rust"],"title":"Rust官方文档学习记录","uri":"/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"},{"categories":null,"content":"今年嫖了一波良心云的服务器（2c4g8m），打算把 github page迁移到自己的服务器上。 又不想每次都 ssh 上服务器去拉取，也不想 ftp 去上传文件（公司安全要求）。所以想通过webhooks通知，让服务器自动的去更新博客。具体实现希望通过 docker 来解决，这样可以通用，下次迁移服务的时候可以直接拿个 docker-compose 文件就迁移完成了。毕竟良心云续费可不良心。 说干就干。 首先，我们需要一个能接收到请求的东西，任意方式都行，我这里使用的是 golang 。 build镜像需要以下目录结构，也可以自行调整。 . ├── Dockerfile ├── src │ ├── cmd │ │ ├── main.go │ │ └── sync.sh │ ├── go.mod │ └── go.sum └── ssh ├── id_rsa ├── id_rsa.pub └── known_hosts main.go package main import ( \"fmt\" \"net/http\" \"os/exec\" \"github.com/go-playground/webhooks/v6/github\" ) const ( path = \"/webhooks\" // 可以自行修改 ) func main() { hook, err := github.New(github.Options.Secret(\"你自己设置的秘钥\")) if err != nil { panic(err) } http.HandleFunc(path, func(w http.ResponseWriter, r *http.Request) { cmd := exec.Command(\"/bin/sh\", \"./cmd/sync.sh\") out, err := cmd.Output() if err != nil { fmt.Println(err) } fmt.Println(out) payload, err := hook.Parse(r, github.ReleaseEvent, github.PushEvent) if err != nil { if err == github.ErrEventNotFound { fmt.Println(err) } } switch payload.(type) { case github.PushPayload: fmt.Println(\"received push event\") exec.Command(\"/bin/sh\", \"./cmd/sync.sh\").Run() default: fmt.Println(payload) } }) http.ListenAndServe(\":8888\", nil) } 接收到请求并校验通过之后，会执行 sync.sh 脚本。里面的内容可以根据自己需要进行修改 sync.sh #!/bin/bash cd /data/www echo $(pwd) echo $(git pull) 运行的服务现在准备好了，得准备运行的环境 因为是个小功能所以使用的镜像也希望轻量一些，选用的是 golang:alpine镜像 如果需要其他功能也可以自行修改 Dockerfile FROM golang:alpine # 设置 go mod 代理 ENV GOPROXY=https://goproxy.cn,direct # 替换apk镜像源 RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.tuna.tsinghua.edu.cn/g' /etc/apk/repositories # 设置ssh pub key COPY ./ssh /root/.ssh RUN chmod -R 600 /root/.ssh # 设置工作目录 WORKDIR /tmp/src # 复制代码 COPY ./src /tmp/src RUN apk update RUN apk add git \u0026\u0026 apk add openssh RUN go mod tidy RUN go build -o bin/hugo cmd/main.go ENTRYPOINT [\"./bin/hugo\"] CMD [\"-logtostderr\"] 可以看到这里需要ssh信息，自行添加文件即可。 这里也直接给出 docker-compose 文件 hugo: container_name: hugo build: ./services/go-hugo/ volumes: - {你需要同步的git目录}:/data/www:rw # 资源目录 links: - nginx # 如果你不需要nginx做转发，可以去除这里 nginx: container_name: nginx build: context: ./services/nginx args: NGINX_VERSION: 1.21.3-alpine CONTAINER_PACKAGE_URL: mirrors.aliyun.com ports: - \"80:80\" - \"443:443\" volumes: - {你的资源目录}:/www/:rw - {你的https目录}:/ssl:rw - {你的配置文件目录}:/etc/nginx/conf.d/:rw - {你的根配置文件}:/etc/nginx/nginx.conf:ro - {nginx日志目录}:/var/log/nginx/:rw environment: TZ: \"Asia/Shanghai\" restart: always networks: - default 可以直接把端口暴露出公网，也可以使用nginx做一层转发，可以提高安全性不暴露端口 nginx的Dockerfile ARG NGINX_VERSION FROM nginx:${NGINX_VERSION} ARG TZ ARG NGINX_VERSION ARG CONTAINER_PACKAGE_URL ARG NGINX_INSTALL_APPS ENV INSTALL_APPS=\",${NGINX_INSTALL_APPS},\" RUN if [ \"${CONTAINER_PACKAGE_URL}\" != \"\" ]; then \\ sed -i \"s/dl-cdn.alpinelinux.org/${CONTAINER_PACKAGE_URL}/g\" /etc/apk/repositories; \\ fi RUN if [ -z \"${INSTALL_APPS##*,certbot,*}\" ]; then \\ echo \"---------- Install certbot ----------\"; \\ apk add --no-cache certbot; \\ fi WORKDIR /www nginx配置文件 server { listen 80; server_name 你的域名; return 301 https://$server_name$request_uri; } server { listen 443 ssl; server_name 你的域名; # server_name localhost; root {根地址}; # ssl证书地址 ssl_certificate /ssl/xxx.pem; # pem文件的路径 ssl_certificate_key /ssl/xxx.key; # key文件的路径 location /webhook { proxy_pass http://hugo:8888; # HTTP 代理转发port。这里因为使用了已命名为 hugo 的 docker 容器，所以可以在nginx配置中直接使用。 proxy_set_header Host localhost; # 不要忘记这句 Host $host proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto https; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location / { index index.html; } } 配置都完成后，直接使用 docker-compose up -d 启动容器。在github上设置webhooks的部分就不再此赘述。 ","date":"2021-11-08","objectID":"/webhooks%E5%AE%9E%E7%8E%B0%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/:0:0","tags":["Webhooks","docker"],"title":"Webhooks实现博客自动更新","uri":"/webhooks%E5%AE%9E%E7%8E%B0%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/"},{"categories":null,"content":"题目 请你仅使用两个栈实现先入先出队列。队列应当支持一般队列的支持的所有操作（push、pop、peek、empty）： 实现 MyQueue 类： void push(int x) 将元素 x 推到队列的末尾 int pop() 从队列的开头移除并返回元素 int peek() 返回队列开头的元素 boolean empty() 如果队列为空，返回 true ；否则，返回 false 说明： 你只能使用标准的栈操作 —— 也就是只有 push to top, peek/pop from top, size, 和 is empty 操作是合法的。 你所使用的语言也许不支持栈。你可以使用 list 或者 deque（双端队列）来模拟一个栈，只要是标准的栈操作即可。 进阶： 你能否实现每个操作均摊时间复杂度为 O(1) 的队列？换句话说，执行 n 个操作的总时间复杂度为 O(n) ，即使其中一个操作可能花费较长时间。 示例： 输入： [\"MyQueue\", \"push\", \"push\", \"peek\", \"pop\", \"empty\"] [[], [1], [2], [], [], []] 输出： [null, null, null, 1, 1, false] 解释： MyQueue myQueue = new MyQueue(); myQueue.push(1); // queue is: [1] myQueue.push(2); // queue is: [1, 2] (leftmost is front of the queue) myQueue.peek(); // return 1 myQueue.pop(); // return 1, queue is [2] myQueue.empty(); // return false 提示： 1 \u003c= x \u003c= 9 最多调用 100 次 push、pop、peek 和 empty 假设所有操作都是有效的 （例如，一个空的队列不会调用 pop 或者 peek 操作） 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/implement-queue-using-stacks 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 ","date":"2021-03-05","objectID":"/leetcode-232%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/:0:1","tags":["LeetCode"],"title":"LeetCode 232:用栈实现队列","uri":"/leetcode-232%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/"},{"categories":null,"content":"思路 这题比较简单，主要是实现队列的基本功能，即先进先出。而我们知道栈是先进后出的，这就需要我们额外的操作了。 题目提示的比较明显，使用两个栈来实现。我们可以做出如下模型： 两个栈分别为输入栈和输出栈 输入栈负责接收 push 的内容 输出栈负责 pop 和 peek 的内容 当执行 pop 或者 peek 时，当输出栈为空时，将输入栈的内容输出到输入栈中 in : [] out: [] --push(1) in : [1] out: [] --push(2) in : [2,1] out: [] --peek in : [] out: [1,2] peek = 1 --pop in : [] out: [2] pop = 1 --isEmpty isEmpty(in) \u0026\u0026 isEmpty(out) ","date":"2021-03-05","objectID":"/leetcode-232%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/:0:2","tags":["LeetCode"],"title":"LeetCode 232:用栈实现队列","uri":"/leetcode-232%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/"},{"categories":null,"content":"代码 // MyQueue 队列 type MyQueue struct { in Stack out Stack } // Constructor MyQueue构造方法 func Constructor() MyQueue { in := new(Stack) out := new(Stack) return MyQueue{ in: *in, out: *out, } } func (mq *MyQueue) in2out() { for len(mq.in) \u003e 0 { mq.out.Push(mq.in.Pop()) } } // Push Push func (mq *MyQueue) Push(x int) { mq.in.Push(x) } // Pop Pop func (mq *MyQueue) Pop() int { if mq.out.Len() == 0 { mq.in2out() } return mq.out.Pop() } // Peek Peek func (mq *MyQueue) Peek() int { if mq.out.Len() == 0 { mq.in2out() } return mq.out.Top() } // Empty Empty func (mq *MyQueue) Empty() bool { return mq.in.IsEmpty() \u0026\u0026 mq.out.IsEmpty() } // ------------------------------------------------------- // Stack 栈 type Stack []int // Len 获取栈的长度 func (stack *Stack) Len() int { return len(*stack) } // Push push func (stack *Stack) Push(value int) { *stack = append(*stack, value) } // Top 获取栈的第一个 func (stack *Stack) Top() int { return (*stack)[len(*stack)-1] } // Pop 弹出最后一个 func (stack *Stack) Pop() int { value := (*stack)[len(*stack)-1] *stack = (*stack)[:len(*stack)-1] return value } // IsEmpty 判断是否为空 func (stack *Stack) IsEmpty() bool { return len(*stack) == 0 } ","date":"2021-03-05","objectID":"/leetcode-232%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/:0:3","tags":["LeetCode"],"title":"LeetCode 232:用栈实现队列","uri":"/leetcode-232%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/"},{"categories":null,"content":"题目 给定一些标记了宽度和高度的信封，宽度和高度以整数对形式 (w, h) 出现。当另一个信封的宽度和高度都比这个信封大的时候，这个信封就可以放进另一个信封里，如同俄罗斯套娃一样。 请计算最多能有多少个信封能组成一组“俄罗斯套娃”信封（即可以把一个信封放到另一个信封里面）。 说明: 不允许旋转信封。 示例: 输入: envelopes = [[5,4],[6,4],[6,7],[2,3]] 输出: 3 解释: 最多信封的个数为 3, 组合为: [2,3] =\u003e [5,4] =\u003e [6,7]。 ","date":"2021-03-05","objectID":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/:0:1","tags":["LeetCode"],"title":"LeetCode 354:俄罗斯信封套娃问题","uri":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"思路 来源：labuladong 这道题目其实是最长递增子序列 (Longes Increasing Subsequence, 简写为 LIS) 的一个变种，因为很显然，每次合法的嵌套都是大的套小的，相当于找一个最长递增的子序列，其长度就是最多能嵌套的信封个数。 但是难点在于，标准的LIS算法只能在数组中寻找最长子序列，而我们的信封是由[w, h]这样的二维数对形式表示的，如何把LIS算法运用过来呢？ w * h计算面积的形式是行不通的，1 * 10 大于 3 * 3，但是明显这样的两个信封是无法相互嵌套的。 ","date":"2021-03-05","objectID":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/:0:2","tags":["LeetCode"],"title":"LeetCode 354:俄罗斯信封套娃问题","uri":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"解法 这道题的解法是比较巧妙的： 先对宽度 w 进行升序排列，如果遇到 w 相同的情况，则按照高度 h 降序排列。之后把所有的 h 取出，填入一个数组，在这个数组上计算 LIS 的长度就是我们的答案。 示例： | 宽度w 高度h | [ 1 , 8 ] | [ 2 , 3 ] | [ 5 , 4 ]|降 | [ 5 , 2 ]|序 | [ 6 , 7 ]|降 | [ 6 , 4 ]|序 升 序 很明显，高度 h 组成的数组中 3 -\u003e 4 -\u003e 7 ，就是我们要找的LIS，其最大长度为3 这个解法的关键在于，对于宽度 w 相同的数对，要对其高度 h 进行降序排序。因为两个宽度相同的信封不能相互包含的，逆序排序保证 w 相同的数对中最多只选取一个。 ","date":"2021-03-05","objectID":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/:0:3","tags":["LeetCode"],"title":"LeetCode 354:俄罗斯信封套娃问题","uri":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"代码 func maxEnvelopes(envelopes [][]int) int { count := len(envelopes) // 快速排序 sort.Slice(envelopes, func(i, j int) bool { if envelopes[i][0] == envelopes[j][0] { return envelopes[i][1] \u003e envelopes[j][1] } return envelopes[i][0] \u003c envelopes[j][0] }) // 取出h height := make([]int, count) for i := 0; i \u003c count; i++ { height[i] = envelopes[i][1] } // 计算LIS return lengthOfLIS(height) } // LIS 计算 func lengthOfLIS(nums []int) int { piles, count := 0, len(nums) top := make([]int, count) for i := 0; i \u003c count; i++ { num := nums[i] left, right := 0, piles for left \u003c right { mid := (left + right) / 2 if top[mid] \u003e= num { right = mid } else { left = mid + 1 } } if left == piles { piles++ } top[left] = num } return piles } ","date":"2021-03-05","objectID":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/:0:4","tags":["LeetCode"],"title":"LeetCode 354:俄罗斯信封套娃问题","uri":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"wiki 最长递增子序列扩展到二维而已 动态规划设计方法\u0026\u0026纸牌游戏讲解二分解法 ","date":"2021-03-05","objectID":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/:0:5","tags":["LeetCode"],"title":"LeetCode 354:俄罗斯信封套娃问题","uri":"/leetcode-354%E4%BF%84%E7%BD%97%E6%96%AF%E5%A5%97%E5%A8%83%E4%BF%A1%E5%B0%81%E9%97%AE%E9%A2%98/"},{"categories":null,"content":"题目 给定一个非负整数 num。对于 0 ≤ i ≤ num 范围中的每个数字 i ，计算其二进制数中的 1 的数目并将它们作为数组返回 示例1: 输入: 2 输出: [0, 1, 1] 示例2: 输入: 5 输出: [0, 1, 1, 2, 1, 2] 进阶: 给出时间复杂度为 O(n * sizeof(integer)) 的解答非常容易. 但你可以在线性时间 O(n) 内用一趟扫描做到吗? 要求算法的空间复杂度为 O(n) 你能进一步完善解法吗？要求在C++或任何其他语言中不使用任何内置函数（如 C++ 中的 __builtin_popcount）来执行此操作 ","date":"2021-03-03","objectID":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/:0:1","tags":["LeetCode"],"title":"LeetCode 338:比特位计数","uri":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/"},{"categories":null,"content":"开始的思路 先不考虑进阶, 使用语言自带的函数进行解答，Golang中可以使用bits.OnesCount()函数来计算 func countBits(num int) []int { nums := make([]int, num+1) for i := 0; i \u003c= num; i++ { nums[i] = bits.OnesCount(uint(i)) } return nums } 这种解答十分简单，我们来尝试一下手写一个 OneCount() leetcode 官方解答内提到有一个位运算的小技巧 对于任意整数x, 令 x = x \u0026 (x - 1) , 该运算将 x 的二进制表示的最后一个1变成0. 因此, 对x重复该操作, 直到x变成0, 则操作次数即为x的「一比特数」 我们来实际操作一下试试 // 8的二进制为 1000 // 7的二进制为 0111 // 我们进行 \u0026 操作 1000 \u0026 0111 = 0000 // x 变成了 0 , 8的二进制数为1, 这符合我们的答案 // 让我们再来一个 // 6的二进制为 0110 // 5的二进制为 0101 // 4的二进制为 0100 // 3的二进制为 0011 0111 \u0026 0110 = 0110 // ones + 1 0110 \u0026 0101 = 0100 // ones + 1 0101 \u0026 0100 = 0100 // ones + 1 0100 \u0026 0011 = 0000 // ones = 3 // 对此我只能发出咸鱼的声音，妙啊 对此技巧，我们可以写出: func onesCount(x int) (ones int) { for ; x \u003e 0; x \u0026= x - 1 { ones++ } return } 但是这依然不满足进阶解答的需求，所以我们继续 ","date":"2021-03-03","objectID":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/:0:2","tags":["LeetCode"],"title":"LeetCode 338:比特位计数","uri":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/"},{"categories":null,"content":"进阶 要给出时间复杂度为 O(n) 的解法, 代表我们不能使用系统的内置函数, 且不能进入循环. 我们必须进行逻辑梳理 官方给出的解答: 动态规划–最高有效位 有些晦涩难懂 需要对每个数遍历其二进制表示的每一位。可以换一个思路，当计算 i 的「一比特数」时，如果存在 0 ≤ j \u003c i，j 的「一比特数」已知，且 i 和 j 相比，i 的二进制表示只多了一个 1，则可以快速得到 i 的「一比特数」。 令 bits[i] 表示 i 的「一比特数」，则上述关系可以表示成：bits[i] = bits[j] + 1。 对于正整数 x，如果可以知道最大的正整数 y，使得 y ≤ x 且 y 是 2 的整数次幂，则 y 的二进制表示中只有最高位是 1，其余都是 0，此时称 y 为 x 的「最高有效位」。令 z = x − y，显然 0 ≤ z \u003c x，则 bits[x] = bits[z] + 1。 为了判断一个正整数是不是 2 的整数次幂，可以利用方法一中提到的按位与运算的性质。如果正整数 y 是 2 的整数次幂，则 y 的二进制表示中只有最高位是 1，其余都是 0，因此 y \u0026 ( y − 1 ) = 0。由此可见，正整数 y 是 2 的整数次幂，当且仅当 y \u0026 ( y − 1 ) = 0。 显然，0 的「一比特数」为 0。使用 highBit 表示当前的最高有效位，遍历从 1 到 num 的每个正整数 i，进行如下操作。 如果 i\u0026(i−1)=0，则令 highBit = i，更新当前的最高有效位。 i 比 i−highBit 的「一比特数」多 1，由于是从小到大遍历每个数，因此遍历到 i 时，i−highBit 的「一比特数」已知，令 bits[i] = bits[i−highBit] + 1。 最终得到的数组 bits 即为答案。 作者：LeetCode-Solution 链接：https://leetcode-cn.com/problems/counting-bits/solution/bi-te-wei-ji-shu-by-leetcode-solution-0t1i/ 来源：力扣（LeetCode） 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 我这尝试做出自己的解释： 当一个数是 2 的整数次幂时, 它的二进制中1的数量只会是1 当一个数不是2的整数次幂时，它的二进制中1的数量为 (它 与 它上次为2的整数次幂的数的差值)的「一比特数」+ 1 我们可以来实际试试: // 8的二进制为 1000 它是2的整数次幂 所以它的二进制中1的数量只会是1 // 那 9 呢？根据上面的总结 它的上次2的整数次幂的数为 8,9-8=1(0001) 的「一比特数」为1 // 9 的二进制位是 1001 ,「一比特数」为 2, 完美 // 那 10 呢？它的上次2的整数次幂的数依然为 8, 10-8=2(0010) 的「一比特数」为1 // 10 的二进制位为 1010, 「一比特数」为 2 // 继续 11 二进制为 1011, 11-8=3 , 3(0011)的「一比特数」为2 // 对此我只能发出咸鱼的声音，妙啊 // 所以我们能写出下面的方法 func countBits(num int) []int { bits := make([]int, num+1) highBit := 0 // 最高比特位 即 上次为2的整数次幂的数 // 0的「一比特数」为 0，不需要进入循环 for i := 1; i \u003c= num; i++ { // 这里是根据上面的位运算的技巧，判断是否为2的整数次幂，因为2的整数次幂只有一个1 if i\u0026(i-1) == 0 { highBit = i // 更新最高比特位 } // 它与它上次为2的整数次幂的数的差值 的「一比特数」+ 1 bits[i] = bits[i-highBit] + 1 } return bits } 应该还是有些晦涩难懂，但是我也没得办法，这太抽象了，官方解答的其他动态规划思想就不继续了，我们还有新办法。 ","date":"2021-03-03","objectID":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/:0:3","tags":["LeetCode"],"title":"LeetCode 338:比特位计数","uri":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/"},{"categories":null,"content":"新的办法 对于所有的数字，只有两类 奇数|偶数: 奇数: 在二进制中表示，奇数一定比前面的那个偶数多一个1，多的就是最低位的1 举例： 0 = 0000 1 = 0001 2 = 0010 3 = 0011 发现了没有，偶数的最低位总是0，奇数的最低位总是1，我们再考虑偶数 偶数: 二进制中，偶数中的1一定和除以2之后的那个数一样多，因为偶数的最低位总是0 除以2就只是右移一位，把最低位的0去掉而已，所以1的数量是不变的 举例: 0 = 0000 1 = 0001 // 0不算, 1的「一比特数」= 0 + 1 2 = 0010 3 = 0011 // 2 / 2 = 1, 1的「一比特数」= 1 … 4 = 0100 5 = 0101 6 = 0110 7 = 0111 我们能根据上面的规律来写出以下代码 func countBits(num int) []int { nums := make([]int, num+1) for i := 1; i \u003c= num; i++ { // 判断是否为偶数，奇数的最后一位永远是1 if i\u00261 == 1 { nums[i] = nums[i-1] + 1 } else { nums[i] = nums[i/2] } } return nums } 以上思路来自: 作者：duadua 链接：https://leetcode-cn.com/problems/counting-bits/solution/hen-qing-xi-de-si-lu-by-duadua/ 来源：力扣（LeetCode） ","date":"2021-03-03","objectID":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/:0:4","tags":["LeetCode"],"title":"LeetCode 338:比特位计数","uri":"/leetcode-338%E6%AF%94%E7%89%B9%E4%BD%8D%E8%AE%A1%E6%95%B0/"},{"categories":null,"content":" 本主题为系列文章，分上下两篇。本文主要介绍 time/rate 的具体使用方法，另外一篇文章 《Golang 限流器 time/rate 实现剖析》 则着重介绍其内部实现原理。 限流器是后台服务中的非常重要的组件，可以用来限制请求速率，保护服务，以免服务过载。 限流器的实现方法有很多种，例如滑动窗口法、Token Bucket、Leaky Bucket 等。 其实 Golang 标准库中就自带了限流算法的实现，即 golang.org/x/time/rate。该限流器是基于 Token Bucket(令牌桶) 实现的。 简单来说，令牌桶就是想象有一个固定大小的桶，系统会以恒定速率向桶中放 Token，桶满则暂时不放。 而用户则从桶中取 Token，如果有剩余 Token 就可以一直取。如果没有剩余 Token，则需要等到系统中被放置了 Token 才行。 本文则主要集中介绍下该组件的具体使用方法： 构造一个限流器 我们可以使用以下方法构造一个限流器对象： limiter := NewLimiter(10, 1); 这里有两个参数： 第一个参数是 r Limit。代表每秒可以向 Token 桶中产生多少 token。Limit 实际上是 float64 的别名。 第二个参数是 b int。b 代表 Token 桶的容量大小。 那么，对于以上例子来说，其构造出的限流器含义为，其令牌桶大小为 1, 以每秒 10 个 Token 的速率向桶中放置 Token。 除了直接指定每秒产生的 Token 个数外，还可以用 Every 方法来指定向 Token 桶中放置 Token 的间隔，例如： limit := Every(100 * time.Millisecond); limiter := NewLimiter(limit, 1); 以上就表示每 100ms 往桶中放一个 Token。本质上也就是一秒钟产生 10 个。 Limiter 提供了三类方法供用户消费 Token，用户可以每次消费一个 Token，也可以一次性消费多个 Token。 而每种方法代表了当 Token 不足时，各自不同的对应手段。 Wait/WaitN func (lim *Limiter) Wait(ctx context.Context) (err error) func (lim *Limiter) WaitN(ctx context.Context, n int) (err error) Wait 实际上就是 WaitN(ctx,1)。 当使用 Wait 方法消费 Token 时，如果此时桶内 Token 数组不足 (小于 N)，那么 Wait 方法将会阻塞一段时间，直至 Token 满足条件。如果充足则直接返回。 这里可以看到，Wait 方法有一个 context 参数。 我们可以设置 context 的 Deadline 或者 Timeout，来决定此次 Wait 的最长时间。 Allow/AllowN func (lim *Limiter) Allow() bool func (lim *Limiter) AllowN(now time.Time, n int) bool Allow 实际上就是 AllowN(time.Now(),1)。 AllowN 方法表示，截止到某一时刻，目前桶中数目是否至少为 n 个，满足则返回 true，同时从桶中消费 n 个 token。 反之返回不消费 Token，false。 通常对应这样的线上场景，如果请求速率过快，就直接丢到某些请求。 Reserve/ReserveN func (lim *Limiter) Reserve() *Reservation func (lim *Limiter) ReserveN(now time.Time, n int) *Reservation Reserve 相当于 ReserveN(time.Now(), 1)。 ReserveN 的用法就相对来说复杂一些，当调用完成后，无论 Token 是否充足，都会返回一个 Reservation * 对象。 你可以调用该对象的 Delay() 方法，该方法返回了需要等待的时间。如果等待时间为 0，则说明不用等待。 必须等到等待时间之后，才能进行接下来的工作。 或者，如果不想等待，可以调用 Cancel() 方法，该方法会将 Token 归还。 举一个简单的例子，我们可以这么使用 Reserve 方法。 r := lim.Reserve() f !r.OK() { // Not allowed to act! Did you remember to set lim.burst to be \u003e 0 ? return } time.Sleep(r.Delay()) Act() // 执行相关逻辑 动态调整速率 Limiter 支持可以调整速率和桶大小： SetLimit(Limit) 改变放入 Token 的速率 SetBurst(int) 改变 Token 桶大小 有了这两个方法，可以根据现有环境和条件，根据我们的需求，动态的改变 Token 桶大小和速率。 相关文章 Golang 限流器 time/rate 实现剖析 uber-go 漏桶限流器使用与原理分析 本文作者： cyhone 本文链接： https://www.cyhone.com/articles/usage-of-golang-rate/ 版权声明： 本博客所有文章除特别声明外，均采用 BY-NC-SA 许可协议。转载请注明出处！ ","date":"2021-03-03","objectID":"/golang%E6%A0%87%E5%87%86%E5%BA%93%E9%99%90%E6%B5%81%E5%99%A8timerate%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/:0:0","tags":["Go标准库"],"title":"Golang标准库限流器timerate使用介绍","uri":"/golang%E6%A0%87%E5%87%86%E5%BA%93%E9%99%90%E6%B5%81%E5%99%A8timerate%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/"},{"categories":null,"content":"限流器是微服务中必不缺少的一环，可以起到保护下游服务，防止服务过载等作用。上一篇文章 《Golang 限流器 time/rate 使用介绍》 简单介绍了 time/rate 的使用方法，本文则着重分析下其实现原理。建议在正式阅读本文之前，先阅读下上一篇文章。 上一篇文章讲到，time/rate 是基于 Token Bucket(令牌桶) 算法实现的限流。本文将会基于源码，深入剖析下 Golang 是如何实现 Token Bucket 的。其代码也非常简洁，去除注释后，也就 200 行左右的代码量。 同时，我也提供了 time/rate 注释版，辅助大家理解该组件的实现。 背景 简单来说，令牌桶就是想象有一个固定大小的桶，系统会以恒定速率向桶中放 Token，桶满则暂时不放。 而用户则从桶中取 Token，如果有剩余 Token 就可以一直取。如果没有剩余 Token，则需要等到系统中被放置了 Token 才行。 一般介绍 Token Bucket 的时候，都会有一张这样的原理图： 从这个图中看起来，似乎令牌桶实现应该是这样的： 有一个 Timer 和一个 BlockingQueue。Timer 固定的往 BlockingQueue 中放 token。用户则从 BlockingQueue 中取数据。 这固然是 Token Bucket 的一种实现方式，这么做也非常直观，但是效率太低了：我们需要不仅多维护一个 Timer 和 BlockingQueue，而且还耗费了一些不必要的内存。 在 Golang 的 timer/rate 中的实现, 并没有单独维护一个 Timer，而是采用了 lazyload 的方式，直到每次消费之前才根据时间差更新 Token 数目，而且也不是用 BlockingQueue 来存放 Token，而是仅仅通过计数的方式。 Token 的生成和消费 我们在 上一篇文章 中讲到，Token 的消费方式有三种。但其实在内部实现，最终三种消费方式都调用了 reserveN 函数来生成和消费 Token。 我们看下 reserveN 函数的具体实现，整个过程非常简单。在正式讲之前，我们先了解一个简单的概念： 在 time/rate 中，NewLimiter 的第一个参数是速率 limit，代表了一秒钟可以产生多少 Token。 那么简单换算一下，我们就可以知道一个 Token 的生成间隔是多少。 有了这个生成间隔，我们就可以轻易地得到两个数据： 1. 生成 N 个新的 Token 一共需要多久。time/rate 中对应的实现函数为 durationFromTokens。 2. 给定一段时长，这段时间一共可以生成多少个 Token。time/rate 中对应的实现函数为 tokensFromDuration。 那么，有了这些转换函数，整个过程就很清晰了，如下： 计算从上次取 Token 的时间到当前时刻，期间一共新产生了多少 Token： 我们只在取 Token 之前生成新的 Token，也就意味着每次取 Token 的间隔，实际上也是生成 Token 的间隔。我们可以利用 tokensFromDuration, 轻易的算出这段时间一共产生 Token 的数目。 那么，当前 Token 数目 = 新产生的 Token 数目 + 之前剩余的 Token 数目 - 要消费的 Token 数目。 如果消费后剩余 Token 数目大于零，说明此时 Token 桶内仍不为空，此时 Token 充足，无需调用侧等待。 如果 Token 数目小于零，则需等待一段时间。 那么这个时候，我们可以利用 durationFromTokens 将当前负值的 Token 数转化为需要等待的时间。 将需要等待的时间等相关结果返回给调用方。 从上面可以看出，其实整个过程就是利用了 Token 数可以和时间相互转化 的原理。而如果 Token 数为负，则需要等待相应时间即可。 注意 如果当消费时，Token 桶中的 Token 数目已经为负值了，依然可以按照上述流程进行消费。随着负值越来越小，等待的时间将会越来越长。 从结果来看，这个行为跟用 Timer+BlockQueue 实现是一样的。 此外，整个过程为了保证线程安全，更新令牌桶相关数据时都用了 mutex 加锁。 我们模拟下请求与 Token 数变化的关系： 当某一时间，桶内 Token 数为 3, 此时 A 线程请求 5 个 Token。那么此时桶内 Token 不足，因此 A 线程需要等待 2 个 Token 的时间。 且此时桶内 Token 数变为 - 2。 同时，B 线程请求 4 个 Token，此时桶内 Token 数为 - 2，因此 B 线程需要等待 2+4=6 个 Token 的时间，且此时桶内 Token 数变为 - 6。 对于 Allow 函数实现时，只要判断需要等待的时间是否为 0 即可，如果大于 0 说明需要等待，则返回 False，反之返回 True。 对于 Wait 函数，直接 t := time.NewTimer(delay)，等待对应的时间即可。 float 精度问题 从上面原理讲述可以看出，在 Token 和时间的相互转化函数 durationFromTokens 和 tokensFromDuration 中，涉及到 float64 的乘除运算。 一谈到 float 的乘除，我们就需要小心精度问题了。 而 Golang 在这里也踩了坑，以下是 tokensFromDuration 最初的实现版本 func (limit Limit) tokensFromDuration(d time.Duration) float64 { return d.Seconds() * float64(limit) } 这个操作看起来一点问题都没：每秒生成的 Token 数乘于秒数。 然而，这里的问题在于，d.Seconds() 已经是小数了。两个小数相乘，会带来精度的损失。 所以就有了这个 issue:golang.org/issues/34861。 修改后新的版本如下： func (limit Limit) tokensFromDuration(d time.Duration) float64 { sec := float64(d/time.Second) * float64(limit) nsec := float64(d%time.Second) * float64(limit) return sec + nsec/1e9 } time.Duration 是 int64 的别名，代表纳秒。分别求出秒的整数部分和小数部分，进行相乘后再相加，这样可以得到最精确的精度。 数值溢出问题 我们讲 reserveN 函数的具体实现时，第一步就是计算从当前时间到上次取 Token 的时刻，期间一共新产生了多少 Token，同时也可得出当前的 Token 是多少。 我最开始的理解是，直接可以这么做： // elapsed 表示过去的时间差 elapsed := now.Sub(lim.last) // delta 表示这段时间一共新产生了多少 Token delta = tokensFromDuration(now.Sub(lim.last)) tokens := lim.tokens + delta if(token\u003e lim.burst){ token = lim.burst } 其中，lim.tokens 是当前剩余的 Token，lim.last 是上次取 token 的时刻。lim.burst 是 Token 桶的大小。 使用 tokensFromDuration 计算出新生成了多少 Token，累加起来后，不能超过桶的容量即可。 这么做看起来也没什么问题，然而并不是这样。 在 time/rate 里面是这么做的，如下代码所示： maxElapsed := lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens) elapsed := now.Sub(last) if elapsed \u003e maxElapsed { elapsed = maxElapsed } delta := lim.limit.tokensFromDuration(elapsed) tokens := lim.tokens + delta if burst := float64(lim.burst); tokens \u003e burst { tokens = burst } 与我们最开始的代码不一样的是，它没有直接用 now.Sub(lim.last) 来转化为对应的 Token 数，而是 先用 lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens)，计算把桶填满的时间 maxElapsed。 取 elapsed 和 maxElapsed 的最小值。 这么做算出的结果肯定是正确的，但是这么做相比于我们的做法，好处在哪里？ 对于我们的代码，当 last 非常小的时候（或者当其为初始值 0 的时候），此时 now.Sub(lim.last) 的值就会非常大，如果 lim.limit 即每秒生成的 Token 数目也非常大时，直接将二者进行乘法运算，结果有可能会溢出。 因此，time/rate 先计算了把桶填满的时间，将其作为时间差值的上限，这样就规避了溢出的问题。 Token 的归还 而对于 Reserve 函","date":"2021-03-03","objectID":"/golang%E6%A0%87%E5%87%86%E5%BA%93%E9%99%90%E6%B5%81%E5%99%A8timerate%E5%AE%9E%E7%8E%B0%E5%89%96%E6%9E%90/:0:0","tags":["Go标准库"],"title":"Golang标准库限流器timerate实现剖析","uri":"/golang%E6%A0%87%E5%87%86%E5%BA%93%E9%99%90%E6%B5%81%E5%99%A8timerate%E5%AE%9E%E7%8E%B0%E5%89%96%E6%9E%90/"},{"categories":null,"content":"个人博客，瞎写写 OTG ","date":"2021-03-03","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"}]